{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81d730fe",
   "metadata": {},
   "source": [
    "## Import dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "66b9722d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f30fe124",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('TRAIN.csv')\n",
    "test = pd.read_csv('TEST.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b35df",
   "metadata": {},
   "source": [
    "# Data Visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f3f235ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Order</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>7011.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1000002</td>\n",
       "      <td>253</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>60</td>\n",
       "      <td>51789.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1000003</td>\n",
       "      <td>252</td>\n",
       "      <td>S3</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42</td>\n",
       "      <td>36868.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1000004</td>\n",
       "      <td>251</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>19715.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1000005</td>\n",
       "      <td>250</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "      <td>45614.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
       "0  T1000001         1         S1            L3          R1  2018-01-01   \n",
       "1  T1000002       253         S4            L2          R1  2018-01-01   \n",
       "2  T1000003       252         S3            L2          R1  2018-01-01   \n",
       "3  T1000004       251         S2            L3          R1  2018-01-01   \n",
       "4  T1000005       250         S2            L3          R4  2018-01-01   \n",
       "\n",
       "   Holiday Discount  Order     Sales  \n",
       "0        1      Yes      9   7011.84  \n",
       "1        1      Yes     60  51789.12  \n",
       "2        1      Yes     42  36868.20  \n",
       "3        1      Yes     23  19715.16  \n",
       "4        1      Yes     62  45614.52  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9623d776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1000002</td>\n",
       "      <td>253</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1000003</td>\n",
       "      <td>252</td>\n",
       "      <td>S3</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1000004</td>\n",
       "      <td>251</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1000005</td>\n",
       "      <td>250</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
       "0  T1000001         1         S1            L3          R1  2018-01-01   \n",
       "1  T1000002       253         S4            L2          R1  2018-01-01   \n",
       "2  T1000003       252         S3            L2          R1  2018-01-01   \n",
       "3  T1000004       251         S2            L3          R1  2018-01-01   \n",
       "4  T1000005       250         S2            L3          R4  2018-01-01   \n",
       "\n",
       "   Holiday Discount  Order  \n",
       "0        1      Yes      9  \n",
       "1        1      Yes     60  \n",
       "2        1      Yes     42  \n",
       "3        1      Yes     23  \n",
       "4        1      Yes     62  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "f4e8a010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>188340.000000</td>\n",
       "      <td>188340.000000</td>\n",
       "      <td>188340.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>0.131783</td>\n",
       "      <td>68.205692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>105.366308</td>\n",
       "      <td>0.338256</td>\n",
       "      <td>30.467415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>92.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>183.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>274.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>82.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>365.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>371.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store_id        Holiday          Order\n",
       "count  188340.000000  188340.000000  188340.000000\n",
       "mean      183.000000       0.131783      68.205692\n",
       "std       105.366308       0.338256      30.467415\n",
       "min         1.000000       0.000000       0.000000\n",
       "25%        92.000000       0.000000      48.000000\n",
       "50%       183.000000       0.000000      63.000000\n",
       "75%       274.000000       0.000000      82.000000\n",
       "max       365.000000       1.000000     371.000000"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "0876eef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID               0\n",
       "Store_id         0\n",
       "Store_Type       0\n",
       "Location_Type    0\n",
       "Region_Code      0\n",
       "Date             0\n",
       "Holiday          0\n",
       "Discount         0\n",
       "Order            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "fc3830fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>S3</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store_id Store_Type Location_Type Region_Code        Date  Holiday Discount\n",
       "0         1         S1            L3          R1  2018-01-01        1      Yes\n",
       "1       253         S4            L2          R1  2018-01-01        1      Yes\n",
       "2       252         S3            L2          R1  2018-01-01        1      Yes\n",
       "3       251         S2            L3          R1  2018-01-01        1      Yes\n",
       "4       250         S2            L3          R4  2018-01-01        1      Yes"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.drop(columns = ['ID', \"Order\"])\n",
    "x.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "16c84b23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128    516\n",
       "84     516\n",
       "211    516\n",
       "83     516\n",
       "338    516\n",
       "      ... \n",
       "168    516\n",
       "40     516\n",
       "295    516\n",
       "167    516\n",
       "255    516\n",
       "Name: Store_id, Length: 365, dtype: int64"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "ec9156c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S1    88752\n",
       "S4    45924\n",
       "S2    28896\n",
       "S3    24768\n",
       "Name: Store_Type, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0648dfee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L1    85140\n",
       "L2    48504\n",
       "L3    29928\n",
       "L5    13932\n",
       "L4    10836\n",
       "Name: Location_Type, dtype: int64"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Location_Type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "e80a8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S1    53148\n",
       "S4    13932\n",
       "S3    13416\n",
       "S2     4644\n",
       "Name: Store_Type, dtype: int64"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_Type'][x['Location_Type'] == 'L1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ac65ac68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S4    31992\n",
       "S3     9288\n",
       "S1     7224\n",
       "Name: Store_Type, dtype: int64"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_Type'][x['Location_Type'] == 'L2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "a0532716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S1    18576\n",
       "S2     9288\n",
       "S3     2064\n",
       "Name: Store_Type, dtype: int64"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_Type'][x['Location_Type'] == 'L3'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "0c124bd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "S1    6192\n",
       "S2    4644\n",
       "Name: Store_Type, dtype: int64"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Store_Type'][x['Location_Type'] == 'L4'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f32fb064",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "83cf2bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>149</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>153</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>154</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>155</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>152</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store_id        Date  Holiday Discount  Location_Type_L1  \\\n",
       "0              1  2018-01-01        1      Yes                 0   \n",
       "1            253  2018-01-01        1      Yes                 0   \n",
       "2            252  2018-01-01        1      Yes                 0   \n",
       "3            251  2018-01-01        1      Yes                 0   \n",
       "4            250  2018-01-01        1      Yes                 0   \n",
       "...          ...         ...      ...      ...               ...   \n",
       "188335       149  2019-05-31        1      Yes                 0   \n",
       "188336       153  2019-05-31        1       No                 0   \n",
       "188337       154  2019-05-31        1       No                 0   \n",
       "188338       155  2019-05-31        1      Yes                 1   \n",
       "188339       152  2019-05-31        1       No                 1   \n",
       "\n",
       "        Location_Type_L2  Location_Type_L3  Location_Type_L4  \\\n",
       "0                      0                 1                 0   \n",
       "1                      1                 0                 0   \n",
       "2                      1                 0                 0   \n",
       "3                      0                 1                 0   \n",
       "4                      0                 1                 0   \n",
       "...                  ...               ...               ...   \n",
       "188335                 0                 1                 0   \n",
       "188336                 1                 0                 0   \n",
       "188337                 0                 1                 0   \n",
       "188338                 0                 0                 0   \n",
       "188339                 0                 0                 0   \n",
       "\n",
       "        Location_Type_L5  Store_Type_S1  Store_Type_S2  Store_Type_S3  \\\n",
       "0                      0              1              0              0   \n",
       "1                      0              0              0              0   \n",
       "2                      0              0              0              1   \n",
       "3                      0              0              1              0   \n",
       "4                      0              0              1              0   \n",
       "...                  ...            ...            ...            ...   \n",
       "188335                 0              0              1              0   \n",
       "188336                 0              0              0              0   \n",
       "188337                 0              1              0              0   \n",
       "188338                 0              0              0              1   \n",
       "188339                 0              0              1              0   \n",
       "\n",
       "        Store_Type_S4  Region_Code_R1  Region_Code_R2  Region_Code_R3  \\\n",
       "0                   0               1               0               0   \n",
       "1                   1               1               0               0   \n",
       "2                   0               1               0               0   \n",
       "3                   0               1               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "188335              0               0               1               0   \n",
       "188336              1               1               0               0   \n",
       "188337              0               0               1               0   \n",
       "188338              0               0               1               0   \n",
       "188339              0               1               0               0   \n",
       "\n",
       "        Region_Code_R4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "188335               0  \n",
       "188336               0  \n",
       "188337               0  \n",
       "188338               0  \n",
       "188339               0  \n",
       "\n",
       "[188340 rows x 17 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = pd.get_dummies(x, columns = ['Location_Type', 'Store_Type', 'Region_Code'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "88eb02c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>149</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>153</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>154</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>155</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>152</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store_id        Date  Holiday  Discount  Location_Type_L1  \\\n",
       "0              1  2018-01-01        1         1                 0   \n",
       "1            253  2018-01-01        1         1                 0   \n",
       "2            252  2018-01-01        1         1                 0   \n",
       "3            251  2018-01-01        1         1                 0   \n",
       "4            250  2018-01-01        1         1                 0   \n",
       "...          ...         ...      ...       ...               ...   \n",
       "188335       149  2019-05-31        1         1                 0   \n",
       "188336       153  2019-05-31        1         0                 0   \n",
       "188337       154  2019-05-31        1         0                 0   \n",
       "188338       155  2019-05-31        1         1                 1   \n",
       "188339       152  2019-05-31        1         0                 1   \n",
       "\n",
       "        Location_Type_L2  Location_Type_L3  Location_Type_L4  \\\n",
       "0                      0                 1                 0   \n",
       "1                      1                 0                 0   \n",
       "2                      1                 0                 0   \n",
       "3                      0                 1                 0   \n",
       "4                      0                 1                 0   \n",
       "...                  ...               ...               ...   \n",
       "188335                 0                 1                 0   \n",
       "188336                 1                 0                 0   \n",
       "188337                 0                 1                 0   \n",
       "188338                 0                 0                 0   \n",
       "188339                 0                 0                 0   \n",
       "\n",
       "        Location_Type_L5  Store_Type_S1  Store_Type_S2  Store_Type_S3  \\\n",
       "0                      0              1              0              0   \n",
       "1                      0              0              0              0   \n",
       "2                      0              0              0              1   \n",
       "3                      0              0              1              0   \n",
       "4                      0              0              1              0   \n",
       "...                  ...            ...            ...            ...   \n",
       "188335                 0              0              1              0   \n",
       "188336                 0              0              0              0   \n",
       "188337                 0              1              0              0   \n",
       "188338                 0              0              0              1   \n",
       "188339                 0              0              1              0   \n",
       "\n",
       "        Store_Type_S4  Region_Code_R1  Region_Code_R2  Region_Code_R3  \\\n",
       "0                   0               1               0               0   \n",
       "1                   1               1               0               0   \n",
       "2                   0               1               0               0   \n",
       "3                   0               1               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "188335              0               0               1               0   \n",
       "188336              1               1               0               0   \n",
       "188337              0               0               1               0   \n",
       "188338              0               0               1               0   \n",
       "188339              0               1               0               0   \n",
       "\n",
       "        Region_Code_R4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "188335               0  \n",
       "188336               0  \n",
       "188337               0  \n",
       "188338               0  \n",
       "188339               0  \n",
       "\n",
       "[188340 rows x 17 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "x['Discount'] = le.fit_transform(x['Discount'])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9a89de15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2018-01-01\n",
       "1         2018-01-01\n",
       "2         2018-01-01\n",
       "3         2018-01-01\n",
       "4         2018-01-01\n",
       "             ...    \n",
       "188335    2019-05-31\n",
       "188336    2019-05-31\n",
       "188337    2019-05-31\n",
       "188338    2019-05-31\n",
       "188339    2019-05-31\n",
       "Name: Date, Length: 188340, dtype: object"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "66f529a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>149</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>153</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>154</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>155</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>152</td>\n",
       "      <td>2019-05-31</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store_id       Date  Holiday  Discount  Location_Type_L1  \\\n",
       "0              1 2018-01-01        1         1                 0   \n",
       "1            253 2018-01-01        1         1                 0   \n",
       "2            252 2018-01-01        1         1                 0   \n",
       "3            251 2018-01-01        1         1                 0   \n",
       "4            250 2018-01-01        1         1                 0   \n",
       "...          ...        ...      ...       ...               ...   \n",
       "188335       149 2019-05-31        1         1                 0   \n",
       "188336       153 2019-05-31        1         0                 0   \n",
       "188337       154 2019-05-31        1         0                 0   \n",
       "188338       155 2019-05-31        1         1                 1   \n",
       "188339       152 2019-05-31        1         0                 1   \n",
       "\n",
       "        Location_Type_L2  Location_Type_L3  Location_Type_L4  \\\n",
       "0                      0                 1                 0   \n",
       "1                      1                 0                 0   \n",
       "2                      1                 0                 0   \n",
       "3                      0                 1                 0   \n",
       "4                      0                 1                 0   \n",
       "...                  ...               ...               ...   \n",
       "188335                 0                 1                 0   \n",
       "188336                 1                 0                 0   \n",
       "188337                 0                 1                 0   \n",
       "188338                 0                 0                 0   \n",
       "188339                 0                 0                 0   \n",
       "\n",
       "        Location_Type_L5  Store_Type_S1  Store_Type_S2  Store_Type_S3  \\\n",
       "0                      0              1              0              0   \n",
       "1                      0              0              0              0   \n",
       "2                      0              0              0              1   \n",
       "3                      0              0              1              0   \n",
       "4                      0              0              1              0   \n",
       "...                  ...            ...            ...            ...   \n",
       "188335                 0              0              1              0   \n",
       "188336                 0              0              0              0   \n",
       "188337                 0              1              0              0   \n",
       "188338                 0              0              0              1   \n",
       "188339                 0              0              1              0   \n",
       "\n",
       "        Store_Type_S4  Region_Code_R1  Region_Code_R2  Region_Code_R3  \\\n",
       "0                   0               1               0               0   \n",
       "1                   1               1               0               0   \n",
       "2                   0               1               0               0   \n",
       "3                   0               1               0               0   \n",
       "4                   0               0               0               0   \n",
       "...               ...             ...             ...             ...   \n",
       "188335              0               0               1               0   \n",
       "188336              1               1               0               0   \n",
       "188337              0               0               1               0   \n",
       "188338              0               0               1               0   \n",
       "188339              0               1               0               0   \n",
       "\n",
       "        Region_Code_R4  \n",
       "0                    0  \n",
       "1                    0  \n",
       "2                    0  \n",
       "3                    0  \n",
       "4                    1  \n",
       "...                ...  \n",
       "188335               0  \n",
       "188336               0  \n",
       "188337               0  \n",
       "188338               0  \n",
       "188339               0  \n",
       "\n",
       "[188340 rows x 17 columns]"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date'] = pd.to_datetime(x['Date'], format = '%Y-%m-%d', errors = 'coerce')\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "df363e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "8e3f79a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store_id  Date  Holiday  Discount  Location_Type_L1  Location_Type_L2  \\\n",
       "0              1     0        1         1                 0                 0   \n",
       "1            253     0        1         1                 0                 1   \n",
       "2            252     0        1         1                 0                 1   \n",
       "3            251     0        1         1                 0                 0   \n",
       "4            250     0        1         1                 0                 0   \n",
       "...          ...   ...      ...       ...               ...               ...   \n",
       "188335       149     4        1         1                 0                 0   \n",
       "188336       153     4        1         0                 0                 1   \n",
       "188337       154     4        1         0                 0                 0   \n",
       "188338       155     4        1         1                 1                 0   \n",
       "188339       152     4        1         0                 1                 0   \n",
       "\n",
       "        Location_Type_L3  Location_Type_L4  Location_Type_L5  Store_Type_S1  \\\n",
       "0                      1                 0                 0              1   \n",
       "1                      0                 0                 0              0   \n",
       "2                      0                 0                 0              0   \n",
       "3                      1                 0                 0              0   \n",
       "4                      1                 0                 0              0   \n",
       "...                  ...               ...               ...            ...   \n",
       "188335                 1                 0                 0              0   \n",
       "188336                 0                 0                 0              0   \n",
       "188337                 1                 0                 0              1   \n",
       "188338                 0                 0                 0              0   \n",
       "188339                 0                 0                 0              0   \n",
       "\n",
       "        Store_Type_S2  Store_Type_S3  Store_Type_S4  Region_Code_R1  \\\n",
       "0                   0              0              0               1   \n",
       "1                   0              0              1               1   \n",
       "2                   0              1              0               1   \n",
       "3                   1              0              0               1   \n",
       "4                   1              0              0               0   \n",
       "...               ...            ...            ...             ...   \n",
       "188335              1              0              0               0   \n",
       "188336              0              0              1               1   \n",
       "188337              0              0              0               0   \n",
       "188338              0              1              0               0   \n",
       "188339              1              0              0               1   \n",
       "\n",
       "        Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0                    0               0               0  \n",
       "1                    0               0               0  \n",
       "2                    0               0               0  \n",
       "3                    0               0               0  \n",
       "4                    0               0               1  \n",
       "...                ...             ...             ...  \n",
       "188335               1               0               0  \n",
       "188336               0               0               0  \n",
       "188337               1               0               0  \n",
       "188338               1               0               0  \n",
       "188339               0               0               0  \n",
       "\n",
       "[188340 rows x 17 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date'] = x['Date'].dt.dayofweek\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d913e522",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    27010\n",
       "1    27010\n",
       "2    27010\n",
       "3    27010\n",
       "4    27010\n",
       "5    26645\n",
       "6    26645\n",
       "Name: Date, dtype: int64"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x['Date'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "c7a65eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store_id  Date  Holiday  Discount  Location_Type_L1  Location_Type_L2  \\\n",
       "0         1     0        1         1                 0                 0   \n",
       "1       253     0        1         1                 0                 1   \n",
       "2       252     0        1         1                 0                 1   \n",
       "3       251     0        1         1                 0                 0   \n",
       "4       250     0        1         1                 0                 0   \n",
       "\n",
       "   Location_Type_L3  Location_Type_L4  Location_Type_L5  Store_Type_S1  \\\n",
       "0                 1                 0                 0              1   \n",
       "1                 0                 0                 0              0   \n",
       "2                 0                 0                 0              0   \n",
       "3                 1                 0                 0              0   \n",
       "4                 1                 0                 0              0   \n",
       "\n",
       "   Store_Type_S2  Store_Type_S3  Store_Type_S4  Region_Code_R1  \\\n",
       "0              0              0              0               1   \n",
       "1              0              0              1               1   \n",
       "2              0              1              0               1   \n",
       "3              1              0              0               1   \n",
       "4              1              0              0               0   \n",
       "\n",
       "   Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0               0               0               0  \n",
       "1               0               0               0  \n",
       "2               0               0               0  \n",
       "3               0               0               0  \n",
       "4               0               0               1  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e085808",
   "metadata": {},
   "source": [
    "## Feature Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24f08602",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "x = sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0a063df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>252</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>251</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188335</th>\n",
       "      <td>149</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188336</th>\n",
       "      <td>153</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188337</th>\n",
       "      <td>154</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188338</th>\n",
       "      <td>155</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188339</th>\n",
       "      <td>152</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>188340 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Store_id  Date  Holiday  Discount  Location_Type_L1  Location_Type_L2  \\\n",
       "0              1     0        1         1                 0                 0   \n",
       "1            253     0        1         1                 0                 1   \n",
       "2            252     0        1         1                 0                 1   \n",
       "3            251     0        1         1                 0                 0   \n",
       "4            250     0        1         1                 0                 0   \n",
       "...          ...   ...      ...       ...               ...               ...   \n",
       "188335       149     4        1         1                 0                 0   \n",
       "188336       153     4        1         0                 0                 1   \n",
       "188337       154     4        1         0                 0                 0   \n",
       "188338       155     4        1         1                 1                 0   \n",
       "188339       152     4        1         0                 1                 0   \n",
       "\n",
       "        Location_Type_L3  Location_Type_L4  Location_Type_L5  Store_Type_S1  \\\n",
       "0                      1                 0                 0              1   \n",
       "1                      0                 0                 0              0   \n",
       "2                      0                 0                 0              0   \n",
       "3                      1                 0                 0              0   \n",
       "4                      1                 0                 0              0   \n",
       "...                  ...               ...               ...            ...   \n",
       "188335                 1                 0                 0              0   \n",
       "188336                 0                 0                 0              0   \n",
       "188337                 1                 0                 0              1   \n",
       "188338                 0                 0                 0              0   \n",
       "188339                 0                 0                 0              0   \n",
       "\n",
       "        Store_Type_S2  Store_Type_S3  Store_Type_S4  Region_Code_R1  \\\n",
       "0                   0              0              0               1   \n",
       "1                   0              0              1               1   \n",
       "2                   0              1              0               1   \n",
       "3                   1              0              0               1   \n",
       "4                   1              0              0               0   \n",
       "...               ...            ...            ...             ...   \n",
       "188335              1              0              0               0   \n",
       "188336              0              0              1               1   \n",
       "188337              0              0              0               0   \n",
       "188338              0              1              0               0   \n",
       "188339              1              0              0               1   \n",
       "\n",
       "        Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0                    0               0               0  \n",
       "1                    0               0               0  \n",
       "2                    0               0               0  \n",
       "3                    0               0               0  \n",
       "4                    0               0               1  \n",
       "...                ...             ...             ...  \n",
       "188335               1               0               0  \n",
       "188336               0               0               0  \n",
       "188337               1               0               0  \n",
       "188338               1               0               0  \n",
       "188339               0               0               0  \n",
       "\n",
       "[188340 rows x 17 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4ecd41",
   "metadata": {},
   "source": [
    "## Applying Kernal PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222a8a5e",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "\n",
    "Kpca = KernelPCA(n_components = 3, kernel = 'rbf')\n",
    "x = Kpca.fit_transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee877a7a",
   "metadata": {},
   "source": [
    "# Training model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "f82fe3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state = 0, test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "4789b337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63499     52794.00\n",
      "135914    56754.00\n",
      "123327    47349.00\n",
      "103391    20922.00\n",
      "146155    33420.00\n",
      "            ...   \n",
      "152315    37002.00\n",
      "176963    73866.00\n",
      "117952    31236.00\n",
      "173685    49554.00\n",
      "43567     22284.15\n",
      "Name: Sales, Length: 150672, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58fd4de",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9ef76ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(n_jobs=-1, random_state=10)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "reg = RandomForestRegressor(random_state = 10, n_jobs = -1)\n",
    "reg.fit(x, y)          #Training on whole unprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "813c705a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "981c1b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6937.116329258983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7147285089326727"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "acc = mean_absolute_error(y_test, y_pred)\n",
    "print(acc)\n",
    "r2_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed8ca29",
   "metadata": {},
   "source": [
    "## Grid Search "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "cc0153ed",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy: 66.95 %\n",
      "best parameters :  {'max_depth': 50, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parms = {\n",
    "    'n_estimators' : [300],\n",
    "    'max_depth' : [50]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = reg,\n",
    "                          param_grid = parms,\n",
    "                          scoring = 'r2' ,\n",
    "                          n_jobs = -1,\n",
    "                          cv = 5)\n",
    "\n",
    "grid_search.fit(x, y)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('best accuracy: {:.2f} %'.format(best_accuracy*100))\n",
    "print(\"best parameters : \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "087d9146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7266759766666232"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = grid_search.predict(x_test)\n",
    "r2_score(y_test, y_pred)\n",
    "#726674    best parameters :  {'max_depth': 50, 'n_estimators': 300} without fearure scaling\n",
    "#7266759   best parameters :  {'max_depth': 50, 'n_estimators': 300} with fearure scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79183414",
   "metadata": {},
   "source": [
    "# XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9cdb3d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83585.71  23675.025 27263.188 ... 28897.598 32588.826 38855.406]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "xgb = XGBRegressor()\n",
    "xgb.fit(x, y)\n",
    "y_pred = xgb.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "b1109585",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6937.116329258983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7147285089326727"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc = mean_absolute_error(y_test, y_pred)\n",
    "print(acc)\n",
    "r2_score(y_test, y_pred) # 6937 7147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e038c62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best accuracy: 67.88 %\n",
      "best parameters :  {'booster': 'gbtree', 'lambda': 0, 'max_depth': 6}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "parms = {\n",
    "    'booster' : ['gbtree', 'gblinear'],\n",
    "    'max_depth' : [6, 4, 7 ],\n",
    "    'lambda' : [0, 1]\n",
    "}\n",
    "grid_search = GridSearchCV(estimator = xgb,\n",
    "                          param_grid = parms,\n",
    "                          scoring = 'r2' ,\n",
    "                          n_jobs = -1,\n",
    "                          cv = 5)\n",
    "\n",
    "grid_search.fit(x, y)\n",
    "best_accuracy = grid_search.best_score_\n",
    "best_parameters = grid_search.best_params_\n",
    "print('best accuracy: {:.2f} %'.format(best_accuracy*100))    #67.88      \n",
    "print(\"best parameters : \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdc7dc6",
   "metadata": {},
   "source": [
    "# ANN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7de5a034",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 128)               2304      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 199,937\n",
      "Trainable params: 199,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x.shape[1], activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "9ee0b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "77b772a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 8967.5547 - mean_absolute_error: 8967.5547\n",
      "Epoch 00001: val_loss improved from inf to 10947.86914, saving model to Weights-001--10947.86914.hdf5\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 8967.1016 - mean_absolute_error: 8967.1016 - val_loss: 10947.8691 - val_mean_absolute_error: 10947.8691\n",
      "Epoch 2/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 8102.6113 - mean_absolute_error: 8102.6113\n",
      "Epoch 00002: val_loss improved from 10947.86914 to 10650.17969, saving model to Weights-002--10650.17969.hdf5\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 8102.5791 - mean_absolute_error: 8102.5791 - val_loss: 10650.1797 - val_mean_absolute_error: 10650.1797\n",
      "Epoch 3/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7985.0381 - mean_absolute_error: 7985.0381\n",
      "Epoch 00003: val_loss did not improve from 10650.17969\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7985.4219 - mean_absolute_error: 7985.4219 - val_loss: 11057.5752 - val_mean_absolute_error: 11057.5752\n",
      "Epoch 4/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7923.6797 - mean_absolute_error: 7923.6797\n",
      "Epoch 00004: val_loss did not improve from 10650.17969\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7922.2466 - mean_absolute_error: 7922.2466 - val_loss: 10798.9277 - val_mean_absolute_error: 10798.9277\n",
      "Epoch 5/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7858.7319 - mean_absolute_error: 7858.7319\n",
      "Epoch 00005: val_loss improved from 10650.17969 to 10393.76855, saving model to Weights-005--10393.76855.hdf5\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7858.8140 - mean_absolute_error: 7858.8140 - val_loss: 10393.7686 - val_mean_absolute_error: 10393.7686\n",
      "Epoch 6/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7830.4463 - mean_absolute_error: 7830.4463- ETA: 0s - loss: 7829.2900 - mean_absolute_error\n",
      "Epoch 00006: val_loss improved from 10393.76855 to 10261.24707, saving model to Weights-006--10261.24707.hdf5\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7831.2832 - mean_absolute_error: 7831.2832 - val_loss: 10261.2471 - val_mean_absolute_error: 10261.2471\n",
      "Epoch 7/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7801.0557 - mean_absolute_error: 7801.0557\n",
      "Epoch 00007: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7800.3398 - mean_absolute_error: 7800.3398 - val_loss: 10832.7793 - val_mean_absolute_error: 10832.7793\n",
      "Epoch 8/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7776.7944 - mean_absolute_error: 7776.7944\n",
      "Epoch 00008: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7776.0479 - mean_absolute_error: 7776.0479 - val_loss: 11450.1982 - val_mean_absolute_error: 11450.1982\n",
      "Epoch 9/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7735.6782 - mean_absolute_error: 7735.6782\n",
      "Epoch 00009: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 19s 4ms/step - loss: 7735.1582 - mean_absolute_error: 7735.1582 - val_loss: 11643.9141 - val_mean_absolute_error: 11643.9141\n",
      "Epoch 10/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7724.9849 - mean_absolute_error: 7724.9849- ETA: 1s - loss: 7720.16\n",
      "Epoch 00010: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7724.1733 - mean_absolute_error: 7724.1733 - val_loss: 11030.9736 - val_mean_absolute_error: 11030.9736\n",
      "Epoch 11/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7703.5381 - mean_absolute_error: 7703.5381\n",
      "Epoch 00011: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7703.2354 - mean_absolute_error: 7703.2354 - val_loss: 12119.3623 - val_mean_absolute_error: 12119.3623\n",
      "Epoch 12/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7677.1079 - mean_absolute_error: 7677.1079\n",
      "Epoch 00012: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7677.5195 - mean_absolute_error: 7677.5195 - val_loss: 10496.1123 - val_mean_absolute_error: 10496.1123\n",
      "Epoch 13/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7653.6655 - mean_absolute_error: 7653.6655\n",
      "Epoch 00013: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 18s 3ms/step - loss: 7653.7900 - mean_absolute_error: 7653.7900 - val_loss: 10911.6514 - val_mean_absolute_error: 10911.6514\n",
      "Epoch 14/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7639.0088 - mean_absolute_error: 7639.0088\n",
      "Epoch 00014: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7639.0088 - mean_absolute_error: 7639.0088 - val_loss: 10558.8271 - val_mean_absolute_error: 10558.8271\n",
      "Epoch 15/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7626.1436 - mean_absolute_error: 7626.1436\n",
      "Epoch 00015: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7626.2622 - mean_absolute_error: 7626.2622 - val_loss: 10731.4922 - val_mean_absolute_error: 10731.4922\n",
      "Epoch 16/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7609.6021 - mean_absolute_error: 7609.6021\n",
      "Epoch 00016: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7610.3418 - mean_absolute_error: 7610.3418 - val_loss: 11013.9658 - val_mean_absolute_error: 11013.9658\n",
      "Epoch 17/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7599.7417 - mean_absolute_error: 7599.7417\n",
      "Epoch 00017: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 18s 3ms/step - loss: 7599.8765 - mean_absolute_error: 7599.8765 - val_loss: 11318.1914 - val_mean_absolute_error: 11318.1914\n",
      "Epoch 18/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7576.3833 - mean_absolute_error: 7576.3833\n",
      "Epoch 00018: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7576.7676 - mean_absolute_error: 7576.7676 - val_loss: 10616.3457 - val_mean_absolute_error: 10616.3457\n",
      "Epoch 19/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7559.5220 - mean_absolute_error: 7559.5220\n",
      "Epoch 00019: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7560.5464 - mean_absolute_error: 7560.5464 - val_loss: 10552.4404 - val_mean_absolute_error: 10552.4404\n",
      "Epoch 20/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7558.1758 - mean_absolute_error: 7558.1758- ETA: 1s - loss: 7560.512\n",
      "Epoch 00020: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7557.9937 - mean_absolute_error: 7557.9937 - val_loss: 11698.6777 - val_mean_absolute_error: 11698.6777\n",
      "Epoch 21/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7545.9980 - mean_absolute_error: 7545.9980- ETA: 2\n",
      "Epoch 00021: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7546.0859 - mean_absolute_error: 7546.0859 - val_loss: 11083.3799 - val_mean_absolute_error: 11083.3799\n",
      "Epoch 22/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7521.6895 - mean_absolute_error: 7521.6895\n",
      "Epoch 00022: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7521.2471 - mean_absolute_error: 7521.2471 - val_loss: 11483.0137 - val_mean_absolute_error: 11483.0137\n",
      "Epoch 23/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7513.5498 - mean_absolute_error: 7513.5498\n",
      "Epoch 00023: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7513.5483 - mean_absolute_error: 7513.5483 - val_loss: 10653.3105 - val_mean_absolute_error: 10653.3105\n",
      "Epoch 24/700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5295/5298 [============================>.] - ETA: 0s - loss: 7501.2261 - mean_absolute_error: 7501.2261\n",
      "Epoch 00024: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7501.0435 - mean_absolute_error: 7501.0435 - val_loss: 10265.6006 - val_mean_absolute_error: 10265.6006\n",
      "Epoch 25/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7496.3560 - mean_absolute_error: 7496.3560\n",
      "Epoch 00025: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7496.5884 - mean_absolute_error: 7496.5884 - val_loss: 11159.1992 - val_mean_absolute_error: 11159.1992\n",
      "Epoch 26/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7495.3545 - mean_absolute_error: 7495.3545\n",
      "Epoch 00026: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7494.8384 - mean_absolute_error: 7494.8384 - val_loss: 11304.4785 - val_mean_absolute_error: 11304.4785\n",
      "Epoch 27/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7479.0918 - mean_absolute_error: 7479.0918\n",
      "Epoch 00027: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7478.7988 - mean_absolute_error: 7478.7988 - val_loss: 11159.4326 - val_mean_absolute_error: 11159.4326\n",
      "Epoch 28/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7473.4658 - mean_absolute_error: 7473.4658\n",
      "Epoch 00028: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7473.2817 - mean_absolute_error: 7473.2817 - val_loss: 10901.1689 - val_mean_absolute_error: 10901.1689\n",
      "Epoch 29/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7455.6025 - mean_absolute_error: 7455.6025\n",
      "Epoch 00029: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7457.6533 - mean_absolute_error: 7457.6533 - val_loss: 10437.5977 - val_mean_absolute_error: 10437.5977\n",
      "Epoch 30/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7448.4126 - mean_absolute_error: 7448.4126\n",
      "Epoch 00030: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7447.6284 - mean_absolute_error: 7447.6284 - val_loss: 10837.2275 - val_mean_absolute_error: 10837.2275\n",
      "Epoch 31/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7448.4663 - mean_absolute_error: 7448.4663\n",
      "Epoch 00031: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7448.1777 - mean_absolute_error: 7448.1777 - val_loss: 10873.2256 - val_mean_absolute_error: 10873.2256\n",
      "Epoch 32/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7440.4062 - mean_absolute_error: 7440.4062\n",
      "Epoch 00032: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7440.5410 - mean_absolute_error: 7440.5410 - val_loss: 10325.5020 - val_mean_absolute_error: 10325.5020\n",
      "Epoch 33/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7435.2485 - mean_absolute_error: 7435.2485\n",
      "Epoch 00033: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7435.1284 - mean_absolute_error: 7435.1284 - val_loss: 10492.2119 - val_mean_absolute_error: 10492.2119\n",
      "Epoch 34/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7432.6094 - mean_absolute_error: 7432.6094\n",
      "Epoch 00034: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7432.0371 - mean_absolute_error: 7432.0371 - val_loss: 10920.2803 - val_mean_absolute_error: 10920.2803\n",
      "Epoch 35/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7422.5405 - mean_absolute_error: 7422.5405\n",
      "Epoch 00035: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7420.9419 - mean_absolute_error: 7420.9419 - val_loss: 10877.5146 - val_mean_absolute_error: 10877.5146\n",
      "Epoch 36/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7411.5869 - mean_absolute_error: 7411.5869\n",
      "Epoch 00036: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7411.5298 - mean_absolute_error: 7411.5298 - val_loss: 11053.0625 - val_mean_absolute_error: 11053.0625\n",
      "Epoch 37/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7400.2817 - mean_absolute_error: 7400.2817\n",
      "Epoch 00037: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7400.1738 - mean_absolute_error: 7400.1738 - val_loss: 10985.5244 - val_mean_absolute_error: 10985.5244\n",
      "Epoch 38/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7397.4653 - mean_absolute_error: 7397.4653\n",
      "Epoch 00038: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7398.6968 - mean_absolute_error: 7398.6968 - val_loss: 11075.7393 - val_mean_absolute_error: 11075.7393\n",
      "Epoch 39/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7396.2388 - mean_absolute_error: 7396.2388\n",
      "Epoch 00039: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7397.3462 - mean_absolute_error: 7397.3462 - val_loss: 11677.8242 - val_mean_absolute_error: 11677.8242\n",
      "Epoch 40/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7387.7944 - mean_absolute_error: 7387.7944\n",
      "Epoch 00040: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7387.2432 - mean_absolute_error: 7387.2432 - val_loss: 10849.9521 - val_mean_absolute_error: 10849.9521\n",
      "Epoch 41/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7378.4614 - mean_absolute_error: 7378.4614\n",
      "Epoch 00041: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7378.6602 - mean_absolute_error: 7378.6602 - val_loss: 11149.2549 - val_mean_absolute_error: 11149.2549\n",
      "Epoch 42/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7370.3774 - mean_absolute_error: 7370.3774\n",
      "Epoch 00042: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7369.3657 - mean_absolute_error: 7369.3657 - val_loss: 10709.2871 - val_mean_absolute_error: 10709.2871\n",
      "Epoch 43/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7366.4028 - mean_absolute_error: 7366.4028\n",
      "Epoch 00043: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7364.9355 - mean_absolute_error: 7364.9355 - val_loss: 10882.3311 - val_mean_absolute_error: 10882.3311\n",
      "Epoch 44/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7365.6094 - mean_absolute_error: 7365.6094\n",
      "Epoch 00044: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7365.5811 - mean_absolute_error: 7365.5811 - val_loss: 11460.4629 - val_mean_absolute_error: 11460.4629\n",
      "Epoch 45/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7358.8081 - mean_absolute_error: 7358.8081\n",
      "Epoch 00045: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7357.9092 - mean_absolute_error: 7357.9092 - val_loss: 10521.3486 - val_mean_absolute_error: 10521.3486\n",
      "Epoch 46/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7360.6440 - mean_absolute_error: 7360.6440\n",
      "Epoch 00046: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7360.5762 - mean_absolute_error: 7360.5762 - val_loss: 11440.5322 - val_mean_absolute_error: 11440.5322\n",
      "Epoch 47/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7341.8418 - mean_absolute_error: 7341.8418\n",
      "Epoch 00047: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7343.1343 - mean_absolute_error: 7343.1343 - val_loss: 11659.9004 - val_mean_absolute_error: 11659.9004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7342.0820 - mean_absolute_error: 7342.0820\n",
      "Epoch 00048: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7341.7349 - mean_absolute_error: 7341.7349 - val_loss: 11158.5781 - val_mean_absolute_error: 11158.5781\n",
      "Epoch 49/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7335.3794 - mean_absolute_error: 7335.3794\n",
      "Epoch 00049: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7335.0933 - mean_absolute_error: 7335.0933 - val_loss: 10603.0938 - val_mean_absolute_error: 10603.0938\n",
      "Epoch 50/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7335.6860 - mean_absolute_error: 7335.6860\n",
      "Epoch 00050: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7335.6128 - mean_absolute_error: 7335.6128 - val_loss: 11336.4102 - val_mean_absolute_error: 11336.4102\n",
      "Epoch 51/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7324.6665 - mean_absolute_error: 7324.6665\n",
      "Epoch 00051: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7325.2085 - mean_absolute_error: 7325.2085 - val_loss: 11296.5391 - val_mean_absolute_error: 11296.5391\n",
      "Epoch 52/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7314.4185 - mean_absolute_error: 7314.4185\n",
      "Epoch 00052: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7315.0581 - mean_absolute_error: 7315.0581 - val_loss: 11435.7256 - val_mean_absolute_error: 11435.7256\n",
      "Epoch 53/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7314.6934 - mean_absolute_error: 7314.6934\n",
      "Epoch 00053: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7314.7808 - mean_absolute_error: 7314.7808 - val_loss: 10989.6377 - val_mean_absolute_error: 10989.6377\n",
      "Epoch 54/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7308.9443 - mean_absolute_error: 7308.9443\n",
      "Epoch 00054: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7310.3076 - mean_absolute_error: 7310.3076 - val_loss: 11473.9473 - val_mean_absolute_error: 11473.9473\n",
      "Epoch 55/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7306.5391 - mean_absolute_error: 7306.5391\n",
      "Epoch 00055: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7306.5864 - mean_absolute_error: 7306.5864 - val_loss: 10797.6943 - val_mean_absolute_error: 10797.6943\n",
      "Epoch 56/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7296.9404 - mean_absolute_error: 7296.9404\n",
      "Epoch 00056: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7296.6519 - mean_absolute_error: 7296.6519 - val_loss: 11481.8965 - val_mean_absolute_error: 11481.8965\n",
      "Epoch 57/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7296.3398 - mean_absolute_error: 7296.3398\n",
      "Epoch 00057: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7296.8267 - mean_absolute_error: 7296.8267 - val_loss: 12054.2285 - val_mean_absolute_error: 12054.2285\n",
      "Epoch 58/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7293.7476 - mean_absolute_error: 7293.7476\n",
      "Epoch 00058: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7296.0908 - mean_absolute_error: 7296.0908 - val_loss: 10924.3662 - val_mean_absolute_error: 10924.3662\n",
      "Epoch 59/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7291.3237 - mean_absolute_error: 7291.3237\n",
      "Epoch 00059: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7292.2656 - mean_absolute_error: 7292.2656 - val_loss: 10931.1885 - val_mean_absolute_error: 10931.1885\n",
      "Epoch 60/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7287.6064 - mean_absolute_error: 7287.6064\n",
      "Epoch 00060: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7287.5815 - mean_absolute_error: 7287.5815 - val_loss: 10459.2939 - val_mean_absolute_error: 10459.2939\n",
      "Epoch 61/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7298.1802 - mean_absolute_error: 7298.1802\n",
      "Epoch 00061: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7298.2256 - mean_absolute_error: 7298.2256 - val_loss: 11475.4053 - val_mean_absolute_error: 11475.4053\n",
      "Epoch 62/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7276.5845 - mean_absolute_error: 7276.5845\n",
      "Epoch 00062: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7277.2974 - mean_absolute_error: 7277.2974 - val_loss: 10576.4121 - val_mean_absolute_error: 10576.4121\n",
      "Epoch 63/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7283.3481 - mean_absolute_error: 7283.3481\n",
      "Epoch 00063: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7283.1143 - mean_absolute_error: 7283.1143 - val_loss: 11130.6631 - val_mean_absolute_error: 11130.6631\n",
      "Epoch 64/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7270.6074 - mean_absolute_error: 7270.6074\n",
      "Epoch 00064: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7271.0820 - mean_absolute_error: 7271.0820 - val_loss: 11370.5068 - val_mean_absolute_error: 11370.5068\n",
      "Epoch 65/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7270.6284 - mean_absolute_error: 7270.6284\n",
      "Epoch 00065: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7269.1680 - mean_absolute_error: 7269.1680 - val_loss: 11221.5684 - val_mean_absolute_error: 11221.5684\n",
      "Epoch 66/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7263.7852 - mean_absolute_error: 7263.7852\n",
      "Epoch 00066: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7263.7852 - mean_absolute_error: 7263.7852 - val_loss: 10628.3594 - val_mean_absolute_error: 10628.3594\n",
      "Epoch 67/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7268.6650 - mean_absolute_error: 7268.6650\n",
      "Epoch 00067: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7268.4800 - mean_absolute_error: 7268.4800 - val_loss: 10619.4824 - val_mean_absolute_error: 10619.4824\n",
      "Epoch 68/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7256.4297 - mean_absolute_error: 7256.4297\n",
      "Epoch 00068: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7256.4990 - mean_absolute_error: 7256.4990 - val_loss: 10903.6377 - val_mean_absolute_error: 10903.6377\n",
      "Epoch 69/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7257.7788 - mean_absolute_error: 7257.7788\n",
      "Epoch 00069: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7256.7007 - mean_absolute_error: 7256.7007 - val_loss: 11589.7041 - val_mean_absolute_error: 11589.7041\n",
      "Epoch 70/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7252.7173 - mean_absolute_error: 7252.7173\n",
      "Epoch 00070: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7252.4375 - mean_absolute_error: 7252.4375 - val_loss: 10791.6855 - val_mean_absolute_error: 10791.6855\n",
      "Epoch 71/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7248.3501 - mean_absolute_error: 7248.3501\n",
      "Epoch 00071: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7249.3789 - mean_absolute_error: 7249.3789 - val_loss: 10565.5127 - val_mean_absolute_error: 10565.5127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 72/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7239.7798 - mean_absolute_error: 7239.7798\n",
      "Epoch 00072: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7238.7964 - mean_absolute_error: 7238.7964 - val_loss: 10877.1924 - val_mean_absolute_error: 10877.1924\n",
      "Epoch 73/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7240.0605 - mean_absolute_error: 7240.0605\n",
      "Epoch 00073: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7240.3623 - mean_absolute_error: 7240.3623 - val_loss: 10685.0742 - val_mean_absolute_error: 10685.0742\n",
      "Epoch 74/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7236.4478 - mean_absolute_error: 7236.4478\n",
      "Epoch 00074: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7235.0161 - mean_absolute_error: 7235.0161 - val_loss: 11272.7363 - val_mean_absolute_error: 11272.7363\n",
      "Epoch 75/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7235.1108 - mean_absolute_error: 7235.1108\n",
      "Epoch 00075: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7234.4829 - mean_absolute_error: 7234.4829 - val_loss: 11362.8311 - val_mean_absolute_error: 11362.8311\n",
      "Epoch 76/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7232.2979 - mean_absolute_error: 7232.2979\n",
      "Epoch 00076: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7234.2798 - mean_absolute_error: 7234.2798 - val_loss: 10871.2998 - val_mean_absolute_error: 10871.2998\n",
      "Epoch 77/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7226.9404 - mean_absolute_error: 7226.9404\n",
      "Epoch 00077: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7226.1372 - mean_absolute_error: 7226.1372 - val_loss: 11126.7490 - val_mean_absolute_error: 11126.7490\n",
      "Epoch 78/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7218.7593 - mean_absolute_error: 7218.7593\n",
      "Epoch 00078: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7220.2964 - mean_absolute_error: 7220.2964 - val_loss: 10890.9795 - val_mean_absolute_error: 10890.9795\n",
      "Epoch 79/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7219.4165 - mean_absolute_error: 7219.4165\n",
      "Epoch 00079: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7219.3877 - mean_absolute_error: 7219.3877 - val_loss: 11124.3574 - val_mean_absolute_error: 11124.3574\n",
      "Epoch 80/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7217.2778 - mean_absolute_error: 7217.2778\n",
      "Epoch 00080: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7217.9414 - mean_absolute_error: 7217.9414 - val_loss: 10391.4824 - val_mean_absolute_error: 10391.4824\n",
      "Epoch 81/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7211.8140 - mean_absolute_error: 7211.8140\n",
      "Epoch 00081: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7212.0117 - mean_absolute_error: 7212.0117 - val_loss: 10779.5586 - val_mean_absolute_error: 10779.5586\n",
      "Epoch 82/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7215.5078 - mean_absolute_error: 7215.5078\n",
      "Epoch 00082: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7215.9595 - mean_absolute_error: 7215.9595 - val_loss: 11718.8828 - val_mean_absolute_error: 11718.8828\n",
      "Epoch 83/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7208.3091 - mean_absolute_error: 7208.3091\n",
      "Epoch 00083: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7209.2363 - mean_absolute_error: 7209.2363 - val_loss: 11104.5078 - val_mean_absolute_error: 11104.5078\n",
      "Epoch 84/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7210.2583 - mean_absolute_error: 7210.2583\n",
      "Epoch 00084: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7209.6714 - mean_absolute_error: 7209.6714 - val_loss: 10637.1934 - val_mean_absolute_error: 10637.1934\n",
      "Epoch 85/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7200.0347 - mean_absolute_error: 7200.0347\n",
      "Epoch 00085: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7203.2349 - mean_absolute_error: 7203.2349 - val_loss: 10800.9580 - val_mean_absolute_error: 10800.9580\n",
      "Epoch 86/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7202.3989 - mean_absolute_error: 7202.3989\n",
      "Epoch 00086: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7202.2808 - mean_absolute_error: 7202.2808 - val_loss: 10348.4336 - val_mean_absolute_error: 10348.4336\n",
      "Epoch 87/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7203.2261 - mean_absolute_error: 7203.2261\n",
      "Epoch 00087: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7203.0708 - mean_absolute_error: 7203.0708 - val_loss: 10915.7988 - val_mean_absolute_error: 10915.7988\n",
      "Epoch 88/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7191.9453 - mean_absolute_error: 7191.9453\n",
      "Epoch 00088: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7192.3975 - mean_absolute_error: 7192.3975 - val_loss: 10667.8613 - val_mean_absolute_error: 10667.8613\n",
      "Epoch 89/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 7189.8647 - mean_absolute_error: 7189.8647\n",
      "Epoch 00089: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7189.3174 - mean_absolute_error: 7189.3174 - val_loss: 11352.5586 - val_mean_absolute_error: 11352.5586\n",
      "Epoch 90/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7197.2046 - mean_absolute_error: 7197.2046\n",
      "Epoch 00090: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7196.8115 - mean_absolute_error: 7196.8115 - val_loss: 10985.7891 - val_mean_absolute_error: 10985.7891\n",
      "Epoch 91/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7191.2866 - mean_absolute_error: 7191.2866\n",
      "Epoch 00091: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7191.7783 - mean_absolute_error: 7191.7783 - val_loss: 10560.4365 - val_mean_absolute_error: 10560.4365\n",
      "Epoch 92/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7189.0137 - mean_absolute_error: 7189.0137- ETA: 8s - loss: 71\n",
      "Epoch 00092: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 20s 4ms/step - loss: 7189.3574 - mean_absolute_error: 7189.3574 - val_loss: 11095.3047 - val_mean_absolute_error: 11095.3047\n",
      "Epoch 93/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7189.9585 - mean_absolute_error: 7189.9585\n",
      "Epoch 00093: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7190.8203 - mean_absolute_error: 7190.8203 - val_loss: 10906.6797 - val_mean_absolute_error: 10906.6797\n",
      "Epoch 94/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7186.4956 - mean_absolute_error: 7186.4956\n",
      "Epoch 00094: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7186.7310 - mean_absolute_error: 7186.7310 - val_loss: 10328.4951 - val_mean_absolute_error: 10328.4951\n",
      "Epoch 95/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7182.4478 - mean_absolute_error: 7182.4478\n",
      "Epoch 00095: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 18s 3ms/step - loss: 7182.1021 - mean_absolute_error: 7182.1021 - val_loss: 10922.8770 - val_mean_absolute_error: 10922.8770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 96/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7179.7412 - mean_absolute_error: 7179.7412\n",
      "Epoch 00096: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7179.0029 - mean_absolute_error: 7179.0029 - val_loss: 10571.8691 - val_mean_absolute_error: 10571.8691\n",
      "Epoch 97/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7176.0259 - mean_absolute_error: 7176.0259\n",
      "Epoch 00097: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7177.8213 - mean_absolute_error: 7177.8213 - val_loss: 11035.3408 - val_mean_absolute_error: 11035.3408\n",
      "Epoch 98/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7176.0332 - mean_absolute_error: 7176.0332\n",
      "Epoch 00098: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7175.0742 - mean_absolute_error: 7175.0742 - val_loss: 11057.4717 - val_mean_absolute_error: 11057.4717\n",
      "Epoch 99/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7177.6045 - mean_absolute_error: 7177.6045\n",
      "Epoch 00099: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7177.0615 - mean_absolute_error: 7177.0615 - val_loss: 10756.9678 - val_mean_absolute_error: 10756.9678\n",
      "Epoch 100/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7175.3823 - mean_absolute_error: 7175.3823\n",
      "Epoch 00100: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7174.7100 - mean_absolute_error: 7174.7100 - val_loss: 10958.5430 - val_mean_absolute_error: 10958.5430\n",
      "Epoch 101/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7176.5913 - mean_absolute_error: 7176.5913\n",
      "Epoch 00101: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7176.2354 - mean_absolute_error: 7176.2354 - val_loss: 11159.1982 - val_mean_absolute_error: 11159.1982\n",
      "Epoch 102/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7168.3574 - mean_absolute_error: 7168.3574\n",
      "Epoch 00102: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7168.3574 - mean_absolute_error: 7168.3574 - val_loss: 10786.8506 - val_mean_absolute_error: 10786.8506\n",
      "Epoch 103/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7178.2393 - mean_absolute_error: 7178.2393\n",
      "Epoch 00103: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7178.8066 - mean_absolute_error: 7178.8066 - val_loss: 11037.0410 - val_mean_absolute_error: 11037.0410\n",
      "Epoch 104/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7166.4189 - mean_absolute_error: 7166.4189\n",
      "Epoch 00104: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7166.7563 - mean_absolute_error: 7166.7563 - val_loss: 11351.6523 - val_mean_absolute_error: 11351.6523\n",
      "Epoch 105/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7166.2524 - mean_absolute_error: 7166.2524\n",
      "Epoch 00105: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7166.2524 - mean_absolute_error: 7166.2524 - val_loss: 10997.6045 - val_mean_absolute_error: 10997.6045\n",
      "Epoch 106/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7164.1406 - mean_absolute_error: 7164.1406\n",
      "Epoch 00106: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7164.3643 - mean_absolute_error: 7164.3643 - val_loss: 10512.4922 - val_mean_absolute_error: 10512.4922\n",
      "Epoch 107/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7166.0161 - mean_absolute_error: 7166.0161\n",
      "Epoch 00107: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7166.1567 - mean_absolute_error: 7166.1567 - val_loss: 10930.5029 - val_mean_absolute_error: 10930.5029\n",
      "Epoch 108/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7154.4189 - mean_absolute_error: 7154.4189\n",
      "Epoch 00108: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7155.3184 - mean_absolute_error: 7155.3184 - val_loss: 10699.1279 - val_mean_absolute_error: 10699.1279\n",
      "Epoch 109/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7157.7456 - mean_absolute_error: 7157.7456\n",
      "Epoch 00109: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7158.7188 - mean_absolute_error: 7158.7188 - val_loss: 10573.8994 - val_mean_absolute_error: 10573.8994\n",
      "Epoch 110/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7154.0918 - mean_absolute_error: 7154.0918\n",
      "Epoch 00110: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7154.5488 - mean_absolute_error: 7154.5488 - val_loss: 10962.2432 - val_mean_absolute_error: 10962.2432\n",
      "Epoch 111/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7162.6509 - mean_absolute_error: 7162.6509\n",
      "Epoch 00111: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7162.9355 - mean_absolute_error: 7162.9355 - val_loss: 10738.6094 - val_mean_absolute_error: 10738.6094\n",
      "Epoch 112/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7166.5737 - mean_absolute_error: 7166.5737\n",
      "Epoch 00112: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7165.8862 - mean_absolute_error: 7165.8862 - val_loss: 10842.8896 - val_mean_absolute_error: 10842.8896\n",
      "Epoch 113/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7156.8691 - mean_absolute_error: 7156.8691\n",
      "Epoch 00113: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7156.7759 - mean_absolute_error: 7156.7759 - val_loss: 11420.3721 - val_mean_absolute_error: 11420.3721\n",
      "Epoch 114/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7155.3130 - mean_absolute_error: 7155.3130\n",
      "Epoch 00114: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7154.5547 - mean_absolute_error: 7154.5547 - val_loss: 10915.5654 - val_mean_absolute_error: 10915.5654\n",
      "Epoch 115/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7142.2910 - mean_absolute_error: 7142.2910\n",
      "Epoch 00115: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 17s 3ms/step - loss: 7142.2368 - mean_absolute_error: 7142.2368 - val_loss: 11283.6885 - val_mean_absolute_error: 11283.6885\n",
      "Epoch 116/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7150.5239 - mean_absolute_error: 7150.5239\n",
      "Epoch 00116: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7153.1089 - mean_absolute_error: 7153.1089 - val_loss: 10621.0293 - val_mean_absolute_error: 10621.0293\n",
      "Epoch 117/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7147.3794 - mean_absolute_error: 7147.3794\n",
      "Epoch 00117: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7148.9971 - mean_absolute_error: 7148.9971 - val_loss: 10588.7607 - val_mean_absolute_error: 10588.7607\n",
      "Epoch 118/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7147.0781 - mean_absolute_error: 7147.0781\n",
      "Epoch 00118: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7146.4092 - mean_absolute_error: 7146.4092 - val_loss: 10560.5732 - val_mean_absolute_error: 10560.5732\n",
      "Epoch 119/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7139.2222 - mean_absolute_error: 7139.2222\n",
      "Epoch 00119: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7138.3882 - mean_absolute_error: 7138.3882 - val_loss: 11427.8848 - val_mean_absolute_error: 11427.8848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7143.7754 - mean_absolute_error: 7143.7754\n",
      "Epoch 00120: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7143.0254 - mean_absolute_error: 7143.0254 - val_loss: 11109.7080 - val_mean_absolute_error: 11109.7080\n",
      "Epoch 121/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7146.0874 - mean_absolute_error: 7146.0874\n",
      "Epoch 00121: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7145.9629 - mean_absolute_error: 7145.9629 - val_loss: 10997.8418 - val_mean_absolute_error: 10997.8418\n",
      "Epoch 122/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7135.6968 - mean_absolute_error: 7135.6968\n",
      "Epoch 00122: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7135.6968 - mean_absolute_error: 7135.6968 - val_loss: 10995.7490 - val_mean_absolute_error: 10995.7490\n",
      "Epoch 123/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7133.4922 - mean_absolute_error: 7133.4922\n",
      "Epoch 00123: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7132.9385 - mean_absolute_error: 7132.9385 - val_loss: 11225.9375 - val_mean_absolute_error: 11225.9375\n",
      "Epoch 124/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7139.2339 - mean_absolute_error: 7139.2339\n",
      "Epoch 00124: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7139.5156 - mean_absolute_error: 7139.5156 - val_loss: 10479.4893 - val_mean_absolute_error: 10479.4893\n",
      "Epoch 125/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7139.6963 - mean_absolute_error: 7139.6963- ETA: 2s - loss: 7\n",
      "Epoch 00125: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7139.3252 - mean_absolute_error: 7139.3252 - val_loss: 11090.6250 - val_mean_absolute_error: 11090.6250\n",
      "Epoch 126/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7138.0522 - mean_absolute_error: 7138.0522\n",
      "Epoch 00126: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7137.2729 - mean_absolute_error: 7137.2729 - val_loss: 11155.9355 - val_mean_absolute_error: 11155.9355\n",
      "Epoch 127/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7125.2666 - mean_absolute_error: 7125.2666\n",
      "Epoch 00127: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7125.2095 - mean_absolute_error: 7125.2095 - val_loss: 10706.6436 - val_mean_absolute_error: 10706.6436\n",
      "Epoch 128/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7136.2739 - mean_absolute_error: 7136.2739\n",
      "Epoch 00128: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7136.2354 - mean_absolute_error: 7136.2354 - val_loss: 11272.3223 - val_mean_absolute_error: 11272.3223\n",
      "Epoch 129/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7131.5786 - mean_absolute_error: 7131.5786\n",
      "Epoch 00129: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7131.5483 - mean_absolute_error: 7131.5483 - val_loss: 11092.9580 - val_mean_absolute_error: 11092.9580\n",
      "Epoch 130/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7149.6646 - mean_absolute_error: 7149.6646\n",
      "Epoch 00130: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7150.0264 - mean_absolute_error: 7150.0264 - val_loss: 10862.2812 - val_mean_absolute_error: 10862.2812\n",
      "Epoch 131/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7124.6499 - mean_absolute_error: 7124.6499\n",
      "Epoch 00131: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7124.2598 - mean_absolute_error: 7124.2598 - val_loss: 10539.8096 - val_mean_absolute_error: 10539.8096\n",
      "Epoch 132/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7130.9688 - mean_absolute_error: 7130.9688\n",
      "Epoch 00132: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7130.9072 - mean_absolute_error: 7130.9072 - val_loss: 10646.2295 - val_mean_absolute_error: 10646.2295\n",
      "Epoch 133/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7124.2954 - mean_absolute_error: 7124.2954\n",
      "Epoch 00133: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 16s 3ms/step - loss: 7122.8965 - mean_absolute_error: 7122.8965 - val_loss: 11217.3467 - val_mean_absolute_error: 11217.3467\n",
      "Epoch 134/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7125.5356 - mean_absolute_error: 7125.5356\n",
      "Epoch 00134: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7124.5903 - mean_absolute_error: 7124.5903 - val_loss: 11043.7598 - val_mean_absolute_error: 11043.7598\n",
      "Epoch 135/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7123.9438 - mean_absolute_error: 7123.9438\n",
      "Epoch 00135: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7123.6592 - mean_absolute_error: 7123.6592 - val_loss: 11000.0439 - val_mean_absolute_error: 11000.0439\n",
      "Epoch 136/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7132.8599 - mean_absolute_error: 7132.8599\n",
      "Epoch 00136: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7132.6665 - mean_absolute_error: 7132.6665 - val_loss: 11149.8350 - val_mean_absolute_error: 11149.8350\n",
      "Epoch 137/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7116.4785 - mean_absolute_error: 7116.4785\n",
      "Epoch 00137: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7116.8628 - mean_absolute_error: 7116.8628 - val_loss: 11115.6152 - val_mean_absolute_error: 11115.6152\n",
      "Epoch 138/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7116.9087 - mean_absolute_error: 7116.9087\n",
      "Epoch 00138: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7117.4922 - mean_absolute_error: 7117.4922 - val_loss: 10880.6152 - val_mean_absolute_error: 10880.6152\n",
      "Epoch 139/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7118.2710 - mean_absolute_error: 7118.2710\n",
      "Epoch 00139: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7117.9639 - mean_absolute_error: 7117.9639 - val_loss: 11819.4229 - val_mean_absolute_error: 11819.4229\n",
      "Epoch 140/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7116.2837 - mean_absolute_error: 7116.2837\n",
      "Epoch 00140: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7116.2393 - mean_absolute_error: 7116.2393 - val_loss: 10790.8223 - val_mean_absolute_error: 10790.8223\n",
      "Epoch 141/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7120.1196 - mean_absolute_error: 7120.1196\n",
      "Epoch 00141: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7121.3105 - mean_absolute_error: 7121.3105 - val_loss: 11026.6094 - val_mean_absolute_error: 11026.6094\n",
      "Epoch 142/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7121.1348 - mean_absolute_error: 7121.1348\n",
      "Epoch 00142: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7121.0244 - mean_absolute_error: 7121.0244 - val_loss: 10632.2012 - val_mean_absolute_error: 10632.2012\n",
      "Epoch 143/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7115.8726 - mean_absolute_error: 7115.8726\n",
      "Epoch 00143: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7116.6826 - mean_absolute_error: 7116.6826 - val_loss: 10941.0068 - val_mean_absolute_error: 10941.0068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 144/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7108.5430 - mean_absolute_error: 7108.5430\n",
      "Epoch 00144: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7108.0806 - mean_absolute_error: 7108.0806 - val_loss: 10902.0176 - val_mean_absolute_error: 10902.0176\n",
      "Epoch 145/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7111.9658 - mean_absolute_error: 7111.9658\n",
      "Epoch 00145: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7112.1606 - mean_absolute_error: 7112.1606 - val_loss: 10817.5244 - val_mean_absolute_error: 10817.5244\n",
      "Epoch 146/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7107.2944 - mean_absolute_error: 7107.2944\n",
      "Epoch 00146: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7107.1738 - mean_absolute_error: 7107.1738 - val_loss: 10996.5527 - val_mean_absolute_error: 10996.5527\n",
      "Epoch 147/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7109.7285 - mean_absolute_error: 7109.7285\n",
      "Epoch 00147: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7109.6226 - mean_absolute_error: 7109.6226 - val_loss: 10701.7051 - val_mean_absolute_error: 10701.7051\n",
      "Epoch 148/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7104.8359 - mean_absolute_error: 7104.8359\n",
      "Epoch 00148: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7104.8359 - mean_absolute_error: 7104.8359 - val_loss: 10516.1660 - val_mean_absolute_error: 10516.1660\n",
      "Epoch 149/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7109.1523 - mean_absolute_error: 7109.1523\n",
      "Epoch 00149: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7109.5562 - mean_absolute_error: 7109.5562 - val_loss: 10695.2969 - val_mean_absolute_error: 10695.2969\n",
      "Epoch 150/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 7117.2026 - mean_absolute_error: 7117.2026\n",
      "Epoch 00150: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7116.5479 - mean_absolute_error: 7116.5479 - val_loss: 11108.9209 - val_mean_absolute_error: 11108.9209\n",
      "Epoch 151/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7112.5947 - mean_absolute_error: 7112.5947\n",
      "Epoch 00151: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7112.8389 - mean_absolute_error: 7112.8389 - val_loss: 11008.8838 - val_mean_absolute_error: 11008.8838\n",
      "Epoch 152/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7103.9688 - mean_absolute_error: 7103.9688\n",
      "Epoch 00152: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7104.4946 - mean_absolute_error: 7104.4946 - val_loss: 10840.9434 - val_mean_absolute_error: 10840.9434\n",
      "Epoch 153/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7106.4185 - mean_absolute_error: 7106.4185\n",
      "Epoch 00153: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7104.4492 - mean_absolute_error: 7104.4492 - val_loss: 11056.3047 - val_mean_absolute_error: 11056.3047\n",
      "Epoch 154/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7107.2314 - mean_absolute_error: 7107.2314\n",
      "Epoch 00154: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7105.3848 - mean_absolute_error: 7105.3848 - val_loss: 11294.8330 - val_mean_absolute_error: 11294.8330\n",
      "Epoch 155/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7103.1030 - mean_absolute_error: 7103.1030\n",
      "Epoch 00155: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7102.2539 - mean_absolute_error: 7102.2539 - val_loss: 10640.5703 - val_mean_absolute_error: 10640.5703\n",
      "Epoch 156/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7100.3262 - mean_absolute_error: 7100.3262\n",
      "Epoch 00156: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7100.7144 - mean_absolute_error: 7100.7144 - val_loss: 10853.3291 - val_mean_absolute_error: 10853.3291\n",
      "Epoch 157/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7098.3281 - mean_absolute_error: 7098.3281\n",
      "Epoch 00157: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7098.9429 - mean_absolute_error: 7098.9429 - val_loss: 10949.3389 - val_mean_absolute_error: 10949.3389\n",
      "Epoch 158/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7104.0288 - mean_absolute_error: 7104.0288\n",
      "Epoch 00158: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7104.8140 - mean_absolute_error: 7104.8140 - val_loss: 11168.0469 - val_mean_absolute_error: 11168.0469\n",
      "Epoch 159/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7098.0845 - mean_absolute_error: 7098.0845\n",
      "Epoch 00159: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7098.0679 - mean_absolute_error: 7098.0679 - val_loss: 11270.2451 - val_mean_absolute_error: 11270.2451\n",
      "Epoch 160/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7098.7603 - mean_absolute_error: 7098.7603\n",
      "Epoch 00160: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7099.0703 - mean_absolute_error: 7099.0703 - val_loss: 10757.4248 - val_mean_absolute_error: 10757.4248\n",
      "Epoch 161/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 7102.7007 - mean_absolute_error: 7102.7007\n",
      "Epoch 00161: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7101.1289 - mean_absolute_error: 7101.1289 - val_loss: 10998.7627 - val_mean_absolute_error: 10998.7627\n",
      "Epoch 162/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7099.7090 - mean_absolute_error: 7099.7090\n",
      "Epoch 00162: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7099.1694 - mean_absolute_error: 7099.1694 - val_loss: 10492.0254 - val_mean_absolute_error: 10492.0254\n",
      "Epoch 163/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 7098.2056 - mean_absolute_error: 7098.2056\n",
      "Epoch 00163: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7098.8198 - mean_absolute_error: 7098.8198 - val_loss: 11128.6396 - val_mean_absolute_error: 11128.6396\n",
      "Epoch 164/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7089.9585 - mean_absolute_error: 7089.9585\n",
      "Epoch 00164: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7089.2363 - mean_absolute_error: 7089.2363 - val_loss: 11044.1660 - val_mean_absolute_error: 11044.1660\n",
      "Epoch 165/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7097.5757 - mean_absolute_error: 7097.5757\n",
      "Epoch 00165: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7097.5376 - mean_absolute_error: 7097.5376 - val_loss: 11029.6787 - val_mean_absolute_error: 11029.6787\n",
      "Epoch 166/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7089.2021 - mean_absolute_error: 7089.2021\n",
      "Epoch 00166: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7089.2363 - mean_absolute_error: 7089.2363 - val_loss: 11182.2861 - val_mean_absolute_error: 11182.2861\n",
      "Epoch 167/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7088.0469 - mean_absolute_error: 7088.0469\n",
      "Epoch 00167: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7088.9375 - mean_absolute_error: 7088.9375 - val_loss: 10734.4072 - val_mean_absolute_error: 10734.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 168/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7093.4697 - mean_absolute_error: 7093.4697\n",
      "Epoch 00168: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7093.5269 - mean_absolute_error: 7093.5269 - val_loss: 11101.1094 - val_mean_absolute_error: 11101.1094\n",
      "Epoch 169/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7088.0977 - mean_absolute_error: 7088.0977\n",
      "Epoch 00169: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7086.9937 - mean_absolute_error: 7086.9937 - val_loss: 10799.5693 - val_mean_absolute_error: 10799.5693\n",
      "Epoch 170/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7092.5146 - mean_absolute_error: 7092.5146\n",
      "Epoch 00170: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7092.1958 - mean_absolute_error: 7092.1958 - val_loss: 11389.3770 - val_mean_absolute_error: 11389.3770\n",
      "Epoch 171/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7097.1235 - mean_absolute_error: 7097.1235\n",
      "Epoch 00171: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7096.2544 - mean_absolute_error: 7096.2544 - val_loss: 10501.9854 - val_mean_absolute_error: 10501.9854\n",
      "Epoch 172/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7088.9922 - mean_absolute_error: 7088.9922\n",
      "Epoch 00172: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7088.1875 - mean_absolute_error: 7088.1875 - val_loss: 11527.4717 - val_mean_absolute_error: 11527.4717\n",
      "Epoch 173/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7082.5210 - mean_absolute_error: 7082.5210\n",
      "Epoch 00173: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7081.9185 - mean_absolute_error: 7081.9185 - val_loss: 10882.1670 - val_mean_absolute_error: 10882.1670\n",
      "Epoch 174/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7087.1636 - mean_absolute_error: 7087.1636\n",
      "Epoch 00174: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7086.4409 - mean_absolute_error: 7086.4409 - val_loss: 10888.5254 - val_mean_absolute_error: 10888.5254\n",
      "Epoch 175/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7080.1030 - mean_absolute_error: 7080.1030\n",
      "Epoch 00175: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7080.5713 - mean_absolute_error: 7080.5713 - val_loss: 10803.2744 - val_mean_absolute_error: 10803.2744\n",
      "Epoch 176/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7076.8257 - mean_absolute_error: 7076.8257\n",
      "Epoch 00176: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7076.2783 - mean_absolute_error: 7076.2783 - val_loss: 10826.5898 - val_mean_absolute_error: 10826.5898\n",
      "Epoch 177/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7074.3628 - mean_absolute_error: 7074.3628\n",
      "Epoch 00177: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7074.9067 - mean_absolute_error: 7074.9067 - val_loss: 10828.1436 - val_mean_absolute_error: 10828.1436\n",
      "Epoch 178/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7082.5239 - mean_absolute_error: 7082.5239\n",
      "Epoch 00178: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7082.5239 - mean_absolute_error: 7082.5239 - val_loss: 10554.7939 - val_mean_absolute_error: 10554.7939\n",
      "Epoch 179/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7078.7651 - mean_absolute_error: 7078.7651\n",
      "Epoch 00179: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7078.0845 - mean_absolute_error: 7078.0845 - val_loss: 11215.0869 - val_mean_absolute_error: 11215.0869\n",
      "Epoch 180/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7082.6177 - mean_absolute_error: 7082.6177\n",
      "Epoch 00180: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7082.7349 - mean_absolute_error: 7082.7349 - val_loss: 10695.8799 - val_mean_absolute_error: 10695.8799\n",
      "Epoch 181/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7074.0376 - mean_absolute_error: 7074.0376\n",
      "Epoch 00181: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7075.4590 - mean_absolute_error: 7075.4590 - val_loss: 11495.9531 - val_mean_absolute_error: 11495.9531\n",
      "Epoch 182/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7075.5498 - mean_absolute_error: 7075.5498\n",
      "Epoch 00182: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7075.4868 - mean_absolute_error: 7075.4868 - val_loss: 10959.3320 - val_mean_absolute_error: 10959.3320\n",
      "Epoch 183/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7073.2817 - mean_absolute_error: 7073.2817\n",
      "Epoch 00183: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7072.6870 - mean_absolute_error: 7072.6870 - val_loss: 10933.0410 - val_mean_absolute_error: 10933.0410\n",
      "Epoch 184/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7076.9155 - mean_absolute_error: 7076.9155\n",
      "Epoch 00184: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7075.9756 - mean_absolute_error: 7075.9756 - val_loss: 11124.3926 - val_mean_absolute_error: 11124.3926\n",
      "Epoch 185/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7075.9185 - mean_absolute_error: 7075.9185\n",
      "Epoch 00185: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7076.9556 - mean_absolute_error: 7076.9556 - val_loss: 11062.8984 - val_mean_absolute_error: 11062.8984\n",
      "Epoch 186/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7067.6753 - mean_absolute_error: 7067.6753\n",
      "Epoch 00186: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7066.6577 - mean_absolute_error: 7066.6577 - val_loss: 10632.1211 - val_mean_absolute_error: 10632.1211\n",
      "Epoch 187/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7075.8506 - mean_absolute_error: 7075.8506\n",
      "Epoch 00187: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7075.5879 - mean_absolute_error: 7075.5879 - val_loss: 11292.8223 - val_mean_absolute_error: 11292.8223\n",
      "Epoch 188/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7073.6748 - mean_absolute_error: 7073.6748\n",
      "Epoch 00188: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7073.3423 - mean_absolute_error: 7073.3423 - val_loss: 10728.3945 - val_mean_absolute_error: 10728.3945\n",
      "Epoch 189/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7076.0347 - mean_absolute_error: 7076.0347\n",
      "Epoch 00189: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7074.8267 - mean_absolute_error: 7074.8267 - val_loss: 11119.5820 - val_mean_absolute_error: 11119.5820\n",
      "Epoch 190/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7075.9888 - mean_absolute_error: 7075.9888\n",
      "Epoch 00190: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7076.1484 - mean_absolute_error: 7076.1484 - val_loss: 11524.9336 - val_mean_absolute_error: 11524.9336\n",
      "Epoch 191/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7069.1094 - mean_absolute_error: 7069.1094\n",
      "Epoch 00191: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7069.0503 - mean_absolute_error: 7069.0503 - val_loss: 11114.3945 - val_mean_absolute_error: 11114.3945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 192/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7071.9990 - mean_absolute_error: 7071.9990\n",
      "Epoch 00192: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7071.2573 - mean_absolute_error: 7071.2573 - val_loss: 11054.9531 - val_mean_absolute_error: 11054.9531\n",
      "Epoch 193/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7071.5259 - mean_absolute_error: 7071.5259\n",
      "Epoch 00193: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7071.6899 - mean_absolute_error: 7071.6899 - val_loss: 11006.4033 - val_mean_absolute_error: 11006.4033\n",
      "Epoch 194/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7062.7236 - mean_absolute_error: 7062.7236\n",
      "Epoch 00194: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7062.3730 - mean_absolute_error: 7062.3730 - val_loss: 11190.2646 - val_mean_absolute_error: 11190.2646\n",
      "Epoch 195/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7070.0459 - mean_absolute_error: 7070.0459\n",
      "Epoch 00195: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7069.8843 - mean_absolute_error: 7069.8843 - val_loss: 10679.8428 - val_mean_absolute_error: 10679.8428\n",
      "Epoch 196/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7060.9702 - mean_absolute_error: 7060.9702\n",
      "Epoch 00196: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7060.7012 - mean_absolute_error: 7060.7012 - val_loss: 11016.4639 - val_mean_absolute_error: 11016.4639\n",
      "Epoch 197/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7067.6895 - mean_absolute_error: 7067.6895\n",
      "Epoch 00197: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7067.5474 - mean_absolute_error: 7067.5474 - val_loss: 10761.7490 - val_mean_absolute_error: 10761.7490\n",
      "Epoch 198/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7064.5522 - mean_absolute_error: 7064.5522\n",
      "Epoch 00198: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7064.1211 - mean_absolute_error: 7064.1211 - val_loss: 11258.7129 - val_mean_absolute_error: 11258.7129\n",
      "Epoch 199/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7068.2744 - mean_absolute_error: 7068.2744\n",
      "Epoch 00199: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7068.3193 - mean_absolute_error: 7068.3193 - val_loss: 10743.1738 - val_mean_absolute_error: 10743.1738\n",
      "Epoch 200/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7070.3145 - mean_absolute_error: 7070.3145\n",
      "Epoch 00200: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7070.3647 - mean_absolute_error: 7070.3647 - val_loss: 10858.4424 - val_mean_absolute_error: 10858.4424\n",
      "Epoch 201/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7063.3091 - mean_absolute_error: 7063.3091\n",
      "Epoch 00201: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7063.2793 - mean_absolute_error: 7063.2793 - val_loss: 11023.7822 - val_mean_absolute_error: 11023.7822\n",
      "Epoch 202/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7058.3535 - mean_absolute_error: 7058.3535\n",
      "Epoch 00202: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7057.2437 - mean_absolute_error: 7057.2437 - val_loss: 11550.6582 - val_mean_absolute_error: 11550.6582\n",
      "Epoch 203/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7062.2617 - mean_absolute_error: 7062.2617\n",
      "Epoch 00203: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7062.4160 - mean_absolute_error: 7062.4160 - val_loss: 11239.1426 - val_mean_absolute_error: 11239.1426\n",
      "Epoch 204/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7057.9351 - mean_absolute_error: 7057.9351\n",
      "Epoch 00204: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7058.6050 - mean_absolute_error: 7058.6050 - val_loss: 10482.6914 - val_mean_absolute_error: 10482.6914\n",
      "Epoch 205/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7057.7217 - mean_absolute_error: 7057.7217\n",
      "Epoch 00205: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7057.7715 - mean_absolute_error: 7057.7715 - val_loss: 10779.7588 - val_mean_absolute_error: 10779.7588\n",
      "Epoch 206/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7066.8774 - mean_absolute_error: 7066.8774\n",
      "Epoch 00206: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7066.8774 - mean_absolute_error: 7066.8774 - val_loss: 11028.7715 - val_mean_absolute_error: 11028.7715\n",
      "Epoch 207/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7059.1533 - mean_absolute_error: 7059.1533\n",
      "Epoch 00207: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7058.9253 - mean_absolute_error: 7058.9253 - val_loss: 10596.2451 - val_mean_absolute_error: 10596.2451\n",
      "Epoch 208/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7056.7280 - mean_absolute_error: 7056.7280\n",
      "Epoch 00208: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7056.7505 - mean_absolute_error: 7056.7505 - val_loss: 10652.1797 - val_mean_absolute_error: 10652.1797\n",
      "Epoch 209/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7054.1528 - mean_absolute_error: 7054.1528\n",
      "Epoch 00209: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7054.1353 - mean_absolute_error: 7054.1353 - val_loss: 10945.3838 - val_mean_absolute_error: 10945.3838\n",
      "Epoch 210/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7053.2026 - mean_absolute_error: 7053.2026\n",
      "Epoch 00210: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7054.0439 - mean_absolute_error: 7054.0439 - val_loss: 10822.3809 - val_mean_absolute_error: 10822.3809\n",
      "Epoch 211/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7055.8760 - mean_absolute_error: 7055.8760\n",
      "Epoch 00211: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7055.1729 - mean_absolute_error: 7055.1729 - val_loss: 11138.0840 - val_mean_absolute_error: 11138.0840\n",
      "Epoch 212/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7053.2959 - mean_absolute_error: 7053.2959\n",
      "Epoch 00212: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7055.7168 - mean_absolute_error: 7055.7168 - val_loss: 10724.6143 - val_mean_absolute_error: 10724.6143\n",
      "Epoch 213/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7059.7051 - mean_absolute_error: 7059.7051\n",
      "Epoch 00213: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7057.8130 - mean_absolute_error: 7057.8130 - val_loss: 10615.4453 - val_mean_absolute_error: 10615.4453\n",
      "Epoch 214/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7058.9658 - mean_absolute_error: 7058.9658\n",
      "Epoch 00214: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7058.9658 - mean_absolute_error: 7058.9658 - val_loss: 11332.6631 - val_mean_absolute_error: 11332.6631\n",
      "Epoch 215/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7058.1553 - mean_absolute_error: 7058.1553\n",
      "Epoch 00215: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7056.6885 - mean_absolute_error: 7056.6885 - val_loss: 11317.1738 - val_mean_absolute_error: 11317.1738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 216/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7049.0596 - mean_absolute_error: 7049.0596\n",
      "Epoch 00216: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7048.1865 - mean_absolute_error: 7048.1865 - val_loss: 10946.4463 - val_mean_absolute_error: 10946.4463\n",
      "Epoch 217/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7054.4512 - mean_absolute_error: 7054.4512\n",
      "Epoch 00217: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7055.1602 - mean_absolute_error: 7055.1602 - val_loss: 10800.0566 - val_mean_absolute_error: 10800.0566\n",
      "Epoch 218/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7046.6826 - mean_absolute_error: 7046.6826\n",
      "Epoch 00218: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7046.6616 - mean_absolute_error: 7046.6616 - val_loss: 10558.8105 - val_mean_absolute_error: 10558.8105\n",
      "Epoch 219/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7049.9570 - mean_absolute_error: 7049.9570\n",
      "Epoch 00219: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7049.0112 - mean_absolute_error: 7049.0112 - val_loss: 11150.7412 - val_mean_absolute_error: 11150.7412\n",
      "Epoch 220/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7049.9014 - mean_absolute_error: 7049.9014\n",
      "Epoch 00220: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7049.6016 - mean_absolute_error: 7049.6016 - val_loss: 10927.8955 - val_mean_absolute_error: 10927.8955\n",
      "Epoch 221/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7050.6265 - mean_absolute_error: 7050.6265\n",
      "Epoch 00221: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7051.0244 - mean_absolute_error: 7051.0244 - val_loss: 10733.7246 - val_mean_absolute_error: 10733.7246\n",
      "Epoch 222/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7048.4971 - mean_absolute_error: 7048.4971\n",
      "Epoch 00222: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7048.4810 - mean_absolute_error: 7048.4810 - val_loss: 11325.9424 - val_mean_absolute_error: 11325.9424\n",
      "Epoch 223/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7040.2886 - mean_absolute_error: 7040.2886\n",
      "Epoch 00223: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7040.0137 - mean_absolute_error: 7040.0137 - val_loss: 11334.1357 - val_mean_absolute_error: 11334.1357\n",
      "Epoch 224/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7041.4824 - mean_absolute_error: 7041.4824\n",
      "Epoch 00224: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7042.1172 - mean_absolute_error: 7042.1172 - val_loss: 10931.6543 - val_mean_absolute_error: 10931.6543\n",
      "Epoch 225/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7043.9463 - mean_absolute_error: 7043.9463\n",
      "Epoch 00225: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7044.4424 - mean_absolute_error: 7044.4424 - val_loss: 10786.4883 - val_mean_absolute_error: 10786.4883\n",
      "Epoch 226/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7044.7012 - mean_absolute_error: 7044.7012\n",
      "Epoch 00226: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7044.7217 - mean_absolute_error: 7044.7217 - val_loss: 10754.8857 - val_mean_absolute_error: 10754.8857\n",
      "Epoch 227/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7040.9077 - mean_absolute_error: 7040.9077\n",
      "Epoch 00227: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7042.2617 - mean_absolute_error: 7042.2617 - val_loss: 11057.2119 - val_mean_absolute_error: 11057.2119\n",
      "Epoch 228/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7044.4131 - mean_absolute_error: 7044.4131\n",
      "Epoch 00228: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7044.6318 - mean_absolute_error: 7044.6318 - val_loss: 10688.9873 - val_mean_absolute_error: 10688.9873\n",
      "Epoch 229/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7043.8076 - mean_absolute_error: 7043.8076\n",
      "Epoch 00229: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7043.8076 - mean_absolute_error: 7043.8076 - val_loss: 11175.4951 - val_mean_absolute_error: 11175.4951\n",
      "Epoch 230/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7042.0093 - mean_absolute_error: 7042.0093\n",
      "Epoch 00230: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7039.4375 - mean_absolute_error: 7039.4375 - val_loss: 11024.4893 - val_mean_absolute_error: 11024.4893\n",
      "Epoch 231/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7042.7896 - mean_absolute_error: 7042.7896\n",
      "Epoch 00231: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7042.7686 - mean_absolute_error: 7042.7686 - val_loss: 11121.2461 - val_mean_absolute_error: 11121.2461\n",
      "Epoch 232/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7036.1348 - mean_absolute_error: 7036.1348\n",
      "Epoch 00232: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7035.4155 - mean_absolute_error: 7035.4155 - val_loss: 11138.1768 - val_mean_absolute_error: 11138.1768\n",
      "Epoch 233/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7045.0742 - mean_absolute_error: 7045.0742\n",
      "Epoch 00233: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7043.3179 - mean_absolute_error: 7043.3179 - val_loss: 11206.1543 - val_mean_absolute_error: 11206.1543\n",
      "Epoch 234/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 7040.8096 - mean_absolute_error: 7040.8096\n",
      "Epoch 00234: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7040.7266 - mean_absolute_error: 7040.7266 - val_loss: 11512.4668 - val_mean_absolute_error: 11512.4668\n",
      "Epoch 235/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7033.8320 - mean_absolute_error: 7033.8320\n",
      "Epoch 00235: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7033.9316 - mean_absolute_error: 7033.9316 - val_loss: 10625.7383 - val_mean_absolute_error: 10625.7383\n",
      "Epoch 236/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7038.4551 - mean_absolute_error: 7038.4551\n",
      "Epoch 00236: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7038.4272 - mean_absolute_error: 7038.4272 - val_loss: 11156.8438 - val_mean_absolute_error: 11156.8438\n",
      "Epoch 237/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7032.7236 - mean_absolute_error: 7032.7236\n",
      "Epoch 00237: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7031.8096 - mean_absolute_error: 7031.8096 - val_loss: 10722.5713 - val_mean_absolute_error: 10722.5713\n",
      "Epoch 238/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7031.3853 - mean_absolute_error: 7031.3853\n",
      "Epoch 00238: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7031.3853 - mean_absolute_error: 7031.3853 - val_loss: 11001.1475 - val_mean_absolute_error: 11001.1475\n",
      "Epoch 239/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7032.5513 - mean_absolute_error: 7032.5513\n",
      "Epoch 00239: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7032.5264 - mean_absolute_error: 7032.5264 - val_loss: 11066.6221 - val_mean_absolute_error: 11066.6221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7033.8276 - mean_absolute_error: 7033.8276\n",
      "Epoch 00240: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7034.2466 - mean_absolute_error: 7034.2466 - val_loss: 11354.5986 - val_mean_absolute_error: 11354.5986\n",
      "Epoch 241/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7034.9751 - mean_absolute_error: 7034.9751\n",
      "Epoch 00241: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7035.4717 - mean_absolute_error: 7035.4717 - val_loss: 10944.0420 - val_mean_absolute_error: 10944.0420\n",
      "Epoch 242/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7030.8184 - mean_absolute_error: 7030.8184\n",
      "Epoch 00242: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7030.8335 - mean_absolute_error: 7030.8335 - val_loss: 11068.2979 - val_mean_absolute_error: 11068.2979\n",
      "Epoch 243/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7034.9565 - mean_absolute_error: 7034.9565\n",
      "Epoch 00243: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7034.3721 - mean_absolute_error: 7034.3721 - val_loss: 10548.2197 - val_mean_absolute_error: 10548.2197\n",
      "Epoch 244/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7031.8276 - mean_absolute_error: 7031.8276\n",
      "Epoch 00244: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7032.6621 - mean_absolute_error: 7032.6621 - val_loss: 10918.7119 - val_mean_absolute_error: 10918.7119\n",
      "Epoch 245/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7027.9160 - mean_absolute_error: 7027.9160\n",
      "Epoch 00245: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7026.5640 - mean_absolute_error: 7026.5640 - val_loss: 11086.7480 - val_mean_absolute_error: 11086.7480\n",
      "Epoch 246/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7028.5283 - mean_absolute_error: 7028.5283\n",
      "Epoch 00246: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7028.9946 - mean_absolute_error: 7028.9946 - val_loss: 11046.1523 - val_mean_absolute_error: 11046.1523\n",
      "Epoch 247/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7031.6318 - mean_absolute_error: 7031.6318\n",
      "Epoch 00247: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7031.9561 - mean_absolute_error: 7031.9561 - val_loss: 11193.8574 - val_mean_absolute_error: 11193.8574\n",
      "Epoch 248/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7025.2222 - mean_absolute_error: 7025.2222\n",
      "Epoch 00248: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7025.2222 - mean_absolute_error: 7025.2222 - val_loss: 11106.0830 - val_mean_absolute_error: 11106.0830\n",
      "Epoch 249/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7021.6123 - mean_absolute_error: 7021.6123\n",
      "Epoch 00249: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7023.1265 - mean_absolute_error: 7023.1265 - val_loss: 11004.5518 - val_mean_absolute_error: 11004.5518\n",
      "Epoch 250/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7025.6602 - mean_absolute_error: 7025.6602\n",
      "Epoch 00250: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7025.8774 - mean_absolute_error: 7025.8774 - val_loss: 11030.1553 - val_mean_absolute_error: 11030.1553\n",
      "Epoch 251/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 7026.1689 - mean_absolute_error: 7026.1689\n",
      "Epoch 00251: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7026.8750 - mean_absolute_error: 7026.8750 - val_loss: 10830.6611 - val_mean_absolute_error: 10830.6611\n",
      "Epoch 252/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7022.7148 - mean_absolute_error: 7022.7148\n",
      "Epoch 00252: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7022.6729 - mean_absolute_error: 7022.6729 - val_loss: 10940.3916 - val_mean_absolute_error: 10940.3916\n",
      "Epoch 253/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 7019.9922 - mean_absolute_error: 7019.9922\n",
      "Epoch 00253: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7021.3521 - mean_absolute_error: 7021.3521 - val_loss: 10928.7451 - val_mean_absolute_error: 10928.7451\n",
      "Epoch 254/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7025.1177 - mean_absolute_error: 7025.1177\n",
      "Epoch 00254: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7024.1890 - mean_absolute_error: 7024.1890 - val_loss: 11133.2275 - val_mean_absolute_error: 11133.2275\n",
      "Epoch 255/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7027.9600 - mean_absolute_error: 7027.9600\n",
      "Epoch 00255: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7029.0664 - mean_absolute_error: 7029.0664 - val_loss: 10855.3955 - val_mean_absolute_error: 10855.3955\n",
      "Epoch 256/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 7022.6299 - mean_absolute_error: 7022.6299\n",
      "Epoch 00256: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7021.3726 - mean_absolute_error: 7021.3726 - val_loss: 10878.3320 - val_mean_absolute_error: 10878.3320\n",
      "Epoch 257/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7022.3584 - mean_absolute_error: 7022.3584\n",
      "Epoch 00257: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7023.8467 - mean_absolute_error: 7023.8467 - val_loss: 10699.1562 - val_mean_absolute_error: 10699.1562\n",
      "Epoch 258/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7023.8374 - mean_absolute_error: 7023.8374\n",
      "Epoch 00258: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7023.3115 - mean_absolute_error: 7023.3115 - val_loss: 10891.0078 - val_mean_absolute_error: 10891.0078\n",
      "Epoch 259/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7021.5142 - mean_absolute_error: 7021.5142\n",
      "Epoch 00259: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7021.3022 - mean_absolute_error: 7021.3022 - val_loss: 10936.4004 - val_mean_absolute_error: 10936.4004\n",
      "Epoch 260/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7030.3896 - mean_absolute_error: 7030.3896\n",
      "Epoch 00260: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7030.4331 - mean_absolute_error: 7030.4331 - val_loss: 10919.9912 - val_mean_absolute_error: 10919.9912\n",
      "Epoch 261/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7018.3325 - mean_absolute_error: 7018.3325\n",
      "Epoch 00261: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7018.3818 - mean_absolute_error: 7018.3818 - val_loss: 11033.1719 - val_mean_absolute_error: 11033.1719\n",
      "Epoch 262/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7021.0840 - mean_absolute_error: 7021.0840\n",
      "Epoch 00262: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7020.4321 - mean_absolute_error: 7020.4321 - val_loss: 10645.6934 - val_mean_absolute_error: 10645.6934\n",
      "Epoch 263/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7017.1504 - mean_absolute_error: 7017.1504\n",
      "Epoch 00263: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 7016.7529 - mean_absolute_error: 7016.7529 - val_loss: 10613.5947 - val_mean_absolute_error: 10613.5947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 264/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7015.3516 - mean_absolute_error: 7015.3516\n",
      "Epoch 00264: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7014.5532 - mean_absolute_error: 7014.5532 - val_loss: 10913.7578 - val_mean_absolute_error: 10913.7578\n",
      "Epoch 265/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7014.0278 - mean_absolute_error: 7014.0278\n",
      "Epoch 00265: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7014.3223 - mean_absolute_error: 7014.3223 - val_loss: 10883.0107 - val_mean_absolute_error: 10883.0107\n",
      "Epoch 266/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7017.7993 - mean_absolute_error: 7017.7993\n",
      "Epoch 00266: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7017.7671 - mean_absolute_error: 7017.7671 - val_loss: 10696.2383 - val_mean_absolute_error: 10696.2383\n",
      "Epoch 267/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7021.3447 - mean_absolute_error: 7021.3447\n",
      "Epoch 00267: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7020.7524 - mean_absolute_error: 7020.7524 - val_loss: 11073.6680 - val_mean_absolute_error: 11073.6680\n",
      "Epoch 268/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7020.8037 - mean_absolute_error: 7020.8037\n",
      "Epoch 00268: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7020.7305 - mean_absolute_error: 7020.7305 - val_loss: 11449.2227 - val_mean_absolute_error: 11449.2227\n",
      "Epoch 269/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7009.0903 - mean_absolute_error: 7009.0903\n",
      "Epoch 00269: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7009.1045 - mean_absolute_error: 7009.1045 - val_loss: 11161.1162 - val_mean_absolute_error: 11161.1162\n",
      "Epoch 270/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7017.9258 - mean_absolute_error: 7017.9258\n",
      "Epoch 00270: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7018.1216 - mean_absolute_error: 7018.1216 - val_loss: 11415.0342 - val_mean_absolute_error: 11415.0342\n",
      "Epoch 271/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 7011.3501 - mean_absolute_error: 7011.3501\n",
      "Epoch 00271: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7011.0571 - mean_absolute_error: 7011.0571 - val_loss: 11045.0010 - val_mean_absolute_error: 11045.0010\n",
      "Epoch 272/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 7022.4883 - mean_absolute_error: 7022.4883\n",
      "Epoch 00272: val_loss did not improve from 10261.24707\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7022.4883 - mean_absolute_error: 7022.4883 - val_loss: 11036.8594 - val_mean_absolute_error: 11036.8594\n",
      "Epoch 273/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7009.4893 - mean_absolute_error: 7009.4893\n",
      "Epoch 00273: val_loss improved from 10261.24707 to 10248.40137, saving model to Weights-273--10248.40137.hdf5\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7009.6011 - mean_absolute_error: 7009.6011 - val_loss: 10248.4014 - val_mean_absolute_error: 10248.4014\n",
      "Epoch 274/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 7010.5137 - mean_absolute_error: 7010.5137\n",
      "Epoch 00274: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7012.3389 - mean_absolute_error: 7012.3389 - val_loss: 11227.2041 - val_mean_absolute_error: 11227.2041\n",
      "Epoch 275/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7005.4414 - mean_absolute_error: 7005.4414\n",
      "Epoch 00275: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7005.8877 - mean_absolute_error: 7005.8877 - val_loss: 11125.7549 - val_mean_absolute_error: 11125.7549\n",
      "Epoch 276/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 7008.7871 - mean_absolute_error: 7008.7871\n",
      "Epoch 00276: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7009.4561 - mean_absolute_error: 7009.4561 - val_loss: 11435.9502 - val_mean_absolute_error: 11435.9502\n",
      "Epoch 277/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 7012.8608 - mean_absolute_error: 7012.8608\n",
      "Epoch 00277: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7012.9751 - mean_absolute_error: 7012.9751 - val_loss: 10762.8184 - val_mean_absolute_error: 10762.8184\n",
      "Epoch 278/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7010.8408 - mean_absolute_error: 7010.8408\n",
      "Epoch 00278: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7010.0210 - mean_absolute_error: 7010.0210 - val_loss: 11295.1885 - val_mean_absolute_error: 11295.1885\n",
      "Epoch 279/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7012.1748 - mean_absolute_error: 7012.1748\n",
      "Epoch 00279: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7012.9819 - mean_absolute_error: 7012.9819 - val_loss: 10736.6152 - val_mean_absolute_error: 10736.6152\n",
      "Epoch 280/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7006.0161 - mean_absolute_error: 7006.0161\n",
      "Epoch 00280: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7006.1841 - mean_absolute_error: 7006.1841 - val_loss: 10962.4395 - val_mean_absolute_error: 10962.4395\n",
      "Epoch 281/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 7011.7241 - mean_absolute_error: 7011.7241\n",
      "Epoch 00281: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7012.0244 - mean_absolute_error: 7012.0244 - val_loss: 10719.3340 - val_mean_absolute_error: 10719.3340\n",
      "Epoch 282/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7008.0566 - mean_absolute_error: 7008.0566\n",
      "Epoch 00282: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7007.8945 - mean_absolute_error: 7007.8945 - val_loss: 11140.7148 - val_mean_absolute_error: 11140.7148\n",
      "Epoch 283/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 7003.9116 - mean_absolute_error: 7003.9116\n",
      "Epoch 00283: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7004.8750 - mean_absolute_error: 7004.8750 - val_loss: 10891.4238 - val_mean_absolute_error: 10891.4238\n",
      "Epoch 284/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7001.8892 - mean_absolute_error: 7001.8892\n",
      "Epoch 00284: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7002.2310 - mean_absolute_error: 7002.2310 - val_loss: 10624.1133 - val_mean_absolute_error: 10624.1133\n",
      "Epoch 285/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7007.9902 - mean_absolute_error: 7007.9902\n",
      "Epoch 00285: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7006.8320 - mean_absolute_error: 7006.8320 - val_loss: 11209.9717 - val_mean_absolute_error: 11209.9717\n",
      "Epoch 286/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7009.1304 - mean_absolute_error: 7009.1304\n",
      "Epoch 00286: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7008.2739 - mean_absolute_error: 7008.2739 - val_loss: 10805.2969 - val_mean_absolute_error: 10805.2969\n",
      "Epoch 287/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7001.6870 - mean_absolute_error: 7001.6870\n",
      "Epoch 00287: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7001.8965 - mean_absolute_error: 7001.8965 - val_loss: 11097.2197 - val_mean_absolute_error: 11097.2197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 7001.1597 - mean_absolute_error: 7001.1597\n",
      "Epoch 00288: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7003.3760 - mean_absolute_error: 7003.3760 - val_loss: 10796.7832 - val_mean_absolute_error: 10796.7832\n",
      "Epoch 289/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 7004.1294 - mean_absolute_error: 7004.1294\n",
      "Epoch 00289: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7003.3403 - mean_absolute_error: 7003.3403 - val_loss: 10778.7793 - val_mean_absolute_error: 10778.7793\n",
      "Epoch 290/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 7000.1196 - mean_absolute_error: 7000.1196\n",
      "Epoch 00290: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7000.8848 - mean_absolute_error: 7000.8848 - val_loss: 10806.4551 - val_mean_absolute_error: 10806.4551\n",
      "Epoch 291/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6998.2974 - mean_absolute_error: 6998.2974\n",
      "Epoch 00291: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6997.5532 - mean_absolute_error: 6997.5532 - val_loss: 11317.1123 - val_mean_absolute_error: 11317.1123\n",
      "Epoch 292/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 7006.9404 - mean_absolute_error: 7006.9404\n",
      "Epoch 00292: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7006.3037 - mean_absolute_error: 7006.3037 - val_loss: 10845.1689 - val_mean_absolute_error: 10845.1689\n",
      "Epoch 293/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 7003.6348 - mean_absolute_error: 7003.6348\n",
      "Epoch 00293: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7003.1284 - mean_absolute_error: 7003.1284 - val_loss: 10857.9277 - val_mean_absolute_error: 10857.9277\n",
      "Epoch 294/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 7000.0493 - mean_absolute_error: 7000.0493\n",
      "Epoch 00294: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6999.9980 - mean_absolute_error: 6999.9980 - val_loss: 10524.1006 - val_mean_absolute_error: 10524.1006\n",
      "Epoch 295/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6998.8960 - mean_absolute_error: 6998.8960\n",
      "Epoch 00295: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6999.1968 - mean_absolute_error: 6999.1968 - val_loss: 10773.5283 - val_mean_absolute_error: 10773.5283\n",
      "Epoch 296/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6999.2124 - mean_absolute_error: 6999.2124\n",
      "Epoch 00296: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6999.2485 - mean_absolute_error: 6999.2485 - val_loss: 10804.9961 - val_mean_absolute_error: 10804.9961\n",
      "Epoch 297/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6995.3521 - mean_absolute_error: 6995.3521\n",
      "Epoch 00297: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6996.3569 - mean_absolute_error: 6996.3569 - val_loss: 10518.8438 - val_mean_absolute_error: 10518.8438\n",
      "Epoch 298/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 7003.0386 - mean_absolute_error: 7003.0386\n",
      "Epoch 00298: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7003.4629 - mean_absolute_error: 7003.4629 - val_loss: 10795.3018 - val_mean_absolute_error: 10795.3018\n",
      "Epoch 299/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6994.1978 - mean_absolute_error: 6994.1978\n",
      "Epoch 00299: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6993.2593 - mean_absolute_error: 6993.2593 - val_loss: 11122.4043 - val_mean_absolute_error: 11122.4043\n",
      "Epoch 300/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6999.9575 - mean_absolute_error: 6999.9575\n",
      "Epoch 00300: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7000.1152 - mean_absolute_error: 7000.1152 - val_loss: 10788.4229 - val_mean_absolute_error: 10788.4229\n",
      "Epoch 301/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 7001.0088 - mean_absolute_error: 7001.0088\n",
      "Epoch 00301: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7001.4609 - mean_absolute_error: 7001.4609 - val_loss: 10750.7021 - val_mean_absolute_error: 10750.7021\n",
      "Epoch 302/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6999.5298 - mean_absolute_error: 6999.5298\n",
      "Epoch 00302: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6999.9648 - mean_absolute_error: 6999.9648 - val_loss: 11353.8086 - val_mean_absolute_error: 11353.8086\n",
      "Epoch 303/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6998.3228 - mean_absolute_error: 6998.3228\n",
      "Epoch 00303: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6998.1494 - mean_absolute_error: 6998.1494 - val_loss: 11087.9014 - val_mean_absolute_error: 11087.9014\n",
      "Epoch 304/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 7003.7817 - mean_absolute_error: 7003.7817- ETA: 2s - loss\n",
      "Epoch 00304: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 7003.7793 - mean_absolute_error: 7003.7793 - val_loss: 10697.1807 - val_mean_absolute_error: 10697.1807\n",
      "Epoch 305/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6999.5767 - mean_absolute_error: 6999.5767\n",
      "Epoch 00305: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6998.6074 - mean_absolute_error: 6998.6074 - val_loss: 10894.4297 - val_mean_absolute_error: 10894.4297\n",
      "Epoch 306/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6991.7817 - mean_absolute_error: 6991.7817\n",
      "Epoch 00306: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6992.7158 - mean_absolute_error: 6992.7158 - val_loss: 10700.0732 - val_mean_absolute_error: 10700.0732\n",
      "Epoch 307/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6991.0688 - mean_absolute_error: 6991.0688\n",
      "Epoch 00307: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6989.9180 - mean_absolute_error: 6989.9180 - val_loss: 10591.2432 - val_mean_absolute_error: 10591.2432\n",
      "Epoch 308/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6992.6143 - mean_absolute_error: 6992.6143\n",
      "Epoch 00308: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6993.3721 - mean_absolute_error: 6993.3721 - val_loss: 10648.3760 - val_mean_absolute_error: 10648.3760\n",
      "Epoch 309/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6995.8486 - mean_absolute_error: 6995.8486\n",
      "Epoch 00309: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6995.8486 - mean_absolute_error: 6995.8486 - val_loss: 10935.7783 - val_mean_absolute_error: 10935.7783\n",
      "Epoch 310/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6989.0220 - mean_absolute_error: 6989.0220\n",
      "Epoch 00310: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6988.5098 - mean_absolute_error: 6988.5098 - val_loss: 10496.5273 - val_mean_absolute_error: 10496.5273\n",
      "Epoch 311/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6984.4360 - mean_absolute_error: 6984.4360\n",
      "Epoch 00311: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6984.2651 - mean_absolute_error: 6984.2651 - val_loss: 10792.1709 - val_mean_absolute_error: 10792.1709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 312/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6987.3467 - mean_absolute_error: 6987.3467\n",
      "Epoch 00312: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6989.3755 - mean_absolute_error: 6989.3755 - val_loss: 10984.3701 - val_mean_absolute_error: 10984.3701\n",
      "Epoch 313/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6987.2842 - mean_absolute_error: 6987.2842\n",
      "Epoch 00313: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6987.6895 - mean_absolute_error: 6987.6895 - val_loss: 10857.2764 - val_mean_absolute_error: 10857.2764\n",
      "Epoch 314/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6990.8726 - mean_absolute_error: 6990.8726\n",
      "Epoch 00314: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6990.3340 - mean_absolute_error: 6990.3340 - val_loss: 11141.7363 - val_mean_absolute_error: 11141.7363\n",
      "Epoch 315/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6989.0688 - mean_absolute_error: 6989.0688\n",
      "Epoch 00315: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6988.4150 - mean_absolute_error: 6988.4150 - val_loss: 10775.6211 - val_mean_absolute_error: 10775.6211\n",
      "Epoch 316/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6990.9126 - mean_absolute_error: 6990.9126\n",
      "Epoch 00316: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6990.7896 - mean_absolute_error: 6990.7896 - val_loss: 10993.8379 - val_mean_absolute_error: 10993.8379\n",
      "Epoch 317/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6992.9341 - mean_absolute_error: 6992.9341\n",
      "Epoch 00317: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6993.5908 - mean_absolute_error: 6993.5908 - val_loss: 10749.7695 - val_mean_absolute_error: 10749.7695\n",
      "Epoch 318/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6987.2319 - mean_absolute_error: 6987.2319\n",
      "Epoch 00318: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6987.2598 - mean_absolute_error: 6987.2598 - val_loss: 10704.1074 - val_mean_absolute_error: 10704.1074\n",
      "Epoch 319/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6993.1733 - mean_absolute_error: 6993.1733\n",
      "Epoch 00319: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6991.3608 - mean_absolute_error: 6991.3608 - val_loss: 10967.8672 - val_mean_absolute_error: 10967.8672\n",
      "Epoch 320/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6986.9507 - mean_absolute_error: 6986.9507\n",
      "Epoch 00320: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6986.5815 - mean_absolute_error: 6986.5815 - val_loss: 11083.7324 - val_mean_absolute_error: 11083.7324\n",
      "Epoch 321/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6987.6626 - mean_absolute_error: 6987.6626\n",
      "Epoch 00321: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6987.7749 - mean_absolute_error: 6987.7749 - val_loss: 10989.2051 - val_mean_absolute_error: 10989.2051\n",
      "Epoch 322/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6986.8945 - mean_absolute_error: 6986.8945\n",
      "Epoch 00322: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6987.2222 - mean_absolute_error: 6987.2222 - val_loss: 10855.0078 - val_mean_absolute_error: 10855.0078\n",
      "Epoch 323/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6985.2754 - mean_absolute_error: 6985.2754\n",
      "Epoch 00323: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6985.6860 - mean_absolute_error: 6985.6860 - val_loss: 10962.4346 - val_mean_absolute_error: 10962.4346\n",
      "Epoch 324/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6985.6021 - mean_absolute_error: 6985.6021\n",
      "Epoch 00324: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6985.1069 - mean_absolute_error: 6985.1069 - val_loss: 10763.3584 - val_mean_absolute_error: 10763.3584\n",
      "Epoch 325/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6985.3696 - mean_absolute_error: 6985.3696\n",
      "Epoch 00325: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6986.6616 - mean_absolute_error: 6986.6616 - val_loss: 10897.7363 - val_mean_absolute_error: 10897.7363\n",
      "Epoch 326/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6985.8682 - mean_absolute_error: 6985.8682\n",
      "Epoch 00326: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6985.6221 - mean_absolute_error: 6985.6221 - val_loss: 10957.7686 - val_mean_absolute_error: 10957.7686\n",
      "Epoch 327/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6987.6758 - mean_absolute_error: 6987.6758\n",
      "Epoch 00327: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6987.5732 - mean_absolute_error: 6987.5732 - val_loss: 11195.3281 - val_mean_absolute_error: 11195.3281\n",
      "Epoch 328/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6981.7573 - mean_absolute_error: 6981.7573\n",
      "Epoch 00328: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6981.5244 - mean_absolute_error: 6981.5244 - val_loss: 11059.8887 - val_mean_absolute_error: 11059.8887\n",
      "Epoch 329/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6985.7510 - mean_absolute_error: 6985.7510\n",
      "Epoch 00329: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6985.8853 - mean_absolute_error: 6985.8853 - val_loss: 10677.0342 - val_mean_absolute_error: 10677.0342\n",
      "Epoch 330/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6984.2075 - mean_absolute_error: 6984.2075\n",
      "Epoch 00330: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6983.8247 - mean_absolute_error: 6983.8247 - val_loss: 11079.5967 - val_mean_absolute_error: 11079.5967\n",
      "Epoch 331/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6977.1528 - mean_absolute_error: 6977.1528\n",
      "Epoch 00331: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6978.1240 - mean_absolute_error: 6978.1240 - val_loss: 10884.1045 - val_mean_absolute_error: 10884.1045\n",
      "Epoch 332/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6978.7632 - mean_absolute_error: 6978.7632\n",
      "Epoch 00332: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6979.6943 - mean_absolute_error: 6979.6943 - val_loss: 10858.1133 - val_mean_absolute_error: 10858.1133\n",
      "Epoch 333/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6982.4961 - mean_absolute_error: 6982.4961\n",
      "Epoch 00333: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6982.8203 - mean_absolute_error: 6982.8203 - val_loss: 10919.2598 - val_mean_absolute_error: 10919.2598\n",
      "Epoch 334/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6986.1294 - mean_absolute_error: 6986.1294\n",
      "Epoch 00334: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6985.8862 - mean_absolute_error: 6985.8862 - val_loss: 11051.7256 - val_mean_absolute_error: 11051.7256\n",
      "Epoch 335/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6978.3730 - mean_absolute_error: 6978.3730\n",
      "Epoch 00335: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6978.9683 - mean_absolute_error: 6978.9683 - val_loss: 11043.3242 - val_mean_absolute_error: 11043.3242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 336/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6979.4951 - mean_absolute_error: 6979.4951\n",
      "Epoch 00336: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6979.6519 - mean_absolute_error: 6979.6519 - val_loss: 11015.8467 - val_mean_absolute_error: 11015.8467\n",
      "Epoch 337/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6975.1567 - mean_absolute_error: 6975.1567\n",
      "Epoch 00337: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6975.1567 - mean_absolute_error: 6975.1567 - val_loss: 10607.0557 - val_mean_absolute_error: 10607.0557\n",
      "Epoch 338/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6974.0278 - mean_absolute_error: 6974.0278\n",
      "Epoch 00338: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6974.0405 - mean_absolute_error: 6974.0405 - val_loss: 11166.7344 - val_mean_absolute_error: 11166.7344\n",
      "Epoch 339/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6979.4263 - mean_absolute_error: 6979.4263\n",
      "Epoch 00339: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6979.3896 - mean_absolute_error: 6979.3896 - val_loss: 10684.7080 - val_mean_absolute_error: 10684.7080\n",
      "Epoch 340/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6973.6123 - mean_absolute_error: 6973.6123\n",
      "Epoch 00340: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6973.6123 - mean_absolute_error: 6973.6123 - val_loss: 10851.8828 - val_mean_absolute_error: 10851.8828\n",
      "Epoch 341/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6975.7466 - mean_absolute_error: 6975.7466\n",
      "Epoch 00341: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6976.7417 - mean_absolute_error: 6976.7417 - val_loss: 10504.8164 - val_mean_absolute_error: 10504.8164\n",
      "Epoch 342/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6972.5229 - mean_absolute_error: 6972.5229\n",
      "Epoch 00342: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6972.7817 - mean_absolute_error: 6972.7817 - val_loss: 11087.2559 - val_mean_absolute_error: 11087.2559\n",
      "Epoch 343/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6973.6104 - mean_absolute_error: 6973.6104\n",
      "Epoch 00343: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6973.4580 - mean_absolute_error: 6973.4580 - val_loss: 10638.3887 - val_mean_absolute_error: 10638.3887\n",
      "Epoch 344/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6976.7520 - mean_absolute_error: 6976.7520\n",
      "Epoch 00344: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6975.6050 - mean_absolute_error: 6975.6050 - val_loss: 11158.9395 - val_mean_absolute_error: 11158.9395\n",
      "Epoch 345/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6980.4053 - mean_absolute_error: 6980.4053\n",
      "Epoch 00345: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6980.4053 - mean_absolute_error: 6980.4053 - val_loss: 11146.5098 - val_mean_absolute_error: 11146.5098\n",
      "Epoch 346/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6975.8911 - mean_absolute_error: 6975.8911\n",
      "Epoch 00346: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6974.9985 - mean_absolute_error: 6974.9985 - val_loss: 10476.6221 - val_mean_absolute_error: 10476.6221\n",
      "Epoch 347/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6974.5073 - mean_absolute_error: 6974.5073\n",
      "Epoch 00347: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6973.9814 - mean_absolute_error: 6973.9814 - val_loss: 10878.0117 - val_mean_absolute_error: 10878.0117\n",
      "Epoch 348/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6976.5991 - mean_absolute_error: 6976.5991\n",
      "Epoch 00348: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6976.8066 - mean_absolute_error: 6976.8066 - val_loss: 10593.7734 - val_mean_absolute_error: 10593.7734\n",
      "Epoch 349/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6977.6147 - mean_absolute_error: 6977.6147\n",
      "Epoch 00349: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6978.6641 - mean_absolute_error: 6978.6641 - val_loss: 11041.0742 - val_mean_absolute_error: 11041.0742\n",
      "Epoch 350/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6979.3213 - mean_absolute_error: 6979.3213\n",
      "Epoch 00350: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6979.3213 - mean_absolute_error: 6979.3213 - val_loss: 10627.6162 - val_mean_absolute_error: 10627.6162\n",
      "Epoch 351/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6973.1899 - mean_absolute_error: 6973.1899\n",
      "Epoch 00351: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6972.8804 - mean_absolute_error: 6972.8804 - val_loss: 11178.7373 - val_mean_absolute_error: 11178.7373\n",
      "Epoch 352/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6975.9297 - mean_absolute_error: 6975.9297\n",
      "Epoch 00352: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6976.2227 - mean_absolute_error: 6976.2227 - val_loss: 10625.2217 - val_mean_absolute_error: 10625.2217\n",
      "Epoch 353/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6972.0938 - mean_absolute_error: 6972.0938\n",
      "Epoch 00353: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6971.3105 - mean_absolute_error: 6971.3105 - val_loss: 10828.2988 - val_mean_absolute_error: 10828.2988\n",
      "Epoch 354/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6970.3955 - mean_absolute_error: 6970.3955\n",
      "Epoch 00354: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6970.9736 - mean_absolute_error: 6970.9736 - val_loss: 11204.8213 - val_mean_absolute_error: 11204.8213\n",
      "Epoch 355/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6972.5415 - mean_absolute_error: 6972.5415\n",
      "Epoch 00355: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6972.1128 - mean_absolute_error: 6972.1128 - val_loss: 10853.7041 - val_mean_absolute_error: 10853.7041\n",
      "Epoch 356/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6971.1812 - mean_absolute_error: 6971.1812\n",
      "Epoch 00356: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6971.5469 - mean_absolute_error: 6971.5469 - val_loss: 11162.0371 - val_mean_absolute_error: 11162.0371\n",
      "Epoch 357/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6969.2930 - mean_absolute_error: 6969.2930\n",
      "Epoch 00357: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6970.2026 - mean_absolute_error: 6970.2026 - val_loss: 11133.3555 - val_mean_absolute_error: 11133.3555\n",
      "Epoch 358/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6967.9946 - mean_absolute_error: 6967.9946\n",
      "Epoch 00358: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6966.6006 - mean_absolute_error: 6966.6006 - val_loss: 10834.0244 - val_mean_absolute_error: 10834.0244\n",
      "Epoch 359/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6974.6147 - mean_absolute_error: 6974.6147\n",
      "Epoch 00359: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6973.6328 - mean_absolute_error: 6973.6328 - val_loss: 10677.9941 - val_mean_absolute_error: 10677.9941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 360/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6970.3208 - mean_absolute_error: 6970.3208\n",
      "Epoch 00360: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6970.4604 - mean_absolute_error: 6970.4604 - val_loss: 10718.8154 - val_mean_absolute_error: 10718.8154\n",
      "Epoch 361/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6966.6294 - mean_absolute_error: 6966.6294\n",
      "Epoch 00361: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6966.6025 - mean_absolute_error: 6966.6025 - val_loss: 10555.7383 - val_mean_absolute_error: 10555.7383\n",
      "Epoch 362/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6968.8545 - mean_absolute_error: 6968.8545\n",
      "Epoch 00362: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6967.9678 - mean_absolute_error: 6967.9678 - val_loss: 10788.4229 - val_mean_absolute_error: 10788.4229\n",
      "Epoch 363/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6970.6226 - mean_absolute_error: 6970.6226\n",
      "Epoch 00363: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6970.6196 - mean_absolute_error: 6970.6196 - val_loss: 10967.2559 - val_mean_absolute_error: 10967.2559\n",
      "Epoch 364/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6963.4663 - mean_absolute_error: 6963.4663\n",
      "Epoch 00364: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6963.4219 - mean_absolute_error: 6963.4219 - val_loss: 10548.5420 - val_mean_absolute_error: 10548.5420\n",
      "Epoch 365/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6970.3296 - mean_absolute_error: 6970.3296\n",
      "Epoch 00365: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6970.1279 - mean_absolute_error: 6970.1279 - val_loss: 11255.7920 - val_mean_absolute_error: 11255.7920\n",
      "Epoch 366/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6963.4775 - mean_absolute_error: 6963.4775\n",
      "Epoch 00366: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6962.5767 - mean_absolute_error: 6962.5767 - val_loss: 11124.3857 - val_mean_absolute_error: 11124.3857\n",
      "Epoch 367/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6969.9736 - mean_absolute_error: 6969.9736\n",
      "Epoch 00367: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6970.2339 - mean_absolute_error: 6970.2339 - val_loss: 10686.8730 - val_mean_absolute_error: 10686.8730\n",
      "Epoch 368/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6958.2832 - mean_absolute_error: 6958.2832\n",
      "Epoch 00368: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6959.1440 - mean_absolute_error: 6959.1440 - val_loss: 10720.8682 - val_mean_absolute_error: 10720.8682\n",
      "Epoch 369/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6967.8936 - mean_absolute_error: 6967.8936\n",
      "Epoch 00369: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6967.6211 - mean_absolute_error: 6967.6211 - val_loss: 10940.2354 - val_mean_absolute_error: 10940.2354\n",
      "Epoch 370/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6960.5693 - mean_absolute_error: 6960.5693\n",
      "Epoch 00370: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6960.7192 - mean_absolute_error: 6960.7192 - val_loss: 10690.6572 - val_mean_absolute_error: 10690.6572\n",
      "Epoch 371/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6964.6221 - mean_absolute_error: 6964.6221\n",
      "Epoch 00371: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6964.3882 - mean_absolute_error: 6964.3882 - val_loss: 11119.3379 - val_mean_absolute_error: 11119.3379\n",
      "Epoch 372/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6961.9658 - mean_absolute_error: 6961.9658\n",
      "Epoch 00372: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6963.3228 - mean_absolute_error: 6963.3228 - val_loss: 11149.4355 - val_mean_absolute_error: 11149.4355\n",
      "Epoch 373/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6959.7588 - mean_absolute_error: 6959.7588\n",
      "Epoch 00373: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.0996 - mean_absolute_error: 6961.0996 - val_loss: 10812.8877 - val_mean_absolute_error: 10812.8877\n",
      "Epoch 374/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6961.1855 - mean_absolute_error: 6961.1855\n",
      "Epoch 00374: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6958.7178 - mean_absolute_error: 6958.7178 - val_loss: 11290.1885 - val_mean_absolute_error: 11290.1885\n",
      "Epoch 375/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6957.1021 - mean_absolute_error: 6957.1021\n",
      "Epoch 00375: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6956.8628 - mean_absolute_error: 6956.8628 - val_loss: 10621.5742 - val_mean_absolute_error: 10621.5742\n",
      "Epoch 376/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6958.0586 - mean_absolute_error: 6958.0586\n",
      "Epoch 00376: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6958.0586 - mean_absolute_error: 6958.0586 - val_loss: 10858.8604 - val_mean_absolute_error: 10858.8604\n",
      "Epoch 377/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6962.9077 - mean_absolute_error: 6962.9077\n",
      "Epoch 00377: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6962.1704 - mean_absolute_error: 6962.1704 - val_loss: 11300.1797 - val_mean_absolute_error: 11300.1797\n",
      "Epoch 378/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6963.8403 - mean_absolute_error: 6963.8403\n",
      "Epoch 00378: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6963.6431 - mean_absolute_error: 6963.6431 - val_loss: 11061.4014 - val_mean_absolute_error: 11061.4014\n",
      "Epoch 379/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6961.1880 - mean_absolute_error: 6961.1880\n",
      "Epoch 00379: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.9189 - mean_absolute_error: 6961.9189 - val_loss: 11032.1426 - val_mean_absolute_error: 11032.1426\n",
      "Epoch 380/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6960.5566 - mean_absolute_error: 6960.5566\n",
      "Epoch 00380: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.0874 - mean_absolute_error: 6961.0874 - val_loss: 11049.5332 - val_mean_absolute_error: 11049.5332\n",
      "Epoch 381/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6960.8262 - mean_absolute_error: 6960.8262\n",
      "Epoch 00381: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.9507 - mean_absolute_error: 6961.9507 - val_loss: 10934.2363 - val_mean_absolute_error: 10934.2363\n",
      "Epoch 382/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6955.0039 - mean_absolute_error: 6955.0039\n",
      "Epoch 00382: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6954.8979 - mean_absolute_error: 6954.8979 - val_loss: 10997.4395 - val_mean_absolute_error: 10997.4395\n",
      "Epoch 383/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6970.0093 - mean_absolute_error: 6970.0093\n",
      "Epoch 00383: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6970.2310 - mean_absolute_error: 6970.2310 - val_loss: 11013.9062 - val_mean_absolute_error: 11013.9062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 384/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6961.6069 - mean_absolute_error: 6961.6069\n",
      "Epoch 00384: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.1685 - mean_absolute_error: 6961.1685 - val_loss: 10994.8008 - val_mean_absolute_error: 10994.8008\n",
      "Epoch 385/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6956.2134 - mean_absolute_error: 6956.2134\n",
      "Epoch 00385: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6955.3823 - mean_absolute_error: 6955.3823 - val_loss: 10695.0859 - val_mean_absolute_error: 10695.0859\n",
      "Epoch 386/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6954.0034 - mean_absolute_error: 6954.0034\n",
      "Epoch 00386: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6954.7808 - mean_absolute_error: 6954.7808 - val_loss: 10899.5908 - val_mean_absolute_error: 10899.5908\n",
      "Epoch 387/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6952.8892 - mean_absolute_error: 6952.8892\n",
      "Epoch 00387: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6953.6021 - mean_absolute_error: 6953.6021 - val_loss: 10756.7197 - val_mean_absolute_error: 10756.7197\n",
      "Epoch 388/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6957.2778 - mean_absolute_error: 6957.2778\n",
      "Epoch 00388: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6957.3423 - mean_absolute_error: 6957.3423 - val_loss: 11031.6328 - val_mean_absolute_error: 11031.6328\n",
      "Epoch 389/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6959.7832 - mean_absolute_error: 6959.7832\n",
      "Epoch 00389: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6958.9482 - mean_absolute_error: 6958.9482 - val_loss: 10703.8398 - val_mean_absolute_error: 10703.8398\n",
      "Epoch 390/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6957.8208 - mean_absolute_error: 6957.8208\n",
      "Epoch 00390: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6956.5347 - mean_absolute_error: 6956.5347 - val_loss: 10826.1631 - val_mean_absolute_error: 10826.1631\n",
      "Epoch 391/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6951.9971 - mean_absolute_error: 6951.9971\n",
      "Epoch 00391: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6952.1538 - mean_absolute_error: 6952.1538 - val_loss: 10931.4062 - val_mean_absolute_error: 10931.4062\n",
      "Epoch 392/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6960.7783 - mean_absolute_error: 6960.7783\n",
      "Epoch 00392: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6960.3530 - mean_absolute_error: 6960.3530 - val_loss: 11393.8350 - val_mean_absolute_error: 11393.8350\n",
      "Epoch 393/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6958.2754 - mean_absolute_error: 6958.2754\n",
      "Epoch 00393: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6957.6621 - mean_absolute_error: 6957.6621 - val_loss: 10891.0820 - val_mean_absolute_error: 10891.0820\n",
      "Epoch 394/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6955.9873 - mean_absolute_error: 6955.9873\n",
      "Epoch 00394: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6956.7998 - mean_absolute_error: 6956.7998 - val_loss: 10976.1240 - val_mean_absolute_error: 10976.1240\n",
      "Epoch 395/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6951.4414 - mean_absolute_error: 6951.4414\n",
      "Epoch 00395: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6952.3433 - mean_absolute_error: 6952.3433 - val_loss: 10739.0264 - val_mean_absolute_error: 10739.0264\n",
      "Epoch 396/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6955.5835 - mean_absolute_error: 6955.5835\n",
      "Epoch 00396: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6955.9302 - mean_absolute_error: 6955.9302 - val_loss: 11094.7539 - val_mean_absolute_error: 11094.7539\n",
      "Epoch 397/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6960.6968 - mean_absolute_error: 6960.6968\n",
      "Epoch 00397: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6961.3003 - mean_absolute_error: 6961.3003 - val_loss: 10951.5400 - val_mean_absolute_error: 10951.5400\n",
      "Epoch 398/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6953.9946 - mean_absolute_error: 6953.9946\n",
      "Epoch 00398: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6954.2334 - mean_absolute_error: 6954.2334 - val_loss: 10820.0557 - val_mean_absolute_error: 10820.0557\n",
      "Epoch 399/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6952.6157 - mean_absolute_error: 6952.6157\n",
      "Epoch 00399: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6953.9116 - mean_absolute_error: 6953.9116 - val_loss: 11177.4727 - val_mean_absolute_error: 11177.4727\n",
      "Epoch 400/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6957.0283 - mean_absolute_error: 6957.0283\n",
      "Epoch 00400: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6956.1045 - mean_absolute_error: 6956.1045 - val_loss: 10976.6523 - val_mean_absolute_error: 10976.6523\n",
      "Epoch 401/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6955.6724 - mean_absolute_error: 6955.6724\n",
      "Epoch 00401: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6955.0625 - mean_absolute_error: 6955.0625 - val_loss: 10897.7773 - val_mean_absolute_error: 10897.7773\n",
      "Epoch 402/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6953.0352 - mean_absolute_error: 6953.0352\n",
      "Epoch 00402: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6953.3008 - mean_absolute_error: 6953.3008 - val_loss: 11018.3936 - val_mean_absolute_error: 11018.3936\n",
      "Epoch 403/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6952.0244 - mean_absolute_error: 6952.0244\n",
      "Epoch 00403: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6951.4824 - mean_absolute_error: 6951.4824 - val_loss: 10915.0273 - val_mean_absolute_error: 10915.0273\n",
      "Epoch 404/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6947.1021 - mean_absolute_error: 6947.1021\n",
      "Epoch 00404: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6947.1689 - mean_absolute_error: 6947.1689 - val_loss: 10831.8965 - val_mean_absolute_error: 10831.8965\n",
      "Epoch 405/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6947.6177 - mean_absolute_error: 6947.6177\n",
      "Epoch 00405: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6947.1982 - mean_absolute_error: 6947.1982 - val_loss: 10696.0156 - val_mean_absolute_error: 10696.0156\n",
      "Epoch 406/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6951.5278 - mean_absolute_error: 6951.5278\n",
      "Epoch 00406: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6951.7104 - mean_absolute_error: 6951.7104 - val_loss: 11089.7539 - val_mean_absolute_error: 11089.7539\n",
      "Epoch 407/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6946.6470 - mean_absolute_error: 6946.6470\n",
      "Epoch 00407: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6947.1318 - mean_absolute_error: 6947.1318 - val_loss: 10565.0859 - val_mean_absolute_error: 10565.0859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 408/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6951.4082 - mean_absolute_error: 6951.4082\n",
      "Epoch 00408: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6950.7876 - mean_absolute_error: 6950.7876 - val_loss: 11030.6455 - val_mean_absolute_error: 11030.6455\n",
      "Epoch 409/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6943.3867 - mean_absolute_error: 6943.3867\n",
      "Epoch 00409: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6943.9160 - mean_absolute_error: 6943.9160 - val_loss: 10952.0889 - val_mean_absolute_error: 10952.0889\n",
      "Epoch 410/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6950.3823 - mean_absolute_error: 6950.3823\n",
      "Epoch 00410: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6949.7490 - mean_absolute_error: 6949.7490 - val_loss: 11086.4307 - val_mean_absolute_error: 11086.4307\n",
      "Epoch 411/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6953.5674 - mean_absolute_error: 6953.5674\n",
      "Epoch 00411: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6954.0581 - mean_absolute_error: 6954.0581 - val_loss: 11030.7549 - val_mean_absolute_error: 11030.7549\n",
      "Epoch 412/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6947.5649 - mean_absolute_error: 6947.5649\n",
      "Epoch 00412: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6947.5864 - mean_absolute_error: 6947.5864 - val_loss: 10716.8652 - val_mean_absolute_error: 10716.8652\n",
      "Epoch 413/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6946.7769 - mean_absolute_error: 6946.7769\n",
      "Epoch 00413: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6946.7769 - mean_absolute_error: 6946.7769 - val_loss: 10868.8145 - val_mean_absolute_error: 10868.8145\n",
      "Epoch 414/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6945.0591 - mean_absolute_error: 6945.0591\n",
      "Epoch 00414: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6944.8433 - mean_absolute_error: 6944.8433 - val_loss: 10721.4053 - val_mean_absolute_error: 10721.4053\n",
      "Epoch 415/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6945.7832 - mean_absolute_error: 6945.7832\n",
      "Epoch 00415: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6945.7744 - mean_absolute_error: 6945.7744 - val_loss: 10833.7295 - val_mean_absolute_error: 10833.7295\n",
      "Epoch 416/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6953.3613 - mean_absolute_error: 6953.3613\n",
      "Epoch 00416: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6952.1538 - mean_absolute_error: 6952.1538 - val_loss: 11052.0654 - val_mean_absolute_error: 11052.0654\n",
      "Epoch 417/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6953.7368 - mean_absolute_error: 6953.7368\n",
      "Epoch 00417: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6953.4824 - mean_absolute_error: 6953.4824 - val_loss: 10755.9951 - val_mean_absolute_error: 10755.9951\n",
      "Epoch 418/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6949.5952 - mean_absolute_error: 6949.5952\n",
      "Epoch 00418: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6948.8145 - mean_absolute_error: 6948.8145 - val_loss: 11048.1309 - val_mean_absolute_error: 11048.1309\n",
      "Epoch 419/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6947.3589 - mean_absolute_error: 6947.3589\n",
      "Epoch 00419: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6947.3252 - mean_absolute_error: 6947.3252 - val_loss: 11140.5811 - val_mean_absolute_error: 11140.5811\n",
      "Epoch 420/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6940.4814 - mean_absolute_error: 6940.4814\n",
      "Epoch 00420: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.8906 - mean_absolute_error: 6940.8906 - val_loss: 11075.0693 - val_mean_absolute_error: 11075.0693\n",
      "Epoch 421/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6942.6294 - mean_absolute_error: 6942.6294\n",
      "Epoch 00421: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6943.4243 - mean_absolute_error: 6943.4243 - val_loss: 10734.8223 - val_mean_absolute_error: 10734.8223\n",
      "Epoch 422/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6943.2583 - mean_absolute_error: 6943.2583\n",
      "Epoch 00422: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6943.6230 - mean_absolute_error: 6943.6230 - val_loss: 10743.5186 - val_mean_absolute_error: 10743.5186\n",
      "Epoch 423/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6941.8130 - mean_absolute_error: 6941.8130\n",
      "Epoch 00423: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6941.7939 - mean_absolute_error: 6941.7939 - val_loss: 11118.0508 - val_mean_absolute_error: 11118.0508\n",
      "Epoch 424/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6945.3125 - mean_absolute_error: 6945.3125\n",
      "Epoch 00424: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6944.9585 - mean_absolute_error: 6944.9585 - val_loss: 11043.8936 - val_mean_absolute_error: 11043.8936\n",
      "Epoch 425/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6942.5303 - mean_absolute_error: 6942.5303\n",
      "Epoch 00425: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6942.3208 - mean_absolute_error: 6942.3208 - val_loss: 10757.9238 - val_mean_absolute_error: 10757.9238\n",
      "Epoch 426/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6947.9536 - mean_absolute_error: 6947.9536\n",
      "Epoch 00426: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6946.6689 - mean_absolute_error: 6946.6689 - val_loss: 11209.8301 - val_mean_absolute_error: 11209.8301\n",
      "Epoch 427/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6938.5098 - mean_absolute_error: 6938.5098\n",
      "Epoch 00427: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6938.5098 - mean_absolute_error: 6938.5098 - val_loss: 10870.8018 - val_mean_absolute_error: 10870.8018\n",
      "Epoch 428/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6938.5635 - mean_absolute_error: 6938.5635\n",
      "Epoch 00428: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6938.8330 - mean_absolute_error: 6938.8330 - val_loss: 10426.9775 - val_mean_absolute_error: 10426.9775\n",
      "Epoch 429/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6943.1675 - mean_absolute_error: 6943.1675\n",
      "Epoch 00429: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6944.7837 - mean_absolute_error: 6944.7837 - val_loss: 10844.6943 - val_mean_absolute_error: 10844.6943\n",
      "Epoch 430/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6941.2866 - mean_absolute_error: 6941.2866\n",
      "Epoch 00430: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6941.2441 - mean_absolute_error: 6941.2441 - val_loss: 10755.1025 - val_mean_absolute_error: 10755.1025\n",
      "Epoch 431/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6939.3813 - mean_absolute_error: 6939.3813\n",
      "Epoch 00431: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6939.4922 - mean_absolute_error: 6939.4922 - val_loss: 10843.4053 - val_mean_absolute_error: 10843.4053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 432/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6942.8252 - mean_absolute_error: 6942.8252\n",
      "Epoch 00432: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6944.0259 - mean_absolute_error: 6944.0259 - val_loss: 11151.6641 - val_mean_absolute_error: 11151.6641\n",
      "Epoch 433/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6939.7759 - mean_absolute_error: 6939.7759\n",
      "Epoch 00433: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.0186 - mean_absolute_error: 6940.0186 - val_loss: 10867.6230 - val_mean_absolute_error: 10867.6230\n",
      "Epoch 434/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6942.7241 - mean_absolute_error: 6942.7241\n",
      "Epoch 00434: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6942.1758 - mean_absolute_error: 6942.1758 - val_loss: 11139.6084 - val_mean_absolute_error: 11139.6084\n",
      "Epoch 435/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6948.7466 - mean_absolute_error: 6948.7466\n",
      "Epoch 00435: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6948.6665 - mean_absolute_error: 6948.6665 - val_loss: 10872.4121 - val_mean_absolute_error: 10872.4121\n",
      "Epoch 436/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6940.1094 - mean_absolute_error: 6940.1094\n",
      "Epoch 00436: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.8804 - mean_absolute_error: 6940.8804 - val_loss: 10635.0029 - val_mean_absolute_error: 10635.0029\n",
      "Epoch 437/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6946.4595 - mean_absolute_error: 6946.4595\n",
      "Epoch 00437: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6946.4419 - mean_absolute_error: 6946.4419 - val_loss: 10685.8760 - val_mean_absolute_error: 10685.8760\n",
      "Epoch 438/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6940.8286 - mean_absolute_error: 6940.8286\n",
      "Epoch 00438: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.8501 - mean_absolute_error: 6940.8501 - val_loss: 10800.9473 - val_mean_absolute_error: 10800.9473\n",
      "Epoch 439/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6936.8813 - mean_absolute_error: 6936.8813\n",
      "Epoch 00439: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6939.3486 - mean_absolute_error: 6939.3486 - val_loss: 11346.0576 - val_mean_absolute_error: 11346.0576\n",
      "Epoch 440/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6937.7412 - mean_absolute_error: 6937.7412\n",
      "Epoch 00440: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6937.4526 - mean_absolute_error: 6937.4526 - val_loss: 10791.2197 - val_mean_absolute_error: 10791.2197\n",
      "Epoch 441/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6940.3940 - mean_absolute_error: 6940.3940\n",
      "Epoch 00441: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.1885 - mean_absolute_error: 6940.1885 - val_loss: 11040.8135 - val_mean_absolute_error: 11040.8135\n",
      "Epoch 442/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6937.8477 - mean_absolute_error: 6937.8477\n",
      "Epoch 00442: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6936.8877 - mean_absolute_error: 6936.8877 - val_loss: 10878.4033 - val_mean_absolute_error: 10878.4033\n",
      "Epoch 443/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6935.6426 - mean_absolute_error: 6935.6426\n",
      "Epoch 00443: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6936.0059 - mean_absolute_error: 6936.0059 - val_loss: 10831.3574 - val_mean_absolute_error: 10831.3574\n",
      "Epoch 444/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6939.0107 - mean_absolute_error: 6939.0107\n",
      "Epoch 00444: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6939.2256 - mean_absolute_error: 6939.2256 - val_loss: 10778.2705 - val_mean_absolute_error: 10778.2705\n",
      "Epoch 445/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6939.6255 - mean_absolute_error: 6939.6255\n",
      "Epoch 00445: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6939.1123 - mean_absolute_error: 6939.1123 - val_loss: 10635.2725 - val_mean_absolute_error: 10635.2725\n",
      "Epoch 446/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6937.3091 - mean_absolute_error: 6937.3091\n",
      "Epoch 00446: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6937.7148 - mean_absolute_error: 6937.7148 - val_loss: 10767.4043 - val_mean_absolute_error: 10767.4043\n",
      "Epoch 447/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6940.0332 - mean_absolute_error: 6940.0332\n",
      "Epoch 00447: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6939.9692 - mean_absolute_error: 6939.9692 - val_loss: 10591.8701 - val_mean_absolute_error: 10591.8701\n",
      "Epoch 448/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6934.1938 - mean_absolute_error: 6934.1938\n",
      "Epoch 00448: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6934.7529 - mean_absolute_error: 6934.7529 - val_loss: 10944.3838 - val_mean_absolute_error: 10944.3838\n",
      "Epoch 449/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6935.7256 - mean_absolute_error: 6935.7256\n",
      "Epoch 00449: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6934.9917 - mean_absolute_error: 6934.9917 - val_loss: 11168.4668 - val_mean_absolute_error: 11168.4668\n",
      "Epoch 450/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6939.7246 - mean_absolute_error: 6939.7246\n",
      "Epoch 00450: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6939.9263 - mean_absolute_error: 6939.9263 - val_loss: 10741.2861 - val_mean_absolute_error: 10741.2861\n",
      "Epoch 451/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6931.4868 - mean_absolute_error: 6931.4868\n",
      "Epoch 00451: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6932.2148 - mean_absolute_error: 6932.2148 - val_loss: 10508.8623 - val_mean_absolute_error: 10508.8623\n",
      "Epoch 452/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6939.1040 - mean_absolute_error: 6939.1040\n",
      "Epoch 00452: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6940.0791 - mean_absolute_error: 6940.0791 - val_loss: 10760.1133 - val_mean_absolute_error: 10760.1133\n",
      "Epoch 453/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6933.8247 - mean_absolute_error: 6933.8247\n",
      "Epoch 00453: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6934.2744 - mean_absolute_error: 6934.2744 - val_loss: 10884.2080 - val_mean_absolute_error: 10884.2080\n",
      "Epoch 454/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6934.4600 - mean_absolute_error: 6934.4600\n",
      "Epoch 00454: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6933.6831 - mean_absolute_error: 6933.6831 - val_loss: 10687.4609 - val_mean_absolute_error: 10687.4609\n",
      "Epoch 455/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6931.3633 - mean_absolute_error: 6931.3633\n",
      "Epoch 00455: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6931.8320 - mean_absolute_error: 6931.8320 - val_loss: 10865.3623 - val_mean_absolute_error: 10865.3623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 456/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6928.9541 - mean_absolute_error: 6928.9541\n",
      "Epoch 00456: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6929.3955 - mean_absolute_error: 6929.3955 - val_loss: 11051.6377 - val_mean_absolute_error: 11051.6377\n",
      "Epoch 457/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6932.1167 - mean_absolute_error: 6932.1167\n",
      "Epoch 00457: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6932.3584 - mean_absolute_error: 6932.3584 - val_loss: 10890.2256 - val_mean_absolute_error: 10890.2256\n",
      "Epoch 458/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6940.9546 - mean_absolute_error: 6940.9546\n",
      "Epoch 00458: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.1440 - mean_absolute_error: 6940.1440 - val_loss: 10678.0371 - val_mean_absolute_error: 10678.0371\n",
      "Epoch 459/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6939.4106 - mean_absolute_error: 6939.4106\n",
      "Epoch 00459: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6937.3174 - mean_absolute_error: 6937.3174 - val_loss: 11179.9668 - val_mean_absolute_error: 11179.9668\n",
      "Epoch 460/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6934.8369 - mean_absolute_error: 6934.8369\n",
      "Epoch 00460: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6934.7856 - mean_absolute_error: 6934.7856 - val_loss: 10871.4785 - val_mean_absolute_error: 10871.4785\n",
      "Epoch 461/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6935.6885 - mean_absolute_error: 6935.6885\n",
      "Epoch 00461: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6935.5571 - mean_absolute_error: 6935.5571 - val_loss: 10823.7217 - val_mean_absolute_error: 10823.7217\n",
      "Epoch 462/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6941.4102 - mean_absolute_error: 6941.4102\n",
      "Epoch 00462: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6940.1567 - mean_absolute_error: 6940.1567 - val_loss: 11089.3896 - val_mean_absolute_error: 11089.3896\n",
      "Epoch 463/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6933.8091 - mean_absolute_error: 6933.8091\n",
      "Epoch 00463: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6933.8091 - mean_absolute_error: 6933.8091 - val_loss: 10633.1025 - val_mean_absolute_error: 10633.1025\n",
      "Epoch 464/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6939.2773 - mean_absolute_error: 6939.2773\n",
      "Epoch 00464: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6938.7104 - mean_absolute_error: 6938.7104 - val_loss: 11387.8379 - val_mean_absolute_error: 11387.8379\n",
      "Epoch 465/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6927.4683 - mean_absolute_error: 6927.4683\n",
      "Epoch 00465: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.9810 - mean_absolute_error: 6927.9810 - val_loss: 10618.8359 - val_mean_absolute_error: 10618.8359\n",
      "Epoch 466/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6930.9624 - mean_absolute_error: 6930.9624\n",
      "Epoch 00466: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6931.2793 - mean_absolute_error: 6931.2793 - val_loss: 10883.2861 - val_mean_absolute_error: 10883.2861\n",
      "Epoch 467/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6938.1396 - mean_absolute_error: 6938.1396- ETA: 0s - loss: 6935.6177 - mean_absolute_erro\n",
      "Epoch 00467: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6938.5854 - mean_absolute_error: 6938.5854 - val_loss: 10863.5986 - val_mean_absolute_error: 10863.5986\n",
      "Epoch 468/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6930.8608 - mean_absolute_error: 6930.8608\n",
      "Epoch 00468: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6929.7373 - mean_absolute_error: 6929.7373 - val_loss: 10894.7637 - val_mean_absolute_error: 10894.7637\n",
      "Epoch 469/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6931.2285 - mean_absolute_error: 6931.2285\n",
      "Epoch 00469: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6930.6904 - mean_absolute_error: 6930.6904 - val_loss: 10795.6133 - val_mean_absolute_error: 10795.6133\n",
      "Epoch 470/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6924.2373 - mean_absolute_error: 6924.2373\n",
      "Epoch 00470: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6924.2183 - mean_absolute_error: 6924.2183 - val_loss: 11101.9736 - val_mean_absolute_error: 11101.9736\n",
      "Epoch 471/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6929.5327 - mean_absolute_error: 6929.5327\n",
      "Epoch 00471: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6929.6353 - mean_absolute_error: 6929.6353 - val_loss: 10727.9004 - val_mean_absolute_error: 10727.9004\n",
      "Epoch 472/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6927.8135 - mean_absolute_error: 6927.8135\n",
      "Epoch 00472: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.8135 - mean_absolute_error: 6927.8135 - val_loss: 10815.7168 - val_mean_absolute_error: 10815.7168\n",
      "Epoch 473/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6931.5542 - mean_absolute_error: 6931.5542- ETA: 1s - loss: 6929.4727 - mean_a\n",
      "Epoch 00473: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6932.9292 - mean_absolute_error: 6932.9292 - val_loss: 10817.6709 - val_mean_absolute_error: 10817.6709\n",
      "Epoch 474/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6926.5986 - mean_absolute_error: 6926.5986\n",
      "Epoch 00474: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6926.7266 - mean_absolute_error: 6926.7266 - val_loss: 10856.2295 - val_mean_absolute_error: 10856.2295\n",
      "Epoch 475/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6933.3989 - mean_absolute_error: 6933.3989\n",
      "Epoch 00475: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6932.9106 - mean_absolute_error: 6932.9106 - val_loss: 10838.6045 - val_mean_absolute_error: 10838.6045\n",
      "Epoch 476/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6931.4316 - mean_absolute_error: 6931.4316\n",
      "Epoch 00476: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6932.2256 - mean_absolute_error: 6932.2256 - val_loss: 11110.1396 - val_mean_absolute_error: 11110.1396\n",
      "Epoch 477/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6925.6602 - mean_absolute_error: 6925.6602\n",
      "Epoch 00477: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.5972 - mean_absolute_error: 6925.5972 - val_loss: 10977.2520 - val_mean_absolute_error: 10977.2520\n",
      "Epoch 478/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6927.6006 - mean_absolute_error: 6927.6006\n",
      "Epoch 00478: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6928.1094 - mean_absolute_error: 6928.1094 - val_loss: 10714.0742 - val_mean_absolute_error: 10714.0742\n",
      "Epoch 479/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6924.8467 - mean_absolute_error: 6924.8467\n",
      "Epoch 00479: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6924.0786 - mean_absolute_error: 6924.0786 - val_loss: 11191.5088 - val_mean_absolute_error: 11191.5088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 480/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6930.9019 - mean_absolute_error: 6930.9019\n",
      "Epoch 00480: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6931.1064 - mean_absolute_error: 6931.1064 - val_loss: 10844.9346 - val_mean_absolute_error: 10844.9346\n",
      "Epoch 481/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6928.3394 - mean_absolute_error: 6928.3394\n",
      "Epoch 00481: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.9961 - mean_absolute_error: 6927.9961 - val_loss: 10959.1230 - val_mean_absolute_error: 10959.1230\n",
      "Epoch 482/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6929.2354 - mean_absolute_error: 6929.2354\n",
      "Epoch 00482: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6929.2056 - mean_absolute_error: 6929.2056 - val_loss: 10677.5029 - val_mean_absolute_error: 10677.5029\n",
      "Epoch 483/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6926.3906 - mean_absolute_error: 6926.3906\n",
      "Epoch 00483: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.6802 - mean_absolute_error: 6925.6802 - val_loss: 10663.6533 - val_mean_absolute_error: 10663.6533\n",
      "Epoch 484/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6925.8423 - mean_absolute_error: 6925.8423\n",
      "Epoch 00484: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.7700 - mean_absolute_error: 6925.7700 - val_loss: 10697.0107 - val_mean_absolute_error: 10697.0107\n",
      "Epoch 485/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6924.1777 - mean_absolute_error: 6924.1777\n",
      "Epoch 00485: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6923.6787 - mean_absolute_error: 6923.6787 - val_loss: 10889.9541 - val_mean_absolute_error: 10889.9541\n",
      "Epoch 486/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6929.3154 - mean_absolute_error: 6929.3154\n",
      "Epoch 00486: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6929.3154 - mean_absolute_error: 6929.3154 - val_loss: 11120.7285 - val_mean_absolute_error: 11120.7285\n",
      "Epoch 487/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6926.9150 - mean_absolute_error: 6926.9150\n",
      "Epoch 00487: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6926.4731 - mean_absolute_error: 6926.4731 - val_loss: 10744.6484 - val_mean_absolute_error: 10744.6484\n",
      "Epoch 488/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6928.0142 - mean_absolute_error: 6928.0142\n",
      "Epoch 00488: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.9932 - mean_absolute_error: 6927.9932 - val_loss: 10514.4189 - val_mean_absolute_error: 10514.4189\n",
      "Epoch 489/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6927.8540 - mean_absolute_error: 6927.8540\n",
      "Epoch 00489: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6926.5288 - mean_absolute_error: 6926.5288 - val_loss: 10776.5049 - val_mean_absolute_error: 10776.5049\n",
      "Epoch 490/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6923.3945 - mean_absolute_error: 6923.3945\n",
      "Epoch 00490: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6924.4175 - mean_absolute_error: 6924.4175 - val_loss: 10702.6074 - val_mean_absolute_error: 10702.6074\n",
      "Epoch 491/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6925.3398 - mean_absolute_error: 6925.3398\n",
      "Epoch 00491: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6924.8579 - mean_absolute_error: 6924.8579 - val_loss: 10708.6016 - val_mean_absolute_error: 10708.6016\n",
      "Epoch 492/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6927.5552 - mean_absolute_error: 6927.5552\n",
      "Epoch 00492: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.2627 - mean_absolute_error: 6927.2627 - val_loss: 10842.5693 - val_mean_absolute_error: 10842.5693\n",
      "Epoch 493/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6924.4863 - mean_absolute_error: 6924.4863\n",
      "Epoch 00493: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6923.2554 - mean_absolute_error: 6923.2554 - val_loss: 10588.2881 - val_mean_absolute_error: 10588.2881\n",
      "Epoch 494/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6926.1240 - mean_absolute_error: 6926.1240\n",
      "Epoch 00494: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6926.1030 - mean_absolute_error: 6926.1030 - val_loss: 11150.4639 - val_mean_absolute_error: 11150.4639\n",
      "Epoch 495/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6914.8203 - mean_absolute_error: 6914.8203\n",
      "Epoch 00495: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6914.8145 - mean_absolute_error: 6914.8145 - val_loss: 10668.9980 - val_mean_absolute_error: 10668.9980\n",
      "Epoch 496/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6918.5503 - mean_absolute_error: 6918.5503\n",
      "Epoch 00496: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.0698 - mean_absolute_error: 6918.0698 - val_loss: 10818.5459 - val_mean_absolute_error: 10818.5459\n",
      "Epoch 497/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6923.6899 - mean_absolute_error: 6923.6899\n",
      "Epoch 00497: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6924.1592 - mean_absolute_error: 6924.1592 - val_loss: 11177.1895 - val_mean_absolute_error: 11177.1895\n",
      "Epoch 498/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6924.5278 - mean_absolute_error: 6924.5278\n",
      "Epoch 00498: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.9683 - mean_absolute_error: 6925.9683 - val_loss: 10648.2217 - val_mean_absolute_error: 10648.2217\n",
      "Epoch 499/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6926.6499 - mean_absolute_error: 6926.6499\n",
      "Epoch 00499: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.3579 - mean_absolute_error: 6927.3579 - val_loss: 11012.4502 - val_mean_absolute_error: 11012.4502\n",
      "Epoch 500/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6920.8594 - mean_absolute_error: 6920.8594\n",
      "Epoch 00500: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6920.9248 - mean_absolute_error: 6920.9248 - val_loss: 11054.5996 - val_mean_absolute_error: 11054.5996\n",
      "Epoch 501/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6915.6812 - mean_absolute_error: 6915.6812\n",
      "Epoch 00501: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6917.0376 - mean_absolute_error: 6917.0376 - val_loss: 10917.7822 - val_mean_absolute_error: 10917.7822\n",
      "Epoch 502/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6925.3433 - mean_absolute_error: 6925.3433\n",
      "Epoch 00502: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.1982 - mean_absolute_error: 6925.1982 - val_loss: 10646.5107 - val_mean_absolute_error: 10646.5107\n",
      "Epoch 503/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6925.2573 - mean_absolute_error: 6925.2573\n",
      "Epoch 00503: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6925.2705 - mean_absolute_error: 6925.2705 - val_loss: 10719.7285 - val_mean_absolute_error: 10719.7285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6920.9697 - mean_absolute_error: 6920.9697\n",
      "Epoch 00504: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6922.2500 - mean_absolute_error: 6922.2500 - val_loss: 10545.7822 - val_mean_absolute_error: 10545.7822\n",
      "Epoch 505/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6919.9033 - mean_absolute_error: 6919.9033\n",
      "Epoch 00505: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6919.0796 - mean_absolute_error: 6919.0796 - val_loss: 10773.7139 - val_mean_absolute_error: 10773.7139\n",
      "Epoch 506/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6918.3530 - mean_absolute_error: 6918.3530\n",
      "Epoch 00506: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.6875 - mean_absolute_error: 6918.6875 - val_loss: 11117.5938 - val_mean_absolute_error: 11117.5938\n",
      "Epoch 507/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6917.9590 - mean_absolute_error: 6917.9590\n",
      "Epoch 00507: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6917.9263 - mean_absolute_error: 6917.9263 - val_loss: 10903.4424 - val_mean_absolute_error: 10903.4424\n",
      "Epoch 508/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6921.4390 - mean_absolute_error: 6921.4390\n",
      "Epoch 00508: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6921.3320 - mean_absolute_error: 6921.3320 - val_loss: 11130.8379 - val_mean_absolute_error: 11130.8379\n",
      "Epoch 509/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6914.7993 - mean_absolute_error: 6914.7993\n",
      "Epoch 00509: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6914.9927 - mean_absolute_error: 6914.9927 - val_loss: 10834.8340 - val_mean_absolute_error: 10834.8340\n",
      "Epoch 510/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6925.0576 - mean_absolute_error: 6925.0576\n",
      "Epoch 00510: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6924.9243 - mean_absolute_error: 6924.9243 - val_loss: 10862.9854 - val_mean_absolute_error: 10862.9854\n",
      "Epoch 511/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6928.0293 - mean_absolute_error: 6928.0293\n",
      "Epoch 00511: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6927.1792 - mean_absolute_error: 6927.1792 - val_loss: 11623.3350 - val_mean_absolute_error: 11623.3350\n",
      "Epoch 512/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6922.6094 - mean_absolute_error: 6922.6094\n",
      "Epoch 00512: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6922.0269 - mean_absolute_error: 6922.0269 - val_loss: 11011.5615 - val_mean_absolute_error: 11011.5615\n",
      "Epoch 513/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6919.3188 - mean_absolute_error: 6919.3188\n",
      "Epoch 00513: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6919.7461 - mean_absolute_error: 6919.7461 - val_loss: 10643.9141 - val_mean_absolute_error: 10643.9141\n",
      "Epoch 514/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6926.3057 - mean_absolute_error: 6926.3057\n",
      "Epoch 00514: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6926.2832 - mean_absolute_error: 6926.2832 - val_loss: 10572.9385 - val_mean_absolute_error: 10572.9385\n",
      "Epoch 515/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6919.1064 - mean_absolute_error: 6919.1064\n",
      "Epoch 00515: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6918.9731 - mean_absolute_error: 6918.9731 - val_loss: 11144.4414 - val_mean_absolute_error: 11144.4414\n",
      "Epoch 516/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6917.1650 - mean_absolute_error: 6917.1650\n",
      "Epoch 00516: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6916.9990 - mean_absolute_error: 6916.9990 - val_loss: 11113.5703 - val_mean_absolute_error: 11113.5703\n",
      "Epoch 517/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6913.1250 - mean_absolute_error: 6913.1250\n",
      "Epoch 00517: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6912.6465 - mean_absolute_error: 6912.6465 - val_loss: 11017.3887 - val_mean_absolute_error: 11017.3887\n",
      "Epoch 518/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6918.7202 - mean_absolute_error: 6918.7202\n",
      "Epoch 00518: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.9214 - mean_absolute_error: 6918.9214 - val_loss: 10873.3408 - val_mean_absolute_error: 10873.3408\n",
      "Epoch 519/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6918.8755 - mean_absolute_error: 6918.8755\n",
      "Epoch 00519: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.8755 - mean_absolute_error: 6918.8755 - val_loss: 10620.2480 - val_mean_absolute_error: 10620.2480\n",
      "Epoch 520/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6914.7051 - mean_absolute_error: 6914.7051\n",
      "Epoch 00520: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6915.0430 - mean_absolute_error: 6915.0430 - val_loss: 10914.5352 - val_mean_absolute_error: 10914.5352\n",
      "Epoch 521/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6923.6855 - mean_absolute_error: 6923.6855\n",
      "Epoch 00521: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6923.1494 - mean_absolute_error: 6923.1494 - val_loss: 11278.0146 - val_mean_absolute_error: 11278.0146\n",
      "Epoch 522/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6911.0068 - mean_absolute_error: 6911.0068\n",
      "Epoch 00522: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6911.5508 - mean_absolute_error: 6911.5508 - val_loss: 10639.6348 - val_mean_absolute_error: 10639.6348\n",
      "Epoch 523/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6916.6328 - mean_absolute_error: 6916.6328\n",
      "Epoch 00523: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6917.1084 - mean_absolute_error: 6917.1084 - val_loss: 10947.3193 - val_mean_absolute_error: 10947.3193\n",
      "Epoch 524/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6918.3887 - mean_absolute_error: 6918.3887\n",
      "Epoch 00524: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.3257 - mean_absolute_error: 6918.3257 - val_loss: 10677.0488 - val_mean_absolute_error: 10677.0488\n",
      "Epoch 525/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6919.1826 - mean_absolute_error: 6919.1826\n",
      "Epoch 00525: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6918.3228 - mean_absolute_error: 6918.3228 - val_loss: 11414.0449 - val_mean_absolute_error: 11414.0449\n",
      "Epoch 526/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6918.3999 - mean_absolute_error: 6918.3999\n",
      "Epoch 00526: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6917.7959 - mean_absolute_error: 6917.7959 - val_loss: 11060.1045 - val_mean_absolute_error: 11060.1045\n",
      "Epoch 527/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6916.5049 - mean_absolute_error: 6916.5049\n",
      "Epoch 00527: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6916.8442 - mean_absolute_error: 6916.8442 - val_loss: 10844.9463 - val_mean_absolute_error: 10844.9463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 528/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6915.6411 - mean_absolute_error: 6915.6411\n",
      "Epoch 00528: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6916.7349 - mean_absolute_error: 6916.7349 - val_loss: 10643.7822 - val_mean_absolute_error: 10643.7822\n",
      "Epoch 529/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6917.7593 - mean_absolute_error: 6917.7593\n",
      "Epoch 00529: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6917.2822 - mean_absolute_error: 6917.2822 - val_loss: 10856.2275 - val_mean_absolute_error: 10856.2275\n",
      "Epoch 530/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6906.5474 - mean_absolute_error: 6906.5474\n",
      "Epoch 00530: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6907.1133 - mean_absolute_error: 6907.1133 - val_loss: 10655.5400 - val_mean_absolute_error: 10655.5400\n",
      "Epoch 531/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6911.8374 - mean_absolute_error: 6911.8374\n",
      "Epoch 00531: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6912.0952 - mean_absolute_error: 6912.0952 - val_loss: 10843.7393 - val_mean_absolute_error: 10843.7393\n",
      "Epoch 532/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6914.2368 - mean_absolute_error: 6914.2368\n",
      "Epoch 00532: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6914.2358 - mean_absolute_error: 6914.2358 - val_loss: 10782.7812 - val_mean_absolute_error: 10782.7812\n",
      "Epoch 533/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6914.6533 - mean_absolute_error: 6914.6533\n",
      "Epoch 00533: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6914.4194 - mean_absolute_error: 6914.4194 - val_loss: 10857.6426 - val_mean_absolute_error: 10857.6426\n",
      "Epoch 534/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6909.4360 - mean_absolute_error: 6909.4360\n",
      "Epoch 00534: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6909.1138 - mean_absolute_error: 6909.1138 - val_loss: 11185.1797 - val_mean_absolute_error: 11185.1797\n",
      "Epoch 535/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6915.5586 - mean_absolute_error: 6915.5586\n",
      "Epoch 00535: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6915.2388 - mean_absolute_error: 6915.2388 - val_loss: 10808.0010 - val_mean_absolute_error: 10808.0010\n",
      "Epoch 536/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6908.9009 - mean_absolute_error: 6908.9009\n",
      "Epoch 00536: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6908.9009 - mean_absolute_error: 6908.9009 - val_loss: 10880.4014 - val_mean_absolute_error: 10880.4014\n",
      "Epoch 537/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6911.4609 - mean_absolute_error: 6911.4609\n",
      "Epoch 00537: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6911.1548 - mean_absolute_error: 6911.1548 - val_loss: 10728.1729 - val_mean_absolute_error: 10728.1729\n",
      "Epoch 538/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6911.8970 - mean_absolute_error: 6911.8970\n",
      "Epoch 00538: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6912.9980 - mean_absolute_error: 6912.9980 - val_loss: 11290.3359 - val_mean_absolute_error: 11290.3359\n",
      "Epoch 539/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6910.9819 - mean_absolute_error: 6910.9819\n",
      "Epoch 00539: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6910.6138 - mean_absolute_error: 6910.6138 - val_loss: 10821.2705 - val_mean_absolute_error: 10821.2705\n",
      "Epoch 540/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6909.2354 - mean_absolute_error: 6909.2354\n",
      "Epoch 00540: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6909.2437 - mean_absolute_error: 6909.2437 - val_loss: 10831.3984 - val_mean_absolute_error: 10831.3984\n",
      "Epoch 541/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6912.2778 - mean_absolute_error: 6912.2778\n",
      "Epoch 00541: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6911.8179 - mean_absolute_error: 6911.8179 - val_loss: 10676.6182 - val_mean_absolute_error: 10676.6182\n",
      "Epoch 542/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6906.0649 - mean_absolute_error: 6906.0649\n",
      "Epoch 00542: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6905.9258 - mean_absolute_error: 6905.9258 - val_loss: 10682.0928 - val_mean_absolute_error: 10682.0928\n",
      "Epoch 543/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6903.4502 - mean_absolute_error: 6903.4502\n",
      "Epoch 00543: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6904.1558 - mean_absolute_error: 6904.1558 - val_loss: 10716.4326 - val_mean_absolute_error: 10716.4326\n",
      "Epoch 544/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6917.7886 - mean_absolute_error: 6917.7886\n",
      "Epoch 00544: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6916.7866 - mean_absolute_error: 6916.7866 - val_loss: 10942.4287 - val_mean_absolute_error: 10942.4287\n",
      "Epoch 545/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6909.4224 - mean_absolute_error: 6909.4224\n",
      "Epoch 00545: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6908.9121 - mean_absolute_error: 6908.9121 - val_loss: 11021.3662 - val_mean_absolute_error: 11021.3662\n",
      "Epoch 546/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6911.8257 - mean_absolute_error: 6911.8257\n",
      "Epoch 00546: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6909.9907 - mean_absolute_error: 6909.9907 - val_loss: 10887.4541 - val_mean_absolute_error: 10887.4541\n",
      "Epoch 547/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6911.0933 - mean_absolute_error: 6911.0933\n",
      "Epoch 00547: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6911.2168 - mean_absolute_error: 6911.2168 - val_loss: 10834.6885 - val_mean_absolute_error: 10834.6885\n",
      "Epoch 548/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6909.7710 - mean_absolute_error: 6909.7710\n",
      "Epoch 00548: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6909.7314 - mean_absolute_error: 6909.7314 - val_loss: 10835.6279 - val_mean_absolute_error: 10835.6279\n",
      "Epoch 549/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6911.7808 - mean_absolute_error: 6911.7808\n",
      "Epoch 00549: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6913.0898 - mean_absolute_error: 6913.0898 - val_loss: 11164.7197 - val_mean_absolute_error: 11164.7197\n",
      "Epoch 550/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6910.5791 - mean_absolute_error: 6910.5791\n",
      "Epoch 00550: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6911.3447 - mean_absolute_error: 6911.3447 - val_loss: 10763.6436 - val_mean_absolute_error: 10763.6436\n",
      "Epoch 551/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6904.9395 - mean_absolute_error: 6904.9395\n",
      "Epoch 00551: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6905.5352 - mean_absolute_error: 6905.5352 - val_loss: 10801.9316 - val_mean_absolute_error: 10801.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 552/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6906.5962 - mean_absolute_error: 6906.5962\n",
      "Epoch 00552: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6907.4927 - mean_absolute_error: 6907.4927 - val_loss: 10916.6631 - val_mean_absolute_error: 10916.6631\n",
      "Epoch 553/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6913.4990 - mean_absolute_error: 6913.4990\n",
      "Epoch 00553: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6913.5244 - mean_absolute_error: 6913.5244 - val_loss: 11041.6123 - val_mean_absolute_error: 11041.6123\n",
      "Epoch 554/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6907.7510 - mean_absolute_error: 6907.7510\n",
      "Epoch 00554: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6907.4399 - mean_absolute_error: 6907.4399 - val_loss: 10765.3311 - val_mean_absolute_error: 10765.3311\n",
      "Epoch 555/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6903.1157 - mean_absolute_error: 6903.1157\n",
      "Epoch 00555: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6903.1567 - mean_absolute_error: 6903.1567 - val_loss: 10661.2393 - val_mean_absolute_error: 10661.2393\n",
      "Epoch 556/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6911.1128 - mean_absolute_error: 6911.1128\n",
      "Epoch 00556: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6911.0967 - mean_absolute_error: 6911.0967 - val_loss: 10823.3340 - val_mean_absolute_error: 10823.3340\n",
      "Epoch 557/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6909.8555 - mean_absolute_error: 6909.8555\n",
      "Epoch 00557: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6909.8584 - mean_absolute_error: 6909.8584 - val_loss: 10676.8037 - val_mean_absolute_error: 10676.8037\n",
      "Epoch 558/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6903.5615 - mean_absolute_error: 6903.5615\n",
      "Epoch 00558: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6903.9712 - mean_absolute_error: 6903.9712 - val_loss: 10789.7959 - val_mean_absolute_error: 10789.7959\n",
      "Epoch 559/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6899.9751 - mean_absolute_error: 6899.9751\n",
      "Epoch 00559: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6899.9497 - mean_absolute_error: 6899.9497 - val_loss: 10766.8203 - val_mean_absolute_error: 10766.8203\n",
      "Epoch 560/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6898.9316 - mean_absolute_error: 6898.9316\n",
      "Epoch 00560: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6899.7485 - mean_absolute_error: 6899.7485 - val_loss: 10869.9912 - val_mean_absolute_error: 10869.9912\n",
      "Epoch 561/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6906.8755 - mean_absolute_error: 6906.8755\n",
      "Epoch 00561: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6906.2437 - mean_absolute_error: 6906.2437 - val_loss: 10745.9199 - val_mean_absolute_error: 10745.9199\n",
      "Epoch 562/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6904.5693 - mean_absolute_error: 6904.5693\n",
      "Epoch 00562: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6905.0430 - mean_absolute_error: 6905.0430 - val_loss: 10876.2744 - val_mean_absolute_error: 10876.2744\n",
      "Epoch 563/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6904.8867 - mean_absolute_error: 6904.8867\n",
      "Epoch 00563: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6906.0894 - mean_absolute_error: 6906.0894 - val_loss: 11252.4121 - val_mean_absolute_error: 11252.4121\n",
      "Epoch 564/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6907.1748 - mean_absolute_error: 6907.1748\n",
      "Epoch 00564: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6907.6211 - mean_absolute_error: 6907.6211 - val_loss: 10710.5996 - val_mean_absolute_error: 10710.5996\n",
      "Epoch 565/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6894.5371 - mean_absolute_error: 6894.5371\n",
      "Epoch 00565: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6896.3838 - mean_absolute_error: 6896.3838 - val_loss: 10739.1514 - val_mean_absolute_error: 10739.1514\n",
      "Epoch 566/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6904.5674 - mean_absolute_error: 6904.5674\n",
      "Epoch 00566: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6903.8906 - mean_absolute_error: 6903.8906 - val_loss: 11001.3564 - val_mean_absolute_error: 11001.3564\n",
      "Epoch 567/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6904.0845 - mean_absolute_error: 6904.0845\n",
      "Epoch 00567: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6903.9458 - mean_absolute_error: 6903.9458 - val_loss: 10883.0088 - val_mean_absolute_error: 10883.0088\n",
      "Epoch 568/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6904.7144 - mean_absolute_error: 6904.7144\n",
      "Epoch 00568: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6904.4805 - mean_absolute_error: 6904.4805 - val_loss: 10642.7549 - val_mean_absolute_error: 10642.7549\n",
      "Epoch 569/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6905.7012 - mean_absolute_error: 6905.7012\n",
      "Epoch 00569: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6904.5708 - mean_absolute_error: 6904.5708 - val_loss: 10811.8926 - val_mean_absolute_error: 10811.8926\n",
      "Epoch 570/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6898.7202 - mean_absolute_error: 6898.7202\n",
      "Epoch 00570: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6898.7725 - mean_absolute_error: 6898.7725 - val_loss: 10836.6484 - val_mean_absolute_error: 10836.6484\n",
      "Epoch 571/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6903.2139 - mean_absolute_error: 6903.2139\n",
      "Epoch 00571: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6902.9839 - mean_absolute_error: 6902.9839 - val_loss: 10488.7275 - val_mean_absolute_error: 10488.7275\n",
      "Epoch 572/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6901.8760 - mean_absolute_error: 6901.8760\n",
      "Epoch 00572: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6902.0762 - mean_absolute_error: 6902.0762 - val_loss: 10901.7197 - val_mean_absolute_error: 10901.7197\n",
      "Epoch 573/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6901.4829 - mean_absolute_error: 6901.4829\n",
      "Epoch 00573: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6901.8486 - mean_absolute_error: 6901.8486 - val_loss: 10727.2266 - val_mean_absolute_error: 10727.2266\n",
      "Epoch 574/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6900.3560 - mean_absolute_error: 6900.3560\n",
      "Epoch 00574: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6900.2627 - mean_absolute_error: 6900.2627 - val_loss: 11114.2842 - val_mean_absolute_error: 11114.2842\n",
      "Epoch 575/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6899.6118 - mean_absolute_error: 6899.6118\n",
      "Epoch 00575: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6899.1069 - mean_absolute_error: 6899.1069 - val_loss: 11450.8271 - val_mean_absolute_error: 11450.8271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 576/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6900.2969 - mean_absolute_error: 6900.2969\n",
      "Epoch 00576: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6900.4912 - mean_absolute_error: 6900.4912 - val_loss: 10371.5723 - val_mean_absolute_error: 10371.5723\n",
      "Epoch 577/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6902.6299 - mean_absolute_error: 6902.6299\n",
      "Epoch 00577: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6902.7329 - mean_absolute_error: 6902.7329 - val_loss: 10761.3457 - val_mean_absolute_error: 10761.3457\n",
      "Epoch 578/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6897.9468 - mean_absolute_error: 6897.9468\n",
      "Epoch 00578: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6898.0156 - mean_absolute_error: 6898.0156 - val_loss: 10689.6094 - val_mean_absolute_error: 10689.6094\n",
      "Epoch 579/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6902.6587 - mean_absolute_error: 6902.6587\n",
      "Epoch 00579: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6903.4868 - mean_absolute_error: 6903.4868 - val_loss: 10886.0615 - val_mean_absolute_error: 10886.0615\n",
      "Epoch 580/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6895.7046 - mean_absolute_error: 6895.7046\n",
      "Epoch 00580: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6896.5591 - mean_absolute_error: 6896.5591 - val_loss: 11047.3076 - val_mean_absolute_error: 11047.3076\n",
      "Epoch 581/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6902.3574 - mean_absolute_error: 6902.3574\n",
      "Epoch 00581: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6902.8999 - mean_absolute_error: 6902.8999 - val_loss: 11016.0293 - val_mean_absolute_error: 11016.0293\n",
      "Epoch 582/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6904.3188 - mean_absolute_error: 6904.3188\n",
      "Epoch 00582: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6904.6562 - mean_absolute_error: 6904.6562 - val_loss: 11290.2246 - val_mean_absolute_error: 11290.2246\n",
      "Epoch 583/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6896.9126 - mean_absolute_error: 6896.9126\n",
      "Epoch 00583: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6896.7510 - mean_absolute_error: 6896.7510 - val_loss: 10765.3408 - val_mean_absolute_error: 10765.3408\n",
      "Epoch 584/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6897.2515 - mean_absolute_error: 6897.2515\n",
      "Epoch 00584: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6896.9839 - mean_absolute_error: 6896.9839 - val_loss: 10842.7217 - val_mean_absolute_error: 10842.7217\n",
      "Epoch 585/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6895.0991 - mean_absolute_error: 6895.0991\n",
      "Epoch 00585: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6895.3628 - mean_absolute_error: 6895.3628 - val_loss: 10851.2529 - val_mean_absolute_error: 10851.2529\n",
      "Epoch 586/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6898.0718 - mean_absolute_error: 6898.0718\n",
      "Epoch 00586: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6897.8457 - mean_absolute_error: 6897.8457 - val_loss: 10905.9238 - val_mean_absolute_error: 10905.9238\n",
      "Epoch 587/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6895.8838 - mean_absolute_error: 6895.8838\n",
      "Epoch 00587: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6895.8838 - mean_absolute_error: 6895.8838 - val_loss: 10755.4893 - val_mean_absolute_error: 10755.4893\n",
      "Epoch 588/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6896.2275 - mean_absolute_error: 6896.2275\n",
      "Epoch 00588: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6895.2480 - mean_absolute_error: 6895.2480 - val_loss: 10797.5508 - val_mean_absolute_error: 10797.5508\n",
      "Epoch 589/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6896.5811 - mean_absolute_error: 6896.5811\n",
      "Epoch 00589: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6897.7383 - mean_absolute_error: 6897.7383 - val_loss: 10904.2061 - val_mean_absolute_error: 10904.2061\n",
      "Epoch 590/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6889.7026 - mean_absolute_error: 6889.7026\n",
      "Epoch 00590: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6890.5044 - mean_absolute_error: 6890.5044 - val_loss: 10847.9277 - val_mean_absolute_error: 10847.9277\n",
      "Epoch 591/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6897.2568 - mean_absolute_error: 6897.2568\n",
      "Epoch 00591: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6897.7886 - mean_absolute_error: 6897.7886 - val_loss: 10996.0898 - val_mean_absolute_error: 10996.0898\n",
      "Epoch 592/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6891.7832 - mean_absolute_error: 6891.7832\n",
      "Epoch 00592: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6892.4058 - mean_absolute_error: 6892.4058 - val_loss: 10750.7891 - val_mean_absolute_error: 10750.7891\n",
      "Epoch 593/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6902.8496 - mean_absolute_error: 6902.8496\n",
      "Epoch 00593: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6902.3667 - mean_absolute_error: 6902.3667 - val_loss: 10708.0498 - val_mean_absolute_error: 10708.0498\n",
      "Epoch 594/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6886.0898 - mean_absolute_error: 6886.0898\n",
      "Epoch 00594: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6886.9199 - mean_absolute_error: 6886.9199 - val_loss: 10848.8418 - val_mean_absolute_error: 10848.8418\n",
      "Epoch 595/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6901.6426 - mean_absolute_error: 6901.6426\n",
      "Epoch 00595: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6900.6313 - mean_absolute_error: 6900.6313 - val_loss: 10976.1592 - val_mean_absolute_error: 10976.1592\n",
      "Epoch 596/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6900.6914 - mean_absolute_error: 6900.6914\n",
      "Epoch 00596: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6900.8140 - mean_absolute_error: 6900.8140 - val_loss: 10566.0820 - val_mean_absolute_error: 10566.0820\n",
      "Epoch 597/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6898.5308 - mean_absolute_error: 6898.5308\n",
      "Epoch 00597: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6897.9302 - mean_absolute_error: 6897.9302 - val_loss: 11025.4512 - val_mean_absolute_error: 11025.4512\n",
      "Epoch 598/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6894.2295 - mean_absolute_error: 6894.2295\n",
      "Epoch 00598: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6894.0898 - mean_absolute_error: 6894.0898 - val_loss: 10724.1504 - val_mean_absolute_error: 10724.1504\n",
      "Epoch 599/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6900.0967 - mean_absolute_error: 6900.0967\n",
      "Epoch 00599: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6900.0146 - mean_absolute_error: 6900.0146 - val_loss: 11148.9971 - val_mean_absolute_error: 11148.9971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 600/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6896.0513 - mean_absolute_error: 6896.0513\n",
      "Epoch 00600: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6895.1006 - mean_absolute_error: 6895.1006 - val_loss: 11159.7578 - val_mean_absolute_error: 11159.7578\n",
      "Epoch 601/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6900.3872 - mean_absolute_error: 6900.3872\n",
      "Epoch 00601: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6900.2524 - mean_absolute_error: 6900.2524 - val_loss: 10804.9531 - val_mean_absolute_error: 10804.9531\n",
      "Epoch 602/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6893.5767 - mean_absolute_error: 6893.5767\n",
      "Epoch 00602: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6893.5469 - mean_absolute_error: 6893.5469 - val_loss: 11098.6641 - val_mean_absolute_error: 11098.6641\n",
      "Epoch 603/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6891.6328 - mean_absolute_error: 6891.6328\n",
      "Epoch 00603: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6892.0479 - mean_absolute_error: 6892.0479 - val_loss: 10663.4258 - val_mean_absolute_error: 10663.4258\n",
      "Epoch 604/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6890.7686 - mean_absolute_error: 6890.7686\n",
      "Epoch 00604: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6890.5581 - mean_absolute_error: 6890.5581 - val_loss: 10887.9629 - val_mean_absolute_error: 10887.9629\n",
      "Epoch 605/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6891.2539 - mean_absolute_error: 6891.2539\n",
      "Epoch 00605: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6892.1016 - mean_absolute_error: 6892.1016 - val_loss: 10632.2070 - val_mean_absolute_error: 10632.2070\n",
      "Epoch 606/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6895.2368 - mean_absolute_error: 6895.2368\n",
      "Epoch 00606: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6895.0132 - mean_absolute_error: 6895.0132 - val_loss: 10961.3525 - val_mean_absolute_error: 10961.3525\n",
      "Epoch 607/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6894.9463 - mean_absolute_error: 6894.9463\n",
      "Epoch 00607: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6894.4287 - mean_absolute_error: 6894.4287 - val_loss: 10702.4326 - val_mean_absolute_error: 10702.4326\n",
      "Epoch 608/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6886.8218 - mean_absolute_error: 6886.8218\n",
      "Epoch 00608: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6886.3193 - mean_absolute_error: 6886.3193 - val_loss: 10810.3613 - val_mean_absolute_error: 10810.3613\n",
      "Epoch 609/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6894.3965 - mean_absolute_error: 6894.3965\n",
      "Epoch 00609: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6894.3594 - mean_absolute_error: 6894.3594 - val_loss: 10792.6045 - val_mean_absolute_error: 10792.6045\n",
      "Epoch 610/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6890.0566 - mean_absolute_error: 6890.0566\n",
      "Epoch 00610: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6890.1689 - mean_absolute_error: 6890.1689 - val_loss: 10740.5811 - val_mean_absolute_error: 10740.5811\n",
      "Epoch 611/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6891.0913 - mean_absolute_error: 6891.0913\n",
      "Epoch 00611: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6891.6060 - mean_absolute_error: 6891.6060 - val_loss: 10752.4375 - val_mean_absolute_error: 10752.4375\n",
      "Epoch 612/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6891.4189 - mean_absolute_error: 6891.4189\n",
      "Epoch 00612: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6891.4390 - mean_absolute_error: 6891.4390 - val_loss: 10883.9199 - val_mean_absolute_error: 10883.9199\n",
      "Epoch 613/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6887.5488 - mean_absolute_error: 6887.5488- ETA: 0s - loss: 6891.3569 - mean_absolute_error: 68\n",
      "Epoch 00613: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6887.7285 - mean_absolute_error: 6887.7285 - val_loss: 11036.2842 - val_mean_absolute_error: 11036.2842\n",
      "Epoch 614/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6893.2046 - mean_absolute_error: 6893.2046\n",
      "Epoch 00614: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6893.7622 - mean_absolute_error: 6893.7622 - val_loss: 10923.2764 - val_mean_absolute_error: 10923.2764\n",
      "Epoch 615/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6889.4365 - mean_absolute_error: 6889.4365\n",
      "Epoch 00615: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.3711 - mean_absolute_error: 6888.3711 - val_loss: 10824.9316 - val_mean_absolute_error: 10824.9316\n",
      "Epoch 616/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6893.3125 - mean_absolute_error: 6893.3125\n",
      "Epoch 00616: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6893.3374 - mean_absolute_error: 6893.3374 - val_loss: 10959.5996 - val_mean_absolute_error: 10959.5996\n",
      "Epoch 617/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6896.7798 - mean_absolute_error: 6896.7798\n",
      "Epoch 00617: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6894.6733 - mean_absolute_error: 6894.6733 - val_loss: 10903.8516 - val_mean_absolute_error: 10903.8516\n",
      "Epoch 618/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6885.4731 - mean_absolute_error: 6885.4731\n",
      "Epoch 00618: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6885.8096 - mean_absolute_error: 6885.8096 - val_loss: 11251.7236 - val_mean_absolute_error: 11251.7236\n",
      "Epoch 619/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6883.8945 - mean_absolute_error: 6883.8945\n",
      "Epoch 00619: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6884.8765 - mean_absolute_error: 6884.8765 - val_loss: 10869.6025 - val_mean_absolute_error: 10869.6025\n",
      "Epoch 620/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6896.4810 - mean_absolute_error: 6896.4810\n",
      "Epoch 00620: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6896.9189 - mean_absolute_error: 6896.9189 - val_loss: 10660.5996 - val_mean_absolute_error: 10660.5996\n",
      "Epoch 621/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6889.1060 - mean_absolute_error: 6889.1060\n",
      "Epoch 00621: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6889.0078 - mean_absolute_error: 6889.0078 - val_loss: 10698.1455 - val_mean_absolute_error: 10698.1455\n",
      "Epoch 622/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6892.5068 - mean_absolute_error: 6892.5068\n",
      "Epoch 00622: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6893.5254 - mean_absolute_error: 6893.5254 - val_loss: 10969.1416 - val_mean_absolute_error: 10969.1416\n",
      "Epoch 623/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6892.2026 - mean_absolute_error: 6892.2026\n",
      "Epoch 00623: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6891.5791 - mean_absolute_error: 6891.5791 - val_loss: 10948.3955 - val_mean_absolute_error: 10948.3955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 624/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6887.7544 - mean_absolute_error: 6887.7544\n",
      "Epoch 00624: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6887.0518 - mean_absolute_error: 6887.0518 - val_loss: 10794.5039 - val_mean_absolute_error: 10794.5039\n",
      "Epoch 625/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6886.4995 - mean_absolute_error: 6886.4995\n",
      "Epoch 00625: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6886.5000 - mean_absolute_error: 6886.5000 - val_loss: 11043.3242 - val_mean_absolute_error: 11043.3242\n",
      "Epoch 626/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6888.6357 - mean_absolute_error: 6888.6357\n",
      "Epoch 00626: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.4238 - mean_absolute_error: 6888.4238 - val_loss: 10709.4209 - val_mean_absolute_error: 10709.4209\n",
      "Epoch 627/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6886.9644 - mean_absolute_error: 6886.9644\n",
      "Epoch 00627: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6887.2925 - mean_absolute_error: 6887.2925 - val_loss: 10755.4512 - val_mean_absolute_error: 10755.4512\n",
      "Epoch 628/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6892.4312 - mean_absolute_error: 6892.4312\n",
      "Epoch 00628: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6891.7524 - mean_absolute_error: 6891.7524 - val_loss: 11039.5273 - val_mean_absolute_error: 11039.5273\n",
      "Epoch 629/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6888.9023 - mean_absolute_error: 6888.9023\n",
      "Epoch 00629: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.8262 - mean_absolute_error: 6888.8262 - val_loss: 10878.2402 - val_mean_absolute_error: 10878.2402\n",
      "Epoch 630/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6889.4131 - mean_absolute_error: 6889.4131\n",
      "Epoch 00630: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6890.6235 - mean_absolute_error: 6890.6235 - val_loss: 10787.6143 - val_mean_absolute_error: 10787.6143\n",
      "Epoch 631/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6884.0371 - mean_absolute_error: 6884.0371\n",
      "Epoch 00631: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6884.3188 - mean_absolute_error: 6884.3188 - val_loss: 11029.0771 - val_mean_absolute_error: 11029.0771\n",
      "Epoch 632/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6887.0132 - mean_absolute_error: 6887.0132\n",
      "Epoch 00632: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6887.7842 - mean_absolute_error: 6887.7842 - val_loss: 11016.0674 - val_mean_absolute_error: 11016.0674\n",
      "Epoch 633/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6883.6387 - mean_absolute_error: 6883.6387\n",
      "Epoch 00633: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6883.0376 - mean_absolute_error: 6883.0376 - val_loss: 11066.3730 - val_mean_absolute_error: 11066.3730\n",
      "Epoch 634/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6887.5522 - mean_absolute_error: 6887.5522\n",
      "Epoch 00634: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6887.5190 - mean_absolute_error: 6887.5190 - val_loss: 10892.7188 - val_mean_absolute_error: 10892.7188\n",
      "Epoch 635/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6884.4209 - mean_absolute_error: 6884.4209\n",
      "Epoch 00635: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6885.1313 - mean_absolute_error: 6885.1313 - val_loss: 10592.2812 - val_mean_absolute_error: 10592.2812\n",
      "Epoch 636/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6890.3022 - mean_absolute_error: 6890.3022\n",
      "Epoch 00636: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6890.6621 - mean_absolute_error: 6890.6621 - val_loss: 10792.2910 - val_mean_absolute_error: 10792.2910\n",
      "Epoch 637/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6887.7739 - mean_absolute_error: 6887.7739\n",
      "Epoch 00637: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.0435 - mean_absolute_error: 6888.0435 - val_loss: 10774.9688 - val_mean_absolute_error: 10774.9688\n",
      "Epoch 638/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6888.1709 - mean_absolute_error: 6888.1709\n",
      "Epoch 00638: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.0977 - mean_absolute_error: 6888.0977 - val_loss: 10977.6475 - val_mean_absolute_error: 10977.6475\n",
      "Epoch 639/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6887.9673 - mean_absolute_error: 6887.9673\n",
      "Epoch 00639: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6888.4268 - mean_absolute_error: 6888.4268 - val_loss: 10439.5840 - val_mean_absolute_error: 10439.5840\n",
      "Epoch 640/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6885.0225 - mean_absolute_error: 6885.0225\n",
      "Epoch 00640: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6885.1836 - mean_absolute_error: 6885.1836 - val_loss: 10828.5742 - val_mean_absolute_error: 10828.5742\n",
      "Epoch 641/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6883.2378 - mean_absolute_error: 6883.2378\n",
      "Epoch 00641: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6883.7109 - mean_absolute_error: 6883.7109 - val_loss: 10842.8408 - val_mean_absolute_error: 10842.8408\n",
      "Epoch 642/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6880.7051 - mean_absolute_error: 6880.7051\n",
      "Epoch 00642: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.4526 - mean_absolute_error: 6881.4526 - val_loss: 10792.9688 - val_mean_absolute_error: 10792.9688\n",
      "Epoch 643/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6882.6104 - mean_absolute_error: 6882.6104\n",
      "Epoch 00643: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6882.0137 - mean_absolute_error: 6882.0137 - val_loss: 10945.4697 - val_mean_absolute_error: 10945.4697\n",
      "Epoch 644/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6877.7051 - mean_absolute_error: 6877.7051\n",
      "Epoch 00644: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6878.2476 - mean_absolute_error: 6878.2476 - val_loss: 11071.6553 - val_mean_absolute_error: 11071.6553\n",
      "Epoch 645/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6886.6167 - mean_absolute_error: 6886.6167\n",
      "Epoch 00645: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6886.6167 - mean_absolute_error: 6886.6167 - val_loss: 10760.2227 - val_mean_absolute_error: 10760.2227\n",
      "Epoch 646/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6885.8320 - mean_absolute_error: 6885.8320\n",
      "Epoch 00646: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6885.2612 - mean_absolute_error: 6885.2612 - val_loss: 10830.4854 - val_mean_absolute_error: 10830.4854\n",
      "Epoch 647/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6880.8457 - mean_absolute_error: 6880.8457\n",
      "Epoch 00647: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6880.3555 - mean_absolute_error: 6880.3555 - val_loss: 10845.4678 - val_mean_absolute_error: 10845.4678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 648/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6876.2017 - mean_absolute_error: 6876.2017\n",
      "Epoch 00648: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6877.3315 - mean_absolute_error: 6877.3315 - val_loss: 11076.8232 - val_mean_absolute_error: 11076.8232\n",
      "Epoch 649/700\n",
      "5286/5298 [============================>.] - ETA: 0s - loss: 6877.0352 - mean_absolute_error: 6877.0352\n",
      "Epoch 00649: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6877.7944 - mean_absolute_error: 6877.7944 - val_loss: 10632.1602 - val_mean_absolute_error: 10632.1602\n",
      "Epoch 650/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6883.3179 - mean_absolute_error: 6883.3179\n",
      "Epoch 00650: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6882.9272 - mean_absolute_error: 6882.9272 - val_loss: 10880.8984 - val_mean_absolute_error: 10880.8984\n",
      "Epoch 651/700\n",
      "5291/5298 [============================>.] - ETA: 0s - loss: 6880.1504 - mean_absolute_error: 6880.1504\n",
      "Epoch 00651: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6878.8335 - mean_absolute_error: 6878.8335 - val_loss: 10881.9561 - val_mean_absolute_error: 10881.9561\n",
      "Epoch 652/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6885.9990 - mean_absolute_error: 6885.9990\n",
      "Epoch 00652: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6885.9990 - mean_absolute_error: 6885.9990 - val_loss: 10641.7598 - val_mean_absolute_error: 10641.7598\n",
      "Epoch 653/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6878.9048 - mean_absolute_error: 6878.9048\n",
      "Epoch 00653: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6879.3398 - mean_absolute_error: 6879.3398 - val_loss: 10886.0410 - val_mean_absolute_error: 10886.0410\n",
      "Epoch 654/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6885.9087 - mean_absolute_error: 6885.9087\n",
      "Epoch 00654: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6885.6562 - mean_absolute_error: 6885.6562 - val_loss: 10774.3086 - val_mean_absolute_error: 10774.3086\n",
      "Epoch 655/700\n",
      "5290/5298 [============================>.] - ETA: 0s - loss: 6881.5464 - mean_absolute_error: 6881.5464\n",
      "Epoch 00655: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.9199 - mean_absolute_error: 6881.9199 - val_loss: 10669.2559 - val_mean_absolute_error: 10669.2559\n",
      "Epoch 656/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6880.3833 - mean_absolute_error: 6880.3833\n",
      "Epoch 00656: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.3530 - mean_absolute_error: 6881.3530 - val_loss: 11049.5078 - val_mean_absolute_error: 11049.5078\n",
      "Epoch 657/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6883.6538 - mean_absolute_error: 6883.6538\n",
      "Epoch 00657: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.7578 - mean_absolute_error: 6881.7578 - val_loss: 10869.9102 - val_mean_absolute_error: 10869.9102\n",
      "Epoch 658/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6878.5127 - mean_absolute_error: 6878.5127\n",
      "Epoch 00658: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6879.0693 - mean_absolute_error: 6879.0693 - val_loss: 10830.8760 - val_mean_absolute_error: 10830.8760\n",
      "Epoch 659/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6883.4478 - mean_absolute_error: 6883.4478\n",
      "Epoch 00659: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6883.3794 - mean_absolute_error: 6883.3794 - val_loss: 10648.7246 - val_mean_absolute_error: 10648.7246\n",
      "Epoch 660/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6881.2803 - mean_absolute_error: 6881.2803\n",
      "Epoch 00660: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.1831 - mean_absolute_error: 6881.1831 - val_loss: 10636.4551 - val_mean_absolute_error: 10636.4551\n",
      "Epoch 661/700\n",
      "5298/5298 [==============================] - ETA: 0s - loss: 6880.0327 - mean_absolute_error: 6880.0327\n",
      "Epoch 00661: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6880.0327 - mean_absolute_error: 6880.0327 - val_loss: 10826.1826 - val_mean_absolute_error: 10826.1826\n",
      "Epoch 662/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6871.9810 - mean_absolute_error: 6871.9810\n",
      "Epoch 00662: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6872.4897 - mean_absolute_error: 6872.4897 - val_loss: 10753.9785 - val_mean_absolute_error: 10753.9785\n",
      "Epoch 663/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6881.1064 - mean_absolute_error: 6881.1064\n",
      "Epoch 00663: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.0732 - mean_absolute_error: 6881.0732 - val_loss: 10902.1162 - val_mean_absolute_error: 10902.1162\n",
      "Epoch 664/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6875.3750 - mean_absolute_error: 6875.3750\n",
      "Epoch 00664: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6875.9785 - mean_absolute_error: 6875.9785 - val_loss: 11189.0254 - val_mean_absolute_error: 11189.0254\n",
      "Epoch 665/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6879.9507 - mean_absolute_error: 6879.9507\n",
      "Epoch 00665: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6880.6870 - mean_absolute_error: 6880.6870 - val_loss: 10588.0010 - val_mean_absolute_error: 10588.0010\n",
      "Epoch 666/700\n",
      "5281/5298 [============================>.] - ETA: 0s - loss: 6879.8115 - mean_absolute_error: 6879.8115\n",
      "Epoch 00666: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6880.5244 - mean_absolute_error: 6880.5244 - val_loss: 10745.0000 - val_mean_absolute_error: 10745.0000\n",
      "Epoch 667/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6883.8477 - mean_absolute_error: 6883.8477\n",
      "Epoch 00667: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6883.8706 - mean_absolute_error: 6883.8706 - val_loss: 10970.2236 - val_mean_absolute_error: 10970.2236\n",
      "Epoch 668/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6876.5054 - mean_absolute_error: 6876.5054\n",
      "Epoch 00668: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6877.6030 - mean_absolute_error: 6877.6030 - val_loss: 10925.1143 - val_mean_absolute_error: 10925.1143\n",
      "Epoch 669/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6882.9639 - mean_absolute_error: 6882.9639\n",
      "Epoch 00669: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6883.2646 - mean_absolute_error: 6883.2646 - val_loss: 10796.9746 - val_mean_absolute_error: 10796.9746\n",
      "Epoch 670/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6880.2964 - mean_absolute_error: 6880.2964\n",
      "Epoch 00670: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6880.0918 - mean_absolute_error: 6880.0918 - val_loss: 11111.1865 - val_mean_absolute_error: 11111.1865\n",
      "Epoch 671/700\n",
      "5283/5298 [============================>.] - ETA: 0s - loss: 6883.2124 - mean_absolute_error: 6883.2124\n",
      "Epoch 00671: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6883.1260 - mean_absolute_error: 6883.1260 - val_loss: 10492.3789 - val_mean_absolute_error: 10492.3789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 672/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6875.3027 - mean_absolute_error: 6875.3027\n",
      "Epoch 00672: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6873.5342 - mean_absolute_error: 6873.5342 - val_loss: 10653.2119 - val_mean_absolute_error: 10653.2119\n",
      "Epoch 673/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6878.3491 - mean_absolute_error: 6878.3491\n",
      "Epoch 00673: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6878.2573 - mean_absolute_error: 6878.2573 - val_loss: 10804.9922 - val_mean_absolute_error: 10804.9922\n",
      "Epoch 674/700\n",
      "5288/5298 [============================>.] - ETA: 0s - loss: 6879.1987 - mean_absolute_error: 6879.1987\n",
      "Epoch 00674: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6878.9604 - mean_absolute_error: 6878.9604 - val_loss: 10764.2002 - val_mean_absolute_error: 10764.2002\n",
      "Epoch 675/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6876.3330 - mean_absolute_error: 6876.3330\n",
      "Epoch 00675: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6876.5225 - mean_absolute_error: 6876.5225 - val_loss: 11026.9834 - val_mean_absolute_error: 11026.9834\n",
      "Epoch 676/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6878.0591 - mean_absolute_error: 6878.0591\n",
      "Epoch 00676: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6877.8960 - mean_absolute_error: 6877.8960 - val_loss: 10542.5879 - val_mean_absolute_error: 10542.5879\n",
      "Epoch 677/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6872.9302 - mean_absolute_error: 6872.9302\n",
      "Epoch 00677: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6872.8643 - mean_absolute_error: 6872.8643 - val_loss: 10824.0303 - val_mean_absolute_error: 10824.0303\n",
      "Epoch 678/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6876.0093 - mean_absolute_error: 6876.0093\n",
      "Epoch 00678: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6876.4209 - mean_absolute_error: 6876.4209 - val_loss: 10857.8320 - val_mean_absolute_error: 10857.8320\n",
      "Epoch 679/700\n",
      "5285/5298 [============================>.] - ETA: 0s - loss: 6868.1377 - mean_absolute_error: 6868.1377\n",
      "Epoch 00679: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6868.0762 - mean_absolute_error: 6868.0762 - val_loss: 10467.7930 - val_mean_absolute_error: 10467.7930\n",
      "Epoch 680/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6874.6997 - mean_absolute_error: 6874.6997\n",
      "Epoch 00680: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6874.6050 - mean_absolute_error: 6874.6050 - val_loss: 11082.1885 - val_mean_absolute_error: 11082.1885\n",
      "Epoch 681/700\n",
      "5279/5298 [============================>.] - ETA: 0s - loss: 6880.7515 - mean_absolute_error: 6880.7515\n",
      "Epoch 00681: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6881.9390 - mean_absolute_error: 6881.9390 - val_loss: 10700.7969 - val_mean_absolute_error: 10700.7969\n",
      "Epoch 682/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6872.8442 - mean_absolute_error: 6872.8442\n",
      "Epoch 00682: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6873.1211 - mean_absolute_error: 6873.1211 - val_loss: 10680.0449 - val_mean_absolute_error: 10680.0449\n",
      "Epoch 683/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6873.2490 - mean_absolute_error: 6873.2490\n",
      "Epoch 00683: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6873.4399 - mean_absolute_error: 6873.4399 - val_loss: 10517.5352 - val_mean_absolute_error: 10517.5352\n",
      "Epoch 684/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6882.8135 - mean_absolute_error: 6882.8135\n",
      "Epoch 00684: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6882.5601 - mean_absolute_error: 6882.5601 - val_loss: 10973.5371 - val_mean_absolute_error: 10973.5371\n",
      "Epoch 685/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6875.1104 - mean_absolute_error: 6875.1104\n",
      "Epoch 00685: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6875.3193 - mean_absolute_error: 6875.3193 - val_loss: 10605.9609 - val_mean_absolute_error: 10605.9609\n",
      "Epoch 686/700\n",
      "5296/5298 [============================>.] - ETA: 0s - loss: 6874.3203 - mean_absolute_error: 6874.3203\n",
      "Epoch 00686: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6874.5405 - mean_absolute_error: 6874.5405 - val_loss: 10816.7480 - val_mean_absolute_error: 10816.7480\n",
      "Epoch 687/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6874.8921 - mean_absolute_error: 6874.8921\n",
      "Epoch 00687: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6875.7012 - mean_absolute_error: 6875.7012 - val_loss: 10731.9180 - val_mean_absolute_error: 10731.9180\n",
      "Epoch 688/700\n",
      "5294/5298 [============================>.] - ETA: 0s - loss: 6872.7217 - mean_absolute_error: 6872.7217\n",
      "Epoch 00688: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6872.9980 - mean_absolute_error: 6872.9980 - val_loss: 11049.3701 - val_mean_absolute_error: 11049.3701\n",
      "Epoch 689/700\n",
      "5287/5298 [============================>.] - ETA: 0s - loss: 6874.2393 - mean_absolute_error: 6874.2393\n",
      "Epoch 00689: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6874.2725 - mean_absolute_error: 6874.2725 - val_loss: 10723.9502 - val_mean_absolute_error: 10723.9502\n",
      "Epoch 690/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6871.6108 - mean_absolute_error: 6871.6108\n",
      "Epoch 00690: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6871.7627 - mean_absolute_error: 6871.7627 - val_loss: 10764.1045 - val_mean_absolute_error: 10764.1045\n",
      "Epoch 691/700\n",
      "5289/5298 [============================>.] - ETA: 0s - loss: 6878.6748 - mean_absolute_error: 6878.6748\n",
      "Epoch 00691: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6878.0234 - mean_absolute_error: 6878.0234 - val_loss: 10771.5303 - val_mean_absolute_error: 10771.5303\n",
      "Epoch 692/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6868.9106 - mean_absolute_error: 6868.9106\n",
      "Epoch 00692: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 15s 3ms/step - loss: 6868.8940 - mean_absolute_error: 6868.8940 - val_loss: 10848.9385 - val_mean_absolute_error: 10848.9385\n",
      "Epoch 693/700\n",
      "5293/5298 [============================>.] - ETA: 0s - loss: 6866.2407 - mean_absolute_error: 6866.2407\n",
      "Epoch 00693: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6866.1729 - mean_absolute_error: 6866.1729 - val_loss: 10800.3750 - val_mean_absolute_error: 10800.3750\n",
      "Epoch 694/700\n",
      "5292/5298 [============================>.] - ETA: 0s - loss: 6872.6411 - mean_absolute_error: 6872.6411\n",
      "Epoch 00694: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6872.7974 - mean_absolute_error: 6872.7974 - val_loss: 10937.0264 - val_mean_absolute_error: 10937.0264\n",
      "Epoch 695/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6865.4409 - mean_absolute_error: 6865.4409\n",
      "Epoch 00695: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6865.7246 - mean_absolute_error: 6865.7246 - val_loss: 10431.8730 - val_mean_absolute_error: 10431.8730\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 696/700\n",
      "5295/5298 [============================>.] - ETA: 0s - loss: 6872.8247 - mean_absolute_error: 6872.8247\n",
      "Epoch 00696: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6872.9771 - mean_absolute_error: 6872.9771 - val_loss: 11138.2822 - val_mean_absolute_error: 11138.2822\n",
      "Epoch 697/700\n",
      "5297/5298 [============================>.] - ETA: 0s - loss: 6877.8657 - mean_absolute_error: 6877.8657\n",
      "Epoch 00697: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6877.9473 - mean_absolute_error: 6877.9473 - val_loss: 10489.0156 - val_mean_absolute_error: 10489.0156\n",
      "Epoch 698/700\n",
      "5284/5298 [============================>.] - ETA: 0s - loss: 6867.5503 - mean_absolute_error: 6867.5503\n",
      "Epoch 00698: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6868.7188 - mean_absolute_error: 6868.7188 - val_loss: 10925.2549 - val_mean_absolute_error: 10925.2549\n",
      "Epoch 699/700\n",
      "5280/5298 [============================>.] - ETA: 0s - loss: 6865.0068 - mean_absolute_error: 6865.0068\n",
      "Epoch 00699: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6864.4463 - mean_absolute_error: 6864.4463 - val_loss: 10998.2246 - val_mean_absolute_error: 10998.2246\n",
      "Epoch 700/700\n",
      "5282/5298 [============================>.] - ETA: 0s - loss: 6869.8447 - mean_absolute_error: 6869.8447\n",
      "Epoch 00700: val_loss did not improve from 10248.40137\n",
      "5298/5298 [==============================] - 14s 3ms/step - loss: 6871.3584 - mean_absolute_error: 6871.3584 - val_loss: 10913.9512 - val_mean_absolute_error: 10913.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ad8f2b7df0>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(x, y, epochs=700, batch_size=32, validation_split = 0.1, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "27d335b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d25282",
   "metadata": {},
   "source": [
    "# Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4d742ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_test = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "27f0523d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>#Order</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1000001</td>\n",
       "      <td>1</td>\n",
       "      <td>S1</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>9</td>\n",
       "      <td>7011.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1000002</td>\n",
       "      <td>253</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>60</td>\n",
       "      <td>51789.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1000003</td>\n",
       "      <td>252</td>\n",
       "      <td>S3</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>42</td>\n",
       "      <td>36868.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1000004</td>\n",
       "      <td>251</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R1</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>23</td>\n",
       "      <td>19715.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1000005</td>\n",
       "      <td>250</td>\n",
       "      <td>S2</td>\n",
       "      <td>L3</td>\n",
       "      <td>R4</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>62</td>\n",
       "      <td>45614.52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
       "0  T1000001         1         S1            L3          R1  2018-01-01   \n",
       "1  T1000002       253         S4            L2          R1  2018-01-01   \n",
       "2  T1000003       252         S3            L2          R1  2018-01-01   \n",
       "3  T1000004       251         S2            L3          R1  2018-01-01   \n",
       "4  T1000005       250         S2            L3          R4  2018-01-01   \n",
       "\n",
       "   Holiday Discount  #Order     Sales  \n",
       "0        1      Yes       9   7011.84  \n",
       "1        1      Yes      60  51789.12  \n",
       "2        1      Yes      42  36868.20  \n",
       "3        1      Yes      23  19715.16  \n",
       "4        1      Yes      62  45614.52  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "904d791e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Store_Type</th>\n",
       "      <th>Location_Type</th>\n",
       "      <th>Region_Code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T1188341</td>\n",
       "      <td>171</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R3</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1188342</td>\n",
       "      <td>172</td>\n",
       "      <td>S1</td>\n",
       "      <td>L1</td>\n",
       "      <td>R1</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>T1188343</td>\n",
       "      <td>173</td>\n",
       "      <td>S4</td>\n",
       "      <td>L2</td>\n",
       "      <td>R1</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>T1188344</td>\n",
       "      <td>174</td>\n",
       "      <td>S1</td>\n",
       "      <td>L1</td>\n",
       "      <td>R4</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>T1188345</td>\n",
       "      <td>170</td>\n",
       "      <td>S1</td>\n",
       "      <td>L1</td>\n",
       "      <td>R2</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Store_id Store_Type Location_Type Region_Code        Date  \\\n",
       "0  T1188341       171         S4            L2          R3  2019-06-01   \n",
       "1  T1188342       172         S1            L1          R1  2019-06-01   \n",
       "2  T1188343       173         S4            L2          R1  2019-06-01   \n",
       "3  T1188344       174         S1            L1          R4  2019-06-01   \n",
       "4  T1188345       170         S1            L1          R2  2019-06-01   \n",
       "\n",
       "   Holiday Discount  \n",
       "0        0       No  \n",
       "1        0       No  \n",
       "2        0       No  \n",
       "3        0       No  \n",
       "4        0       No  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "33d1e77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.drop(columns = ['ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1c53b5ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22260</th>\n",
       "      <td>186</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22261</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22262</th>\n",
       "      <td>185</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22263</th>\n",
       "      <td>69</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22264</th>\n",
       "      <td>365</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22265 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store_id        Date  Holiday Discount  Location_Type_L1  \\\n",
       "0           171  2019-06-01        0       No                 0   \n",
       "1           172  2019-06-01        0       No                 1   \n",
       "2           173  2019-06-01        0       No                 0   \n",
       "3           174  2019-06-01        0       No                 1   \n",
       "4           170  2019-06-01        0       No                 1   \n",
       "...         ...         ...      ...      ...               ...   \n",
       "22260       186  2019-07-31        0       No                 0   \n",
       "22261        11  2019-07-31        0       No                 0   \n",
       "22262       185  2019-07-31        0      Yes                 1   \n",
       "22263        69  2019-07-31        0       No                 1   \n",
       "22264       365  2019-07-31        0       No                 1   \n",
       "\n",
       "       Location_Type_L2  Location_Type_L3  Location_Type_L4  Location_Type_L5  \\\n",
       "0                     1                 0                 0                 0   \n",
       "1                     0                 0                 0                 0   \n",
       "2                     1                 0                 0                 0   \n",
       "3                     0                 0                 0                 0   \n",
       "4                     0                 0                 0                 0   \n",
       "...                 ...               ...               ...               ...   \n",
       "22260                 0                 0                 0                 1   \n",
       "22261                 1                 0                 0                 0   \n",
       "22262                 0                 0                 0                 0   \n",
       "22263                 0                 0                 0                 0   \n",
       "22264                 0                 0                 0                 0   \n",
       "\n",
       "       Store_Type_S1  Store_Type_S2  Store_Type_S3  Store_Type_S4  \\\n",
       "0                  0              0              0              1   \n",
       "1                  1              0              0              0   \n",
       "2                  0              0              0              1   \n",
       "3                  1              0              0              0   \n",
       "4                  1              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "22260              0              1              0              0   \n",
       "22261              0              0              0              1   \n",
       "22262              1              0              0              0   \n",
       "22263              1              0              0              0   \n",
       "22264              0              1              0              0   \n",
       "\n",
       "       Region_Code_R1  Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0                   0               0               1               0  \n",
       "1                   1               0               0               0  \n",
       "2                   1               0               0               0  \n",
       "3                   0               0               0               1  \n",
       "4                   0               1               0               0  \n",
       "...               ...             ...             ...             ...  \n",
       "22260               0               1               0               0  \n",
       "22261               1               0               0               0  \n",
       "22262               0               0               1               0  \n",
       "22263               0               0               0               1  \n",
       "22264               0               1               0               0  \n",
       "\n",
       "[22265 rows x 17 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.get_dummies(test, columns = ['Location_Type', 'Store_Type', 'Region_Code'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b3582e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>2019-06-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22260</th>\n",
       "      <td>186</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22261</th>\n",
       "      <td>11</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22262</th>\n",
       "      <td>185</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22263</th>\n",
       "      <td>69</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22264</th>\n",
       "      <td>365</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22265 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store_id        Date  Holiday  Discount  Location_Type_L1  \\\n",
       "0           171  2019-06-01        0         0                 0   \n",
       "1           172  2019-06-01        0         0                 1   \n",
       "2           173  2019-06-01        0         0                 0   \n",
       "3           174  2019-06-01        0         0                 1   \n",
       "4           170  2019-06-01        0         0                 1   \n",
       "...         ...         ...      ...       ...               ...   \n",
       "22260       186  2019-07-31        0         0                 0   \n",
       "22261        11  2019-07-31        0         0                 0   \n",
       "22262       185  2019-07-31        0         1                 1   \n",
       "22263        69  2019-07-31        0         0                 1   \n",
       "22264       365  2019-07-31        0         0                 1   \n",
       "\n",
       "       Location_Type_L2  Location_Type_L3  Location_Type_L4  Location_Type_L5  \\\n",
       "0                     1                 0                 0                 0   \n",
       "1                     0                 0                 0                 0   \n",
       "2                     1                 0                 0                 0   \n",
       "3                     0                 0                 0                 0   \n",
       "4                     0                 0                 0                 0   \n",
       "...                 ...               ...               ...               ...   \n",
       "22260                 0                 0                 0                 1   \n",
       "22261                 1                 0                 0                 0   \n",
       "22262                 0                 0                 0                 0   \n",
       "22263                 0                 0                 0                 0   \n",
       "22264                 0                 0                 0                 0   \n",
       "\n",
       "       Store_Type_S1  Store_Type_S2  Store_Type_S3  Store_Type_S4  \\\n",
       "0                  0              0              0              1   \n",
       "1                  1              0              0              0   \n",
       "2                  0              0              0              1   \n",
       "3                  1              0              0              0   \n",
       "4                  1              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "22260              0              1              0              0   \n",
       "22261              0              0              0              1   \n",
       "22262              1              0              0              0   \n",
       "22263              1              0              0              0   \n",
       "22264              0              1              0              0   \n",
       "\n",
       "       Region_Code_R1  Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0                   0               0               1               0  \n",
       "1                   1               0               0               0  \n",
       "2                   1               0               0               0  \n",
       "3                   0               0               0               1  \n",
       "4                   0               1               0               0  \n",
       "...               ...             ...             ...             ...  \n",
       "22260               0               1               0               0  \n",
       "22261               1               0               0               0  \n",
       "22262               0               0               1               0  \n",
       "22263               0               0               0               1  \n",
       "22264               0               1               0               0  \n",
       "\n",
       "[22265 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Discount'] = le.fit_transform(test['Discount'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "95acf19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_id</th>\n",
       "      <th>Date</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Discount</th>\n",
       "      <th>Location_Type_L1</th>\n",
       "      <th>Location_Type_L2</th>\n",
       "      <th>Location_Type_L3</th>\n",
       "      <th>Location_Type_L4</th>\n",
       "      <th>Location_Type_L5</th>\n",
       "      <th>Store_Type_S1</th>\n",
       "      <th>Store_Type_S2</th>\n",
       "      <th>Store_Type_S3</th>\n",
       "      <th>Store_Type_S4</th>\n",
       "      <th>Region_Code_R1</th>\n",
       "      <th>Region_Code_R2</th>\n",
       "      <th>Region_Code_R3</th>\n",
       "      <th>Region_Code_R4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>173</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>174</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>170</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22260</th>\n",
       "      <td>186</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22261</th>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22262</th>\n",
       "      <td>185</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22263</th>\n",
       "      <td>69</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22264</th>\n",
       "      <td>365</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22265 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Store_id  Date  Holiday  Discount  Location_Type_L1  Location_Type_L2  \\\n",
       "0           171     5        0         0                 0                 1   \n",
       "1           172     5        0         0                 1                 0   \n",
       "2           173     5        0         0                 0                 1   \n",
       "3           174     5        0         0                 1                 0   \n",
       "4           170     5        0         0                 1                 0   \n",
       "...         ...   ...      ...       ...               ...               ...   \n",
       "22260       186     2        0         0                 0                 0   \n",
       "22261        11     2        0         0                 0                 1   \n",
       "22262       185     2        0         1                 1                 0   \n",
       "22263        69     2        0         0                 1                 0   \n",
       "22264       365     2        0         0                 1                 0   \n",
       "\n",
       "       Location_Type_L3  Location_Type_L4  Location_Type_L5  Store_Type_S1  \\\n",
       "0                     0                 0                 0              0   \n",
       "1                     0                 0                 0              1   \n",
       "2                     0                 0                 0              0   \n",
       "3                     0                 0                 0              1   \n",
       "4                     0                 0                 0              1   \n",
       "...                 ...               ...               ...            ...   \n",
       "22260                 0                 0                 1              0   \n",
       "22261                 0                 0                 0              0   \n",
       "22262                 0                 0                 0              1   \n",
       "22263                 0                 0                 0              1   \n",
       "22264                 0                 0                 0              0   \n",
       "\n",
       "       Store_Type_S2  Store_Type_S3  Store_Type_S4  Region_Code_R1  \\\n",
       "0                  0              0              1               0   \n",
       "1                  0              0              0               1   \n",
       "2                  0              0              1               1   \n",
       "3                  0              0              0               0   \n",
       "4                  0              0              0               0   \n",
       "...              ...            ...            ...             ...   \n",
       "22260              1              0              0               0   \n",
       "22261              0              0              1               1   \n",
       "22262              0              0              0               0   \n",
       "22263              0              0              0               0   \n",
       "22264              1              0              0               0   \n",
       "\n",
       "       Region_Code_R2  Region_Code_R3  Region_Code_R4  \n",
       "0                   0               1               0  \n",
       "1                   0               0               0  \n",
       "2                   0               0               0  \n",
       "3                   0               0               1  \n",
       "4                   1               0               0  \n",
       "...               ...             ...             ...  \n",
       "22260               1               0               0  \n",
       "22261               0               0               0  \n",
       "22262               0               1               0  \n",
       "22263               0               0               1  \n",
       "22264               1               0               0  \n",
       "\n",
       "[22265 rows x 17 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['Date'] = pd.to_datetime(test['Date'], format = '%Y-%m-%d', errors = 'coerce')\n",
    "test['Date'] = test['Date'].dt.dayofweek\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c127a96e",
   "metadata": {},
   "source": [
    "# Scaling and applying Kernel Pca"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71ecc9",
   "metadata": {},
   "source": [
    "test = sc.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "0c507b54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.71000000e+02,  5.00000000e+00, -8.45075782e-18, ...,\n",
       "        -2.37205981e-17,  1.00000000e+00, -1.65053864e-20],\n",
       "       [ 1.72000000e+02,  5.00000000e+00, -8.45075782e-18, ...,\n",
       "        -2.37205981e-17,  5.20320516e-17, -1.65053864e-20],\n",
       "       [ 1.73000000e+02,  5.00000000e+00, -8.45075782e-18, ...,\n",
       "        -2.37205981e-17,  5.20320516e-17, -1.65053864e-20],\n",
       "       ...,\n",
       "       [ 1.85000000e+02,  2.00000000e+00, -8.45075782e-18, ...,\n",
       "        -2.37205981e-17,  1.00000000e+00, -1.65053864e-20],\n",
       "       [ 6.90000000e+01,  2.00000000e+00, -8.45075782e-18, ...,\n",
       "        -2.37205981e-17,  5.20320516e-17,  1.00000000e+00],\n",
       "       [ 3.65000000e+02,  2.00000000e+00, -8.45075782e-18, ...,\n",
       "         1.00000000e+00,  5.20320516e-17, -1.65053864e-20]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ab58aba5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#kpca.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4498c7a3",
   "metadata": {},
   "source": [
    "# Predecting Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5aa9c723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([71429.43 , 37066.523, 82935.695, ..., 52808.78 , 38620.69 ,\n",
       "       30115.068], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = grid_search.predict(test)\n",
    "#pred = xgb.predict(test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab71f00",
   "metadata": {},
   "source": [
    "aml_pred = aml.leader.predict(test)\n",
    "aml_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2796000e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved\n"
     ]
    }
   ],
   "source": [
    "submit = pd.DataFrame()\n",
    "submit['ID'] = original_test['ID']\n",
    "submit['Sales'] = pred\n",
    "submit.to_csv('Submission7.csv', index = False)\n",
    "print(\"file saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6f6963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
